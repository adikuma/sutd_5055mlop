{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d2bc81-e67b-413d-b520-38dfe92b2e23",
   "metadata": {},
   "source": [
    "# Group Project / Assignment 3: Retrieval-Augmented Generation Question Answering\n",
    "**Assignment due 6 April 11:59pm 2025**\n",
    "\n",
    "Welcome to the third assignment for 50.055 Machine Learning Operations. \n",
    "The third and fourth assignment together form the course group project. You will be working in your project groups to build a chatbot which can answer questions about SUTD to prospective students.\n",
    "\n",
    "\n",
    "**This assignment is a group assignment.**\n",
    "\n",
    "- Read the instructions in this notebook carefully\n",
    "- Add your solution code and answers in the appropriate places. The questions are marked as **QUESTION:**, the places where you need to add your code and text answers are marked as **ADD YOUR SOLUTION HERE**\n",
    "- The completed notebook, including your added code and generated output will be your submission for the assignment.\n",
    "- The notebook should execute without errors from start to finish when you select \"Restart Kernel and Run All Cells..\". Please test this before submission.\n",
    "- Use the SUTD Education Cluster to solve and test the assignment. If you work on another environment, minimally test your work on the SUTD Education Cluster.\n",
    "\n",
    "**Rubric for assessment** \n",
    "\n",
    "Your submission will be graded using the following criteria. \n",
    "1. Code executes: your code should execute without errors. The SUTD Education cluster should be used to ensure the same execution environment.\n",
    "2. Correctness: the code should produce the correct result or the text answer should state the factual correct answer.\n",
    "3. Style: your code should be written in a way that is clean and efficient. Your text answers should be relevant, concise and easy to understand.\n",
    "4. Partial marks will be awarded for partially correct solutions.\n",
    "5. Creativity and innovation: in this assignment you have more freedom to design your solution, compared to the first assignments. You can show of your creativity and innovative mindset. \n",
    "6. There is a maximum of 225 points for this assignment.\n",
    "\n",
    "**ChatGPT policy** \n",
    "\n",
    "If you use AI tools, such as ChatGPT, to solve the assignment questions, you need to be transparent about its use and mark AI-generated content as such. In particular, you should include the following in addition to your final answer:\n",
    "- A copy or screenshot of the prompt you used\n",
    "- The name of the AI model\n",
    "- The AI generated output\n",
    "- An explanation why the answer is correct or what you had to change to arrive at the correct answer\n",
    "\n",
    "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission instructions are located at the bottom of the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf8b8a-1385-47bf-9aea-68bac46f7098",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation (RAG) \n",
    "\n",
    "In this assignment, you will be building a Retrieval-Augmented Generation (RAG) question answering system which can answer questions about SUTD.\n",
    "\n",
    "We'll be leveraging `langchain` and `llama 3.2`.\n",
    "\n",
    "Check out the docs:\n",
    "- [LangChain](https://docs.langchain.com/docs/)\n",
    "- [Llama 3.2](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/)\n",
    "\n",
    "\n",
    "The SUTD website used to allow chatting with current students. Unfortunately, this feature does not exist anymore. Let's build a chatbot to fill this gap!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada99010",
   "metadata": {},
   "source": [
    "### Conduct user research\n",
    "\n",
    "What are the questions that prospective and current students have about SUTD? In week 2, you already conducted some user research to understand your users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd4e96",
   "metadata": {},
   "source": [
    "### Value Proposition Canvas\n",
    "\n",
    "\n",
    "### QUESTION: \n",
    "\n",
    "Paste the value proposition canvas which you have created in week 2 into this notebook below. \n",
    "\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "\n",
    "- (replace canvas image below)\n",
    "\n",
    "------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5ec91",
   "metadata": {},
   "source": [
    "![image.png](images/canvas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1d0c3",
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "Use pip to install all required dependencies of this assignment in the cell below. Make sure to test this on the SUTD cluster as different environments have different software pre-installed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ed5c8e-f07e-4de2-b2de-0a063001668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==1.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: aiofiles==24.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 2)) (24.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.11.14 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.11.14)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.9.3)\n",
      "Requirement already satisfied: anyio==4.9.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 8)) (4.9.0)\n",
      "Requirement already satisfied: asttokens==3.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: attrs==25.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 10)) (25.3.0)\n",
      "Requirement already satisfied: backoff==2.2.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.13.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 12)) (4.13.3)\n",
      "Requirement already satisfied: bitsandbytes==0.45.4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 13)) (0.45.4)\n",
      "Requirement already satisfied: cachetools==5.5.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 14)) (5.5.2)\n",
      "Requirement already satisfied: certifi==2025.1.31 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 15)) (2025.1.31)\n",
      "Requirement already satisfied: cffi==1.17.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 16)) (1.17.1)\n",
      "Requirement already satisfied: chardet==5.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 17)) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 18)) (3.4.1)\n",
      "Requirement already satisfied: click==8.1.8 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 19)) (8.1.8)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 20)) (0.4.6)\n",
      "Requirement already satisfied: coloredlogs==15.0.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 21)) (15.0.1)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 22)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 23)) (1.3.1)\n",
      "Requirement already satisfied: cryptography==44.0.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 24)) (44.0.2)\n",
      "Requirement already satisfied: cssselect==1.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 25)) (1.3.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 26)) (0.12.1)\n",
      "Requirement already satisfied: dataclasses-json==0.6.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 27)) (0.6.7)\n",
      "Requirement already satisfied: debugpy==1.8.13 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 28)) (1.8.13)\n",
      "Requirement already satisfied: decorator==5.2.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 29)) (5.2.1)\n",
      "Requirement already satisfied: Deprecated==1.2.18 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 30)) (1.2.18)\n",
      "Requirement already satisfied: distro==1.9.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 31)) (1.9.0)\n",
      "Requirement already satisfied: effdet==0.4.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 32)) (0.4.1)\n",
      "Requirement already satisfied: emoji==2.14.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 33)) (2.14.1)\n",
      "Requirement already satisfied: et_xmlfile==2.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 34)) (2.0.0)\n",
      "Requirement already satisfied: eval_type_backport==0.2.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 35)) (0.2.2)\n",
      "Requirement already satisfied: executing==2.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 36)) (2.2.0)\n",
      "Requirement already satisfied: faiss-cpu==1.10.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 37)) (1.10.0)\n",
      "Requirement already satisfied: filelock==3.18.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 38)) (3.18.0)\n",
      "Requirement already satisfied: filetype==1.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 39)) (1.2.0)\n",
      "Requirement already satisfied: FlashRank==0.2.10 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 40)) (0.2.10)\n",
      "Requirement already satisfied: flatbuffers==25.2.10 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 41)) (25.2.10)\n",
      "Requirement already satisfied: fonttools==4.57.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 42)) (4.57.0)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 43)) (1.5.0)\n",
      "Requirement already satisfied: fsspec==2025.3.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 44)) (2025.3.2)\n",
      "Requirement already satisfied: google-api-core==2.24.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 45)) (2.24.2)\n",
      "Requirement already satisfied: google-auth==2.38.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 46)) (2.38.0)\n",
      "Requirement already satisfied: google-cloud-vision==3.10.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 47)) (3.10.1)\n",
      "Requirement already satisfied: googleapis-common-protos==1.69.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 48)) (1.69.2)\n",
      "Requirement already satisfied: graphviz==0.20.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 49)) (0.20.3)\n",
      "Requirement already satisfied: greenlet==3.1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 50)) (3.1.1)\n",
      "Requirement already satisfied: grpcio==1.71.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 51)) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status==1.71.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 52)) (1.71.0)\n",
      "Requirement already satisfied: h11==0.14.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 53)) (0.14.0)\n",
      "Requirement already satisfied: html5lib==1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 54)) (1.1)\n",
      "Requirement already satisfied: httpcore==1.0.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 55)) (1.0.7)\n",
      "Requirement already satisfied: httpx==0.28.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 56)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 57)) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub==0.30.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 58)) (0.30.1)\n",
      "Requirement already satisfied: humanfriendly==10.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 59)) (10.0)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 60)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 61)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.0.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 62)) (9.0.2)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 63)) (1.1.1)\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 64)) (8.1.5)\n",
      "Requirement already satisfied: jedi==0.19.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 65)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 66)) (3.1.6)\n",
      "Requirement already satisfied: jiter==0.9.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 67)) (0.9.0)\n",
      "Requirement already satisfied: joblib==1.4.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 68)) (1.4.2)\n",
      "Requirement already satisfied: jsonpatch==1.33 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 69)) (1.33)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 70)) (3.0.0)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 71)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 72)) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.13 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 73)) (3.0.13)\n",
      "Requirement already satisfied: kiwisolver==1.4.8 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 74)) (1.4.8)\n",
      "Requirement already satisfied: langchain==0.3.21 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 75)) (0.3.21)\n",
      "Requirement already satisfied: langchain-community==0.3.20 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 76)) (0.3.20)\n",
      "Requirement already satisfied: langchain-core==0.3.49 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 77)) (0.3.49)\n",
      "Requirement already satisfied: langchain-openai==0.3.11 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 78)) (0.3.11)\n",
      "Requirement already satisfied: langchain-text-splitters==0.3.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 79)) (0.3.7)\n",
      "Requirement already satisfied: langdetect==1.0.9 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 80)) (1.0.9)\n",
      "Requirement already satisfied: langsmith==0.3.19 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 81)) (0.3.19)\n",
      "Requirement already satisfied: lxml==5.3.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 82)) (5.3.1)\n",
      "Requirement already satisfied: lxml_html_clean==0.4.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 83)) (0.4.1)\n",
      "Requirement already satisfied: Markdown==3.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 84)) (3.7)\n",
      "Requirement already satisfied: markdownify==1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 85)) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 86)) (3.0.2)\n",
      "Requirement already satisfied: marshmallow==3.26.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 87)) (3.26.1)\n",
      "Requirement already satisfied: matplotlib==3.10.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 88)) (3.10.1)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 89)) (0.1.7)\n",
      "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 90)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 91)) (6.2.0)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 92)) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 93)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 94)) (3.4.2)\n",
      "Requirement already satisfied: nltk==3.9.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 95)) (3.9.1)\n",
      "Requirement already satisfied: numpy==2.2.4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 96)) (2.2.4)\n",
      "Requirement already satisfied: olefile==0.47 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 97)) (0.47)\n",
      "Requirement already satisfied: omegaconf==2.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 98)) (2.3.0)\n",
      "Requirement already satisfied: onnx==1.17.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 99)) (1.17.0)\n",
      "Requirement already satisfied: onnxruntime==1.21.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 100)) (1.21.0)\n",
      "Requirement already satisfied: openai==1.69.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 101)) (1.69.0)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 102)) (4.11.0.86)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 103)) (3.1.5)\n",
      "Requirement already satisfied: orjson==3.10.16 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 104)) (3.10.16)\n",
      "Requirement already satisfied: packaging==24.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 105)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 106)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 107)) (0.8.4)\n",
      "Requirement already satisfied: pdf2image==1.17.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 108)) (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 109)) (20250327)\n",
      "Requirement already satisfied: pi_heif==0.22.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 110)) (0.22.0)\n",
      "Requirement already satisfied: pikepdf==9.5.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 111)) (9.5.2)\n",
      "Requirement already satisfied: pillow==11.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 112)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 113)) (4.3.7)\n",
      "Requirement already satisfied: playwright==1.51.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 114)) (1.51.0)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 115)) (3.0.50)\n",
      "Requirement already satisfied: propcache==0.3.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 116)) (0.3.1)\n",
      "Requirement already satisfied: proto-plus==1.26.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 117)) (1.26.1)\n",
      "Requirement already satisfied: protobuf==5.29.4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 118)) (5.29.4)\n",
      "Requirement already satisfied: psutil==7.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 119)) (7.0.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 120)) (0.2.3)\n",
      "Requirement already satisfied: pyasn1==0.6.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 121)) (0.6.1)\n",
      "Requirement already satisfied: pyasn1_modules==0.4.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 122)) (0.4.2)\n",
      "Requirement already satisfied: pycocotools==2.0.8 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 123)) (2.0.8)\n",
      "Requirement already satisfied: pycparser==2.22 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 124)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.11.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 125)) (2.11.1)\n",
      "Requirement already satisfied: pydantic-settings==2.8.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 126)) (2.8.1)\n",
      "Requirement already satisfied: pydantic_core==2.33.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 127)) (2.33.0)\n",
      "Requirement already satisfied: pyee==12.1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 128)) (12.1.1)\n",
      "Requirement already satisfied: Pygments==2.19.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 129)) (2.19.1)\n",
      "Requirement already satisfied: pypandoc==1.15 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 130)) (1.15)\n",
      "Requirement already satisfied: pyparsing==3.2.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 131)) (3.2.3)\n",
      "Requirement already satisfied: pypdf==5.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 132)) (5.4.0)\n",
      "Requirement already satisfied: pypdfium2==4.30.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 133)) (4.30.1)\n",
      "Requirement already satisfied: pyreadline3==3.5.4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 134)) (3.5.4)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 135)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-docx==1.1.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 136)) (1.1.2)\n",
      "Requirement already satisfied: python-dotenv==1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 137)) (1.1.0)\n",
      "Requirement already satisfied: python-iso639==2025.2.18 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 138)) (2025.2.18)\n",
      "Requirement already satisfied: python-magic==0.4.27 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 139)) (0.4.27)\n",
      "Requirement already satisfied: python-multipart==0.0.20 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 140)) (0.0.20)\n",
      "Requirement already satisfied: python-oxmsg==0.0.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 141)) (0.0.2)\n",
      "Requirement already satisfied: python-pptx==1.0.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 142)) (1.0.2)\n",
      "Requirement already satisfied: pytz==2025.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 143)) (2025.2)\n",
      "Requirement already satisfied: pywin32==310 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 144)) (310)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 145)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 146)) (26.3.0)\n",
      "Requirement already satisfied: RapidFuzz==3.13.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 147)) (3.13.0)\n",
      "Requirement already satisfied: readability==0.3.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 148)) (0.3.2)\n",
      "Requirement already satisfied: readability-lxml==0.8.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 149)) (0.8.1)\n",
      "Requirement already satisfied: regex==2024.11.6 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 150)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 151)) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt==1.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 152)) (1.0.0)\n",
      "Requirement already satisfied: rsa==4.9 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 153)) (4.9)\n",
      "Requirement already satisfied: safetensors==0.5.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 154)) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 155)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 156)) (1.15.2)\n",
      "Requirement already satisfied: sentence-transformers==4.0.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 157)) (4.0.2)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 158)) (0.2.0)\n",
      "Requirement already satisfied: setuptools==70.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 159)) (70.2.0)\n",
      "Requirement already satisfied: six==1.17.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 160)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 161)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.6 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 162)) (2.6)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.40 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 163)) (2.0.40)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 164)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 165)) (1.13.1)\n",
      "Requirement already satisfied: tenacity==9.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 166)) (9.0.0)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 167)) (3.6.0)\n",
      "Requirement already satisfied: tiktoken==0.9.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 168)) (0.9.0)\n",
      "Requirement already satisfied: timm==1.0.15 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 169)) (1.0.15)\n",
      "Requirement already satisfied: tokenizers==0.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 170)) (0.21.1)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 171)) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 172)) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.21.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 173)) (0.21.0+cu118)\n",
      "Requirement already satisfied: tornado==6.4.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 174)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 175)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 176)) (5.14.3)\n",
      "Requirement already satisfied: transformers==4.50.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 177)) (4.50.3)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 178)) (0.9.0)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 179)) (0.4.0)\n",
      "Requirement already satisfied: typing_extensions==4.13.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 180)) (4.13.0)\n",
      "Requirement already satisfied: tzdata==2025.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 181)) (2025.2)\n",
      "Requirement already satisfied: unstructured==0.17.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 182)) (0.17.2)\n",
      "Requirement already satisfied: unstructured-client==0.32.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 183)) (0.32.1)\n",
      "Requirement already satisfied: unstructured-inference==0.8.10 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 184)) (0.8.10)\n",
      "Requirement already satisfied: unstructured.pytesseract==0.3.15 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 185)) (0.3.15)\n",
      "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 186)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 187)) (0.2.13)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 188)) (0.5.1)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 189)) (4.0.13)\n",
      "Requirement already satisfied: wrapt==1.17.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 190)) (1.17.2)\n",
      "Requirement already satisfied: xlrd==2.0.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 191)) (2.0.1)\n",
      "Requirement already satisfied: XlsxWriter==3.2.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 192)) (3.2.2)\n",
      "Requirement already satisfied: yarl==1.18.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 193)) (1.18.3)\n",
      "Requirement already satisfied: zstandard==0.23.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from -r requirements.txt (line 194)) (0.23.0)\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Install and import all required packages\n",
    "# The rest of your code should execute without any import or dependency errors.\n",
    "\n",
    "# **--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "!pip3 install -r requirements.txt\n",
    "\n",
    "# For CUDA purposes, uncomment the following line and run it in your terminal:\n",
    "#! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb2b9c",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b15dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from glob import glob\n",
    "import openai\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from markdown import markdown\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "import tempfile\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "from rag_prompt import RAG_PROMPT\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "MARKDOWN_PATH = \"data/markdown/markdown_data.json\"\n",
    "HTML_PATH = \"data/html/html_data.json\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "TOP_K = 5\n",
    "OUTPUT_DIR = \"vector_store\"\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "MODEL_DIR = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3447d-b41f-4ac5-95b9-1cae3a42d620",
   "metadata": {},
   "source": [
    "# Download documents\n",
    "The RAG application should be able to answer questions based on ingested documents. For the SUTD chatbot, download PDF and HTML files from the SUTD website. The documents should contain information about the admission process, available courses and the university in general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c5201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 30 HTML documents and 30 Markdown documents\n",
      "Found 27 Markdown files on disk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Has Markdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUTD About page</td>\n",
       "      <td>https://www.sutd.edu.sg/about/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUTD Contact page</td>\n",
       "      <td>https://www.sutd.edu.sg/contact-us/contact-sutd/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUTD Home page</td>\n",
       "      <td>https://www.sutd.edu.sg/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUTD Application Guide page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/undergradua...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUTD Appeal Guide page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/undergradua...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUTD Admission Requirements page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/undergradua...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUTD Masters information page 1</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/graduate/ma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUTD Masters information page 2</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/graduate/ma...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUTD PHD information page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/graduate/phd/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUTD Academic Calendar</td>\n",
       "      <td>https://www.sutd.edu.sg/education/undergraduat...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                   SUTD About page   \n",
       "1                 SUTD Contact page   \n",
       "2                    SUTD Home page   \n",
       "3       SUTD Application Guide page   \n",
       "4            SUTD Appeal Guide page   \n",
       "5  SUTD Admission Requirements page   \n",
       "6   SUTD Masters information page 1   \n",
       "7   SUTD Masters information page 2   \n",
       "8         SUTD PHD information page   \n",
       "9            SUTD Academic Calendar   \n",
       "\n",
       "                                                 URL  Has Markdown  \n",
       "0                     https://www.sutd.edu.sg/about/          True  \n",
       "1   https://www.sutd.edu.sg/contact-us/contact-sutd/          True  \n",
       "2                           https://www.sutd.edu.sg/         False  \n",
       "3  https://www.sutd.edu.sg/admissions/undergradua...          True  \n",
       "4  https://www.sutd.edu.sg/admissions/undergradua...          True  \n",
       "5  https://www.sutd.edu.sg/admissions/undergradua...          True  \n",
       "6  https://www.sutd.edu.sg/admissions/graduate/ma...         False  \n",
       "7  https://www.sutd.edu.sg/admissions/graduate/ma...          True  \n",
       "8   https://www.sutd.edu.sg/admissions/graduate/phd/          True  \n",
       "9  https://www.sutd.edu.sg/education/undergraduat...          True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... and 20 more documents\n",
      "\n",
      "Document Statistics:\n",
      "Total SUTD documents: 30\n",
      "Documents with extracted markdown content: 27\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Download documents from the SUTD website\n",
    "# You should download at least 10 documents but more documents can increase the knowledge base of your chatbot.\n",
    "\n",
    "# **--- ADD YOUR SOLUTION HERE (20 points) ---**\n",
    "def get_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        output_json = json.load(f)\n",
    "    return output_json\n",
    "\n",
    "# load the HTML and Markdown data to be used\n",
    "html_data = get_data(HTML_PATH)\n",
    "markdown_data = get_data(MARKDOWN_PATH)\n",
    "\n",
    "# this is just for displaying the data\n",
    "print(\n",
    "    f\"Successfully loaded {len(html_data)} HTML documents and {len(markdown_data)} Markdown documents\"\n",
    ")\n",
    "\n",
    "markdown_files = glob(\"data/markdown/*.md\")\n",
    "print(f\"Found {len(markdown_files)} Markdown files on disk\")\n",
    "\n",
    "docs_info = []\n",
    "for doc in markdown_data:\n",
    "    docs_info.append(\n",
    "        {\n",
    "            \"Title\": doc.get(\"title\", \"No Title\"),\n",
    "            \"URL\": doc.get(\"url\", \"No URL\"),\n",
    "            \"Has Markdown\": bool(doc.get(\"markdown\", \"\").strip()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "docs_df = pd.DataFrame(docs_info)\n",
    "display(docs_df.head(10))\n",
    "\n",
    "if len(docs_df) > 10:\n",
    "    print(f\"... and {len(docs_df) - 10} more documents\")\n",
    "\n",
    "print(\"\\nDocument Statistics:\")\n",
    "print(f\"Total SUTD documents: {len(docs_df)}\")\n",
    "print(f\"Documents with extracted markdown content: {docs_df['Has Markdown'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a646cbd-2a05-4078-995b-4317a94ed109",
   "metadata": {},
   "source": [
    "# Split documents\n",
    "Use LangChain to split the documents into smaller text chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ed0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "####LATEST CHUNKING CODE#####\n",
    "\n",
    "# QUESTION: Use langchain to split the documents into chunks\n",
    "\n",
    "# --- ADD YOUR SOLUTION HERE (20 points)---\n",
    "all_documents = []\n",
    "\n",
    "def extract_pillar(title, url):\n",
    "    # extract each pillar to add to metadata to make it easier to provide context to llm\n",
    "    pillars = [\"ISTD\", \"ESD\", \"EPD\", \"ASD\", \"DAI\", \"HASS\", \"SMT\"]\n",
    "\n",
    "    for pillar in pillars:\n",
    "        if pillar in title or pillar.lower() in url.lower():\n",
    "            return pillar\n",
    "    # if no pillar is found, return 'General'\n",
    "    return \"General\"\n",
    "\n",
    "#extract all internal urls in a page\n",
    "def extract_all_internal_urls(markdown_text):\n",
    "    internal_urls = []\n",
    "\n",
    "    link_pattern = r'\\[([^\\]]+)\\]\\((https?://[^)]+)\\)'\n",
    "    matches = re.findall(link_pattern, markdown_text)  # using regex to extract links\n",
    "\n",
    "    for text, url in matches:\n",
    "        if 'sutd.edu.sg' in url:\n",
    "            internal_urls.append({\n",
    "                'text': text,\n",
    "                'url': url\n",
    "            })\n",
    "\n",
    "    return internal_urls\n",
    "\n",
    "#match urls to chunk title\n",
    "def match_urls_to_chunk(chunk_title, all_urls):\n",
    "    if not chunk_title:\n",
    "        return []\n",
    "\n",
    "    matched_urls = []\n",
    "\n",
    "    normalized_title = chunk_title.lower()\n",
    "\n",
    "    for url_info in all_urls:\n",
    "        link_text = url_info['text'].lower()\n",
    "\n",
    "        if link_text == normalized_title:\n",
    "            matched_urls.append(url_info['url'])\n",
    "            continue\n",
    "\n",
    "        title_words = set(normalized_title.split())\n",
    "        link_words = set(link_text.split())\n",
    "\n",
    "        common_words = title_words.intersection(link_words)\n",
    "        if len(common_words) >= min(2, len(title_words) // 2):\n",
    "            matched_urls.append(url_info['url'])\n",
    "\n",
    "    return matched_urls\n",
    "\n",
    "for item in markdown_data:\n",
    "    # if markdown is empty, continue\n",
    "    if not item.get(\"markdown\"):\n",
    "        continue\n",
    "\n",
    "    all_internal_urls = extract_all_internal_urls(item[\"markdown\"])\n",
    "\n",
    "    # create temporary file for each markdown page as the input for unstructuredmarkdownloader\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False, encoding='utf-8') as temp_file: # added encoding='utf-8' to handle them non-ascii characters\n",
    "        temp_file.write(item[\"markdown\"])\n",
    "        temp_file_path = temp_file.name\n",
    "\n",
    "    try:\n",
    "        # call unstructuredmarkdownloader class to parse markdown files and split file by \"elements\" structure\n",
    "        loader = UnstructuredMarkdownLoader(temp_file_path, mode=\"elements\")\n",
    "        docs = loader.load()\n",
    "\n",
    "        chunk_groups = {}\n",
    "        current_title = None\n",
    "\n",
    "        # access to individual \"chunks\" of data after split by elements\n",
    "        for doc in docs:\n",
    "\n",
    "            if doc.metadata.get(\"category\") == \"Title\":\n",
    "                current_title = doc.page_content\n",
    "                # doc.metadata[\"_skip\"] = True\n",
    "                continue\n",
    "\n",
    "            if current_title not in chunk_groups:\n",
    "                chunk_groups[current_title] = []\n",
    "\n",
    "            chunk_groups[current_title].append(doc.page_content)\n",
    "        for title, contents in chunk_groups.items():\n",
    "\n",
    "            combined_content = \" \".join(contents)\n",
    "\n",
    "            if len(combined_content.split()) < 3:  # skip if fewer than 3 words\n",
    "                continue\n",
    "\n",
    "            relevant_urls = match_urls_to_chunk(title, all_internal_urls)  # changed current_title to title for correct matching\n",
    "\n",
    "            enhanced_metadata = {\n",
    "                \"title\": item[\"title\"],\n",
    "                \"url\": item[\"url\"],\n",
    "                \"description\": item[\"description\"],\n",
    "\n",
    "                \"element_type\": \"unknown\",  # replaced undefined doc with fixed value\n",
    "\n",
    "                \"chunk_title\": title,\n",
    "\n",
    "                #TODO: match all internal urls according to words similarity to current_title\n",
    "\n",
    "                \"internal_urls\": relevant_urls if relevant_urls else None,\n",
    "\n",
    "                \"pillar\": extract_pillar(item.get(\"title\", \"\"), item.get(\"url\", \"\"))\n",
    "            }\n",
    "\n",
    "            enhanced_doc = Document(\n",
    "                page_content=combined_content,\n",
    "                metadata=enhanced_metadata\n",
    "            )\n",
    "\n",
    "            # finally, add the enhanced document to the list of all documents\n",
    "            all_documents.append(enhanced_doc)\n",
    "\n",
    "    finally:\n",
    "        # clean up the temporary files\n",
    "        os.unlink(temp_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85abee2",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "\n",
    "What chunking method or strategy did you use? Why did you use this method. Explain your design decision in less than 10 sentences.\n",
    "\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "\n",
    "We designed a hierarchical chunking strategy that respects the natural flow of a document. First, we extract logical sections using markdown headers (h1-h6), turning each section into its own chunk with its heading, content, and useful metadata like title, URL, parent sections, and pillar/department information. To avoid fragmentation, we combine very short chunks (under 100 characters) with nearby related content, and for long chunks (over 1000 characters), we split them using a recursive approach that breaks at natural separators such as paragraphs or sentences. We also keep a 100-character overlap between chunks to maintain context. This way, each chunk remains a complete, meaningful unit, perfectly sized for embedding and retrieval.\n",
    "\n",
    "------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a133cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is the implementation for using LangChain to create a vector store\n",
    "# But it didn't allow us to switch between different embeddings easily with various models\n",
    "\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embedding = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=OPENAI_API_KEY)\n",
    "# retriever = FAISS.from_documents(refined_chunks, embedding).as_retriever(search_kwargs={\"k\": 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891962a0-65ac-48c5-8a36-6424f0e14734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example chunk: page_content='SUTD was founded in July 2009 as Singapore's fourth publicly funded university. The university was officially inaugurated by President Tony Tan Keng Yam on May 7, 2012. SUTD's first academic year began in April 2012.' metadata={'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'element_type': 'unknown', 'chunk_title': 'About SUTD', 'internal_urls': ['https://www.sutd.edu.sg/about/partnering-with-sutd/giving/'], 'pillar': 'General'}\n",
      "\n",
      "embedding 202 items with model: sentence-transformers/all-MiniLM-L6-v2\n",
      "saved vector store with 202 documents\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: create embeddings of document chunks and store them in a local vector store for fast lookup\n",
    "# Decide an appropriate embedding model. Use Huggingface to run the embedding model locally.\n",
    "# You do not have to use cloud-based APIs.\n",
    "\n",
    "# --- ADD YOUR SOLUTION HERE (20 points)---\n",
    "# QUESTION: create embeddings of document chunks and store them in a local vector store for fast lookup\n",
    "# Decide an appropriate embedding model. Use Huggingface to run the embedding model locally.\n",
    "# You do not have to use cloud-based APIs.\n",
    "# --- ADD YOUR SOLUTION HERE (20 points)---\n",
    "\n",
    "\n",
    "\n",
    "# creating a retriever class to make it compatible with langchain and allow for huggingface embeddings and openai embeddings\n",
    "# this class that can handle both local Hugging Face models AND OpenAI models in one implementation (we made this to make it easy for us to switch between models)\n",
    "# the best part is storing the embeddings in a local vector store (i think langchain has this as well but we made our own)\n",
    "# we just added this layer on top of the simple langchain implementation\n",
    "class CustomEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        if model_name.startswith(\"text-embedding-\"):\n",
    "            self.model = None\n",
    "        else:\n",
    "            self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        print(f\"\\nembedding {len(texts)} items with model: {self.model_name}\")\n",
    "        if self.model_name.startswith(\"text-embedding-\"):\n",
    "            response = openai.embeddings.create(model=self.model_name, input=texts)\n",
    "            return [r.embedding for r in response.data]\n",
    "        else:\n",
    "            embeddings = self.model.encode(\n",
    "                texts, convert_to_numpy=True, normalize_embeddings=True\n",
    "            ).astype(\"float32\")\n",
    "            return embeddings.tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# using FAISS to create a vector store from the documents and using it's as_retriever method to create a retriever\n",
    "# setting default k to 7\n",
    "# embedding model chosen is text-embedding-ada-002\n",
    "def create_retriever(refined_chunks, embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\", k=7):\n",
    "    embeddings = CustomEmbeddings(model_name=embedding_model)\n",
    "\n",
    "    if len(refined_chunks) > 0:\n",
    "        print(f\"example chunk: {refined_chunks[0]}\")\n",
    "\n",
    "    vectorstore = FAISS.from_documents(refined_chunks, embeddings)\n",
    "    vector_store_dir = OUTPUT_DIR\n",
    "    os.makedirs(vector_store_dir, exist_ok=True)\n",
    "    vectorstore.save_local(vector_store_dir)\n",
    "\n",
    "    print(f\"saved vector store with {len(refined_chunks)} documents\")\n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "retriever = create_retriever(all_documents, embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6bb601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "# the idea here is to rerank those candidates with a more powerful model (slower but more accurate)\n",
    "# we think that the retriever may not be able to pick the best documents hence use a reranker to pick the best documents\n",
    "# this is done by using the FlashrankRerank class\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [\n",
    "                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n",
    "                for i, d in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "compressor = FlashrankRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f20674",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "\n",
    "What embeddings and vector store did you use and why? Explain your design decision in less than 10 sentences.\n",
    "\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "\n",
    "We used OpenAI's \"text-embedding-ada-002\" for embeddings and FAISS (Facebook AI Similarity Search) as our vector store. The \"text-embedding-ada-002\" model provides embeddings with high quality semantic understanding of academic and technical content, which is important for accurately representing SUTD's educational information. We have compared the performance of this model against the following other models namely: all-MiniLM-L6-v2, all-mpnet-base-v2, and text-embedding-3-small. Among the 4, text-embedding-ada-002 was able to perform the best (based on human judgement) and it also integrates smoothly alongside the vector store chosen.\n",
    "\n",
    "FAISS was our go-to choice because it efficiently handles nearest-neighbor searches in high-dimensional spaces, retrieves results quickly even from large collections, and keeps memory usage low through quantization. We have done research on other strategies such as Pinecone and Weaviate, but the ease of integration with FAISS utlimately helped us make our decision. Moreover, we have come across a lot of research in which FAISS was used, which proves its reliability.\n",
    "\n",
    "We built a custom embeddings class that works with both OpenAI and local HuggingFace models, so switching between them is seamless while using the same interface. This setup delivers fast, accurate semantic search results while reliably keeping the vector store locally.\n",
    "\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff0a3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: When was SUTD founded?\n",
      "\n",
      "embedding 1 items with model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20b1ffef2154c668965cc1c07171f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "SUTD was founded in July 2009 as Singapore's fourth publicly funded university. The university was officially inaugurated by President Tony Tan Keng Yam on May 7, 2012. SUTD's first academic year began in April 2012.\n",
      "Metadata: {'id': 0, 'relevance_score': np.float32(0.99925786), 'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'element_type': 'unknown', 'chunk_title': 'About SUTD', 'internal_urls': ['https://www.sutd.edu.sg/about/partnering-with-sutd/giving/'], 'pillar': 'General'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "SUTDs approach to Admissions is significantly different from most universities. Keep this in mind as you read through this, and please contact us if you have any questions.\n",
      "Metadata: {'id': 3, 'relevance_score': np.float32(0.9991303), 'title': 'SUTD Admission Requirements page', 'url': 'https://www.sutd.edu.sg/admissions/undergraduate/admission-requirements/overview', 'description': \"Outlines the academic and other requirements for admission to SUTD's undergraduate programs.\", 'element_type': 'unknown', 'chunk_title': 'Admission Requirements Overview', 'internal_urls': None, 'pillar': 'General'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "Get the latest updates about SUTD  from news and research to events and more.\n",
      "Metadata: {'id': 1, 'relevance_score': np.float32(0.99762857), 'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'element_type': 'unknown', 'chunk_title': 'Latest Happenings', 'internal_urls': None, 'pillar': 'General'}\n"
     ]
    }
   ],
   "source": [
    "# Execute a query against the vector store\n",
    "\n",
    "query = \"When was SUTD founded?\"\n",
    "\n",
    "# QUESTION: run the query against the vector store, print the top 5 search results\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points)---\n",
    "# TODO: manually add in when SUTD was founded to the dataset\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# use the query_index function to get the top k results\n",
    "response = compression_retriever.invoke(query)\n",
    "pretty_print_docs(response)\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ce000",
   "metadata": {},
   "source": [
    "## Huggingface Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0492e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "003e2cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# setting the device to cuda for faster inference\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f8d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f56d663f7064258aedff16086217f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3addd0cdcd47068e9ed6a41b8dc737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   3%|2         | 126M/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c212ca924c1840d29663e52fbf920407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   8%|7         | 115M/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\adity\\.cache\\huggingface\\hub\\models--meta-llama--Llama-3.2-3B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf9630b72ce4a1c813ea0e9a80d10ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d667493d574d0d9e798e53c571bb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "936991bd377b4044ac7ad5912ff5300e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589969829dc64f3583805746b0907c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690279e6401b4934a3f00527e0559fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.47 GiB is allocated by PyTorch, and 8.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BitsAndBytesConfig\n\u001b[32m     15\u001b[39m model_id = \u001b[33m\"\u001b[39m\u001b[33mmeta-llama/Llama-3.2-3B-Instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m pipeline = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m messages = [\n\u001b[32m     22\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33myou are a helpful instruct assistant.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     23\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: query}, \u001b[38;5;66;03m# adding the query here\u001b[39;00m\n\u001b[32m     24\u001b[39m ]\n\u001b[32m     26\u001b[39m outputs = pipe(messages, max_new_tokens=\u001b[32m256\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1180\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1178\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mprocessor\u001b[39m\u001b[33m\"\u001b[39m] = processor\n\u001b[32m-> \u001b[39m\u001b[32m1180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_generation.py:99\u001b[39m, in \u001b[36mTextGenerationPipeline.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_model_type(\n\u001b[32m    101\u001b[39m         TF_MODEL_FOR_CAUSAL_LM_MAPPING_NAMES \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m MODEL_FOR_CAUSAL_LM_MAPPING_NAMES\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mprefix\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._preprocess_params:\n\u001b[32m    104\u001b[39m         \u001b[38;5;66;03m# This is very specific. The logic is quite complex and needs to be done\u001b[39;00m\n\u001b[32m    105\u001b[39m         \u001b[38;5;66;03m# as a \"default\".\u001b[39;00m\n\u001b[32m    106\u001b[39m         \u001b[38;5;66;03m# It also defines both some preprocess_kwargs and generate_kwargs\u001b[39;00m\n\u001b[32m    107\u001b[39m         \u001b[38;5;66;03m# which is why we cannot put them in their respective methods.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:988\u001b[39m, in \u001b[36mPipeline.__init__\u001b[39m\u001b[34m(self, model, tokenizer, feature_extractor, image_processor, processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[39m\n\u001b[32m    981\u001b[39m \u001b[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    983\u001b[39m     \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    984\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.device != \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m    985\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.device, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device < \u001b[32m0\u001b[39m)\n\u001b[32m    986\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m hf_device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    987\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m988\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[38;5;66;03m# If the model can generate:\u001b[39;00m\n\u001b[32m    991\u001b[39m \u001b[38;5;66;03m# 1 - create a local generation config. This is done to avoid side-effects on the model as we apply local\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[38;5;66;03m# tweaks to the generation config.\u001b[39;00m\n\u001b[32m    993\u001b[39m \u001b[38;5;66;03m# 2 - load the assistant model if it is passed.\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;28mself\u001b[39m.assistant_model, \u001b[38;5;28mself\u001b[39m.assistant_tokenizer = load_assistant_model(\n\u001b[32m    995\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33massistant_model\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33massistant_tokenizer\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    996\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3712\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3707\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   3708\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   3709\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3710\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3711\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3712\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1343\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1340\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1341\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[31m[... skipping similar frames: Module._apply at line 903 (2 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:903\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:930\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    926\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    931\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    933\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1329\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1323\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1324\u001b[39m             device,\n\u001b[32m   1325\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1326\u001b[39m             non_blocking,\n\u001b[32m   1327\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1328\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.47 GiB is allocated by PyTorch, and 8.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# QUESTION: Use the Huggingface transformers library to load the Llama 3.2-3B instruct model\n",
    "# https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct\n",
    "# Run the model locally. You do not have to use cloud-based APIs.\n",
    "\n",
    "# Execute the below query against the model and let it it answer from it's internal memory\n",
    "\n",
    "query = \"What courses are available in SUTD?\"\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\", model=model_id, device = device \n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"you are a helpful instruct assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": query}, # adding the query here\n",
    "]\n",
    "\n",
    "outputs = pipe(messages, max_new_tokens=256)\n",
    "print(\"model response:\")\n",
    "print(outputs[0][\"generated_text\"])\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36af8f0a-45d0-404e-a1e9-8e16af4a158a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "models is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://huggingface.co/models/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:961\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1068\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1596\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1593\u001b[39m ):\n\u001b[32m   1594\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1595\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1401\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1401\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:285\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m response = get_session().request(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 404 Client Error. (Request ID: Root=1-67f0f2e3-1a8097af63d7f8cf190c4664;072f8c5f-99ec-43ce-adf5-9f7187c2f25b)\n\nRepository Not Found for url: https://huggingface.co/models/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     17\u001b[39m     MODEL_DIR,\n\u001b[32m     18\u001b[39m     torch_dtype=torch.float16,  \u001b[38;5;66;03m# using float16 for faster inference\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     low_cpu_mem_usage=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m pipeline = pipeline(\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer, max_new_tokens=\u001b[32m256\u001b[39m \u001b[38;5;66;03m# setting max_new_tokens to 512 to be able to run on my GPU\u001b[39;00m\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:910\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m    909\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m    912\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:742\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    739\u001b[39m     token = use_auth_token\n\u001b[32m    741\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    759\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    209\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    210\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    211\u001b[39m     **kwargs,\n\u001b[32m    212\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    213\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\utils\\hub.py:456\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    457\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[32m    463\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    464\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: models is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# QUESTION: Now put everything together. Use langchain to integrate your vector store and Llama model into a RAG system\n",
    "# Run the below example question against your RAG system.\n",
    "\n",
    "# Example questions\n",
    "# TODO: what does this mean?\n",
    "query = \"How can I increase my chances of admission into SUTD?\"\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# instantiate the pipeline without overwriting the function name\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model_id, device=device\n",
    ")\n",
    "\n",
    "# create your HuggingFacePipeline wrapper with the pipeline\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,  # ensure compression_retriever is defined in your code\n",
    "    chain_type_kwargs={\"prompt\": RAG_PROMPT},  # pass the custom prompt here\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query = \"How can I increase my chances of admission into SUTD?\"\n",
    "result = rag_chain.run(query)\n",
    "print(\"RAG Chain Response:\")\n",
    "print(result)\n",
    "#------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30ce26-8a19-4492-91e3-1cea5f750d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: Below is set of test questions. Add another 10 test questions based on your user interviews and your value proposition canvas.\n",
    "# Run the complete set of test questions against the RAG question answering system.\n",
    "\n",
    "questions = [\"What are the admissions deadlines for SUTD?\",\n",
    "             \"Is there financial aid available?\",\n",
    "             \"What is the minimum score for the Mother Tongue Language?\",\n",
    "             \"Do I require reference letters?\",\n",
    "             \"Can polytechnic diploma students apply?\",\n",
    "             \"Do I need SAT score?\",\n",
    "             \"How many PhD students does SUTD have?\",\n",
    "             \"How much are the tuition fees for Singaporeans?\",\n",
    "             \"How much are the tuition fees for international students?\",\n",
    "             \"Is there a minimum CAP?\"\n",
    "             ]\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
    "additional_questions = [\n",
    "    \"What is SUTDs mission and vision?\",\n",
    "    \"When was SUTD officially inaugurated?\",\n",
    "    \"Which core values does SUTD emphasize?\",\n",
    "    \"Where is SUTD located, and how can it be contacted?\",\n",
    "    \"What different SUTD offices or departments can I reach out to?\",\n",
    "    \"What are the key components of the Freshmore curriculum at SUTD?\",\n",
    "    \"Which elective modules are available for Freshmore students in Term 3?\",\n",
    "    \"What courses are offered within the Design and Artificial Intelligence pillar?\",\n",
    "    \"Who are some of the instructors teaching the courses in the DAI program?\",\n",
    "    \"What are the main steps involved in the SUTD application process?\"\n",
    "]\n",
    "\n",
    "all_questions = questions + additional_questions\n",
    "results = []\n",
    "\n",
    "for question in all_questions:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Question: \" + question)\n",
    "    # run the rag chain\n",
    "    result = rag_chain.run(question)\n",
    "    print(\"Response:\")\n",
    "    print(result)\n",
    "    print(\"----------------------------------------------------------------\\n\")\n",
    "    results.append({\n",
    "        \"query\": question,\n",
    "        \"response\": result\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"results.csv\", index=False)\n",
    "print(\"File Saved: results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fd068",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "\n",
    "\n",
    "Manually inspect each answer, fact check whether the answer is correct (use Google or any other method) and check the retrieved documents\n",
    "\n",
    "For each question, answer and context triple, record the following\n",
    "\n",
    "- How accurate is the answer (1-5, 5 best)?\n",
    "- How relevant is the retrieved context (1-5, 5 best)?\n",
    "- How grounded is the answer in the retrieved context (instead of relying on the LLM's internal knowledge) (1-5, 5 best)?\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (20 points) ---**\n",
    "\n",
    "\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67543217",
   "metadata": {},
   "source": [
    "You can try improve the chatbot by going back to previous steps in the notebook and change things until the submission deadline. For example, you can add more data sources, change the embedding models, change the data pre-processing, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3789e17-3fea-495d-a843-85f4b752812b",
   "metadata": {},
   "source": [
    "# End\n",
    "\n",
    "This concludes assignment 3.\n",
    "\n",
    "Please submit this notebook with your answers and the generated output cells as a **Jupyter notebook file** via github.\n",
    "\n",
    "\n",
    "Every group member should do the following submission steps:\n",
    "1. Create a private github repository **sutd_5055mlop** under your github user.\n",
    "2. Add your instructors as collaborator: ddahlmeier and lucainiaoge\n",
    "3. Save your submission as assignment_03_GROUP_NAME.ipynb where GROUP_NAME is the name of the group you have registered. \n",
    "4. Push the submission files to your repo \n",
    "5. Submit the link to the repo via eDimensions\n",
    "\n",
    "\n",
    "\n",
    "**Assignment due 6 April 2025 11:59pm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ad52c-8a4a-49be-bb75-17eaa4830706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
