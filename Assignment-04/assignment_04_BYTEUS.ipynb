{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f99a8a55",
      "metadata": {
        "id": "f99a8a55"
      },
      "source": [
        "# Group Project / Assignment 4: Instruction finetuning a Llama-3.2 model\n",
        "**Assignment due 21 April 11:59pm**\n",
        "\n",
        "Welcome to the fourth and final assignment for 50.055 Machine Learning Operations. The third and fourth assignment together form the course group project. You will continue the work on a chatbot which can answer questions about SUTD to prospective students.\n",
        "\n",
        "\n",
        "**This assignment is a group assignment.**\n",
        "\n",
        "- Read the instructions in this notebook carefully\n",
        "- Add your solution code and answers in the appropriate places. The questions are marked as **QUESTION:**, the places where you need to add your code and text answers are marked as **ADD YOUR SOLUTION HERE**. The assignment is more open-ended than previous assignments, i.e. you have more freedom how to solve the problem and how to structure your code.\n",
        "- The completed notebook, including your added code and generated output will be your submission for the assignment.\n",
        "- The notebook should execute without errors from start to finish when you select \"Restart Kernel and Run All Cells..\". Please test this before submission.\n",
        "- Use the SUTD Education Cluster to solve and test the assignment. If you work on another environment, minimally test your work on the SUTD Education Cluster.\n",
        "\n",
        "**Rubric for assessment**\n",
        "\n",
        "Your submission will be graded using the following criteria.\n",
        "1. Code executes: your code should execute without errors. The SUTD Education cluster should be used to ensure the same execution environment.\n",
        "2. Correctness: the code should produce the correct result or the text answer should state the factual correct answer.\n",
        "3. Style: your code should be written in a way that is clean and efficient. Your text answers should be relevant, concise and easy to understand.\n",
        "4. Partial marks will be awarded for partially correct solutions.\n",
        "5. Creativity and innovation: in this assignment you have more freedom to design your solution, compared to the first assignments. You can show of your creativity and innovative mindset.\n",
        "6. There is a maximum of 310 points for this assignment.\n",
        "\n",
        "**ChatGPT policy**\n",
        "\n",
        "If you use AI tools, such as ChatGPT, to solve the assignment questions, you need to be transparent about its use and mark AI-generated content as such. In particular, you should include the following in addition to your final answer:\n",
        "- A copy or screenshot of the prompt you used\n",
        "- The name of the AI model\n",
        "- The AI generated output\n",
        "- An explanation why the answer is correct or what you had to change to arrive at the correct answer\n",
        "\n",
        "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission Instructions are located at the bottom of the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae5e449",
      "metadata": {
        "id": "dae5e449"
      },
      "source": [
        "### Finetuning LLMs\n",
        "\n",
        "The goal of the assignment is to build a more advanced chatbot that can talk to prospective students and answer questions about SUTD.\n",
        "\n",
        "We will finetune a smaller 1B LLM on question-answer pairs which we synthetically generate. Then we will compare the finetuned and non-finetuned LLMs with and without RAG to see if we were able to improve the SUTD chatbot answer quality.\n",
        "\n",
        "We'll be leveraging `langchain`, `llama 3.2` and `Google AI STudio with Gemini 2.0`.\n",
        "\n",
        "Check out the docs:\n",
        "- [LangChain](https://docs.langchain.com/docs/)\n",
        "- [Llama 3.2](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/)\n",
        "- [Google AI Studio](https://aistudio.google.com/)\n",
        "\n",
        "Note: Google AI Studio provides a lot of free tokens but has certain rate limits. Write your code in a way that it can handle these limits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62530070",
      "metadata": {
        "id": "62530070"
      },
      "source": [
        "# Install dependencies\n",
        "Use pip to install all required dependencies of this assignment in the cell below. Make sure to test this on the SUTD cluster as different environments have different software pre-installed.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4ec75011-c8ef-4c31-9766-2e3e9834684f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ec75011-c8ef-4c31-9766-2e3e9834684f",
        "outputId": "36bffa71-6521-404d-a48e-29850a7208d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl.metadata (28 kB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch) (4.13.2)\n",
            "Collecting networkx (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting sympy==1.13.1 (from torch)\n",
            "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
            "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting numpy (from torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Using cached https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
            "Using cached https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl (2728.9 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-win_amd64.whl (5.3 MB)\n",
            "Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-win_amd64.whl (4.1 MB)\n",
            "Using cached https://download.pytorch.org/whl/pillow-11.0.0-cp311-cp311-win_amd64.whl (2.6 MB)\n",
            "Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Using cached https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Using cached https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Using cached https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Using cached https://download.pytorch.org/whl/numpy-2.1.2-cp311-cp311-win_amd64.whl (12.9 MB)\n",
            "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.0.0 sympy-1.13.1 torch-2.6.0+cu118 torchaudio-2.6.0+cu118 torchvision-0.21.0+cu118\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers) (3.13.1)\n",
            "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
            "  Using cached huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
            "Collecting pyyaml>=5.1 (from transformers)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers)\n",
            "  Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
            "Collecting requests (from transformers)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers)\n",
            "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->transformers)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "Using cached huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
            "Using cached regex-2024.11.6-cp311-cp311-win_amd64.whl (274 kB)\n",
            "Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
            "Using cached tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Using cached charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Installing collected packages: urllib3, tqdm, safetensors, regex, pyyaml, idna, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
            "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 huggingface-hub-0.30.2 idna-3.10 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.51.3 urllib3-2.4.0\n",
            "Collecting datasets\n",
            "  Using cached datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets) (2.1.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Using cached pyarrow-19.0.1-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pandas (from datasets)\n",
            "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->datasets)\n",
            "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Using cached frozenlist-1.6.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Using cached multidict-6.4.3-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
            "  Using cached propcache-0.3.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
            "  Using cached yarl-1.20.0-cp311-cp311-win_amd64.whl.metadata (74 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->datasets)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl (443 kB)\n",
            "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Using cached pyarrow-19.0.1-cp311-cp311-win_amd64.whl (25.3 MB)\n",
            "Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
            "Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Using cached frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
            "Using cached multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
            "Using cached propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
            "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, frozenlist, dill, attrs, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 attrs-25.3.0 datasets-3.5.0 dill-0.3.8 frozenlist-1.6.0 multidict-6.4.3 multiprocess-0.70.16 pandas-2.2.3 propcache-0.3.1 pyarrow-19.0.1 pytz-2025.2 tzdata-2025.2 xxhash-3.5.0 yarl-1.20.0\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (2.6.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Using cached accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-1.6.0\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-core\n",
            "  Using cached langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-community\n",
            "  Using cached langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-experimental\n",
            "  Using cached langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Using cached langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain_openai\n",
            "  Using cached langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
            "  Using cached langsmith-0.3.32-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
            "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Using cached sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core)\n",
            "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting packaging<25,>=23.2 (from langchain-core)\n",
            "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from langchain-core) (4.13.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from langchain-community) (3.11.18)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from langchain-community) (2.1.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting openai<2.0.0,>=1.68.2 (from langchain_openai)\n",
            "  Using cached openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Using cached tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting proto-plus<2.0.0,>=1.22.3 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Using cached orjson-3.10.16-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
            "  Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
            "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
            "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
            "  Using cached jiter-0.9.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
            "Collecting sniffio (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached pydantic_core-2.33.1-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
            "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Using cached greenlet-3.2.0-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached grpcio-1.72.0rc1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached grpcio_status-1.72.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
            "  Using cached httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Downloading protobuf-6.31.0rc1-cp310-abi3-win_amd64.whl.metadata (596 bytes)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Using cached langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
            "Using cached langchain_core-0.3.54-py3-none-any.whl (433 kB)\n",
            "Using cached langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "Using cached langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "Using cached langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "Using cached langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Using cached google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
            "Using cached langsmith-0.3.32-py3-none-any.whl (358 kB)\n",
            "Using cached openai-1.75.0-py3-none-any.whl (646 kB)\n",
            "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
            "Using cached pydantic_core-2.33.1-cp311-cp311-win_amd64.whl (2.0 MB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "Using cached sqlalchemy-2.0.40-cp311-cp311-win_amd64.whl (2.1 MB)\n",
            "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Using cached tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached google_api_core-2.24.2-py3-none-any.whl (160 kB)\n",
            "Using cached google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "Using cached greenlet-3.2.0-cp311-cp311-win_amd64.whl (295 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
            "Using cached jiter-0.9.0-cp311-cp311-win_amd64.whl (210 kB)\n",
            "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "Using cached orjson-3.10.16-cp311-cp311-win_amd64.whl (133 kB)\n",
            "Using cached proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
            "Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
            "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
            "Using cached zstandard-0.23.0-cp311-cp311-win_amd64.whl (495 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
            "Using cached grpcio-1.72.0rc1-cp311-cp311-win_amd64.whl (4.3 MB)\n",
            "Using cached grpcio_status-1.72.0rc1-py3-none-any.whl (14 kB)\n",
            "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: filetype, zstandard, typing-inspection, tenacity, sniffio, python-dotenv, pydantic-core, pyasn1, protobuf, packaging, orjson, mypy-extensions, jsonpointer, jiter, httpx-sse, h11, grpcio, greenlet, distro, cachetools, annotated-types, typing-inspect, tiktoken, SQLAlchemy, rsa, requests-toolbelt, pydantic, pyasn1-modules, proto-plus, marshmallow, jsonpatch, httpcore, googleapis-common-protos, anyio, pydantic-settings, httpx, grpcio-status, google-auth, dataclasses-json, openai, langsmith, google-api-core, langchain-core, langchain-text-splitters, langchain_openai, google-ai-generativelanguage, langchain-google-genai, langchain, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "Successfully installed SQLAlchemy-2.0.40 annotated-types-0.7.0 anyio-4.9.0 cachetools-5.5.2 dataclasses-json-0.6.7 distro-1.9.0 filetype-1.2.0 google-ai-generativelanguage-0.6.17 google-api-core-2.24.2 google-auth-2.39.0 googleapis-common-protos-1.70.0 greenlet-3.2.0 grpcio-1.72.0rc1 grpcio-status-1.72.0rc1 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 httpx-sse-0.4.0 jiter-0.9.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.54 langchain-experimental-0.3.4 langchain-google-genai-2.1.3 langchain-text-splitters-0.3.8 langchain_openai-0.3.14 langsmith-0.3.32 marshmallow-3.26.1 mypy-extensions-1.0.0 openai-1.75.0 orjson-3.10.16 packaging-24.2 proto-plus-1.26.1 protobuf-6.30.2 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.3 pydantic-core-2.33.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 requests-toolbelt-1.0.0 rsa-4.9.1 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 typing-inspect-0.9.0 typing-inspection-0.4.0 zstandard-0.23.0\n",
            "Collecting google-generativeai\n",
            "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
            "Collecting google-api-python-client (from google-generativeai)\n",
            "  Using cached google_api_python_client-2.167.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-generativeai) (2.39.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-generativeai) (6.30.2)\n",
            "Requirement already satisfied: pydantic in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-generativeai) (2.11.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Collecting protobuf (from google-generativeai)\n",
            "  Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
            "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
            "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
            "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.0rc1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.72.0rc1)\n",
            "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
            "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
            "  Using cached grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Using cached google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
            "Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Using cached protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
            "Using cached google_api_python_client-2.167.0-py2.py3-none-any.whl (13.2 MB)\n",
            "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Using cached grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
            "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Installing collected packages: uritemplate, pyparsing, protobuf, httplib2, grpcio-status, google-auth-httplib2, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 6.30.2\n",
            "    Uninstalling protobuf-6.30.2:\n",
            "      Successfully uninstalled protobuf-6.30.2\n",
            "  Attempting uninstall: grpcio-status\n",
            "    Found existing installation: grpcio-status 1.72.0rc1\n",
            "    Uninstalling grpcio-status-1.72.0rc1:\n",
            "      Successfully uninstalled grpcio-status-1.72.0rc1\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.17\n",
            "    Uninstalling google-ai-generativelanguage-0.6.17:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.17\n",
            "Successfully installed google-ai-generativelanguage-0.6.15 google-api-python-client-2.167.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 grpcio-status-1.71.0 httplib2-0.22.0 protobuf-5.29.4 pyparsing-3.2.3 uritemplate-4.1.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.3 requires google-ai-generativelanguage<0.7.0,>=0.6.16, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flashrank\n",
            "  Using cached FlashRank-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tokenizers in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from flashrank) (0.21.1)\n",
            "Collecting onnxruntime (from flashrank)\n",
            "  Using cached onnxruntime-1.21.1-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from flashrank) (2.1.2)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from flashrank) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from flashrank) (4.67.1)\n",
            "Collecting coloredlogs (from onnxruntime->flashrank)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime->flashrank)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: packaging in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from onnxruntime->flashrank) (24.2)\n",
            "Requirement already satisfied: protobuf in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from onnxruntime->flashrank) (5.29.4)\n",
            "Requirement already satisfied: sympy in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from onnxruntime->flashrank) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->flashrank) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->flashrank) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->flashrank) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->flashrank) (2025.1.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tokenizers->flashrank) (0.30.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm->flashrank) (0.4.6)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (2024.6.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (4.13.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->flashrank)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sympy->onnxruntime->flashrank) (1.3.0)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime->flashrank)\n",
            "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Using cached FlashRank-0.2.10-py3-none-any.whl (14 kB)\n",
            "Using cached onnxruntime-1.21.1-cp311-cp311-win_amd64.whl (12.3 MB)\n",
            "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: flatbuffers, pyreadline3, humanfriendly, coloredlogs, onnxruntime, flashrank\n",
            "Successfully installed coloredlogs-15.0.1 flashrank-0.2.10 flatbuffers-25.2.10 humanfriendly-10.0 onnxruntime-1.21.1 pyreadline3-3.5.4\n",
            "Requirement already satisfied: openai in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (1.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sentence-transformers) (2.6.0+cu118)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
            "Collecting scipy (from sentence-transformers)\n",
            "  Using cached scipy-1.15.2-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
            "Using cached scipy-1.15.2-cp311-cp311-win_amd64.whl (41.2 MB)\n",
            "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence-transformers\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 sentence-transformers-4.1.0 threadpoolctl-3.6.0\n",
            "Collecting dotenv\n",
            "  Using cached dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from dotenv) (1.1.0)\n",
            "Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: dotenv\n",
            "Successfully installed dotenv-0.9.9\n",
            "Requirement already satisfied: pydantic in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (2.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic) (0.4.0)\n",
            "Collecting unsloth\n",
            "  Using cached unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n",
            "Collecting unsloth_zoo>=2025.3.17 (from unsloth)\n",
            "  Using cached unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (2.6.0+cu118)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Using cached xformers-0.0.29.post3-cp311-cp311-win_amd64.whl.metadata (1.0 kB)\n",
            "Collecting bitsandbytes (from unsloth)\n",
            "  Using cached bitsandbytes-0.45.5-py3-none-win_amd64.whl.metadata (5.1 kB)\n",
            "Collecting triton-windows (from unsloth)\n",
            "  Using cached triton_windows-3.2.0.post18-cp311-cp311-win_amd64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (24.2)\n",
            "Collecting tyro (from unsloth)\n",
            "  Using cached tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (4.51.3)\n",
            "Requirement already satisfied: datasets>=2.16.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (3.5.0)\n",
            "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
            "  Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (7.0.0)\n",
            "Collecting wheel>=0.42.0 (from unsloth)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (2.1.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (1.6.0)\n",
            "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n",
            "  Using cached trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
            "  Using cached peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting protobuf<4.0.0 (from unsloth)\n",
            "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (0.30.2)\n",
            "Collecting hf_transfer (from unsloth)\n",
            "  Using cached hf_transfer-0.1.9-cp38-abi3-win_amd64.whl.metadata (1.8 kB)\n",
            "Collecting diffusers (from unsloth)\n",
            "  Using cached diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torchvision in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth) (0.21.0+cu118)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.16.0->unsloth) (3.11.18)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub->unsloth) (4.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.4.0->unsloth) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm->unsloth) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.1)\n",
            "Collecting rich (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth)\n",
            "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth)\n",
            "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from unsloth_zoo>=2025.3.17->unsloth) (11.0.0)\n",
            "Collecting importlib-metadata (from diffusers->unsloth)\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
            "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Using cached shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
            "  Using cached typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\n",
            "Collecting zipp>=3.20 (from importlib-metadata->diffusers->unsloth)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n",
            "Using cached unsloth-2025.3.19-py3-none-any.whl (192 kB)\n",
            "Using cached peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "Using cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
            "Using cached trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "Using cached unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Using cached xformers-0.0.29.post3-cp311-cp311-win_amd64.whl (167.7 MB)\n",
            "Using cached bitsandbytes-0.45.5-py3-none-win_amd64.whl (75.4 MB)\n",
            "Using cached diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
            "Using cached hf_transfer-0.1.9-cp38-abi3-win_amd64.whl (1.2 MB)\n",
            "Using cached triton_windows-3.2.0.post18-cp311-cp311-win_amd64.whl (40.0 MB)\n",
            "Using cached tyro-0.9.19-py3-none-any.whl (124 kB)\n",
            "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Using cached shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Using cached typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
            "Using cached cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: triton-windows, sentencepiece, zipp, wheel, typeguard, shtab, protobuf, mdurl, hf_transfer, docstring-parser, markdown-it-py, importlib-metadata, xformers, rich, diffusers, cut_cross_entropy, bitsandbytes, tyro, trl, peft, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "Successfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 diffusers-0.33.1 docstring-parser-0.16 hf_transfer-0.1.9 importlib-metadata-8.6.1 markdown-it-py-3.0.0 mdurl-0.1.2 peft-0.15.2 protobuf-3.20.3 rich-14.0.0 sentencepiece-0.2.0 shtab-1.7.2 triton-windows-3.2.0.post18 trl-0.15.2 typeguard-4.4.2 tyro-0.9.19 unsloth-2025.3.19 unsloth_zoo-2025.3.17 wheel-0.45.1 xformers-0.0.29.post3 zipp-3.21.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "langchain-google-genai 2.1.3 requires google-ai-generativelanguage<0.7.0,>=0.6.16, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (1.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (2.6.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Requirement already satisfied: peft in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (0.15.2)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (2.6.0+cu118)\n",
            "Requirement already satisfied: transformers in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (1.6.0)\n",
            "Requirement already satisfied: safetensors in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from peft) (0.30.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.1.31)\n",
            "Found existing installation: trl 0.15.2\n",
            "Uninstalling trl-0.15.2:\n",
            "  Successfully uninstalled trl-0.15.2\n",
            "Collecting trl<0.15.0\n",
            "  Downloading trl-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading trl-0.14.0-py3-none-any.whl (313 kB)\n",
            "Installing collected packages: trl\n",
            "Successfully installed trl-0.14.0\n",
            "Requirement already satisfied: bitsandbytes in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from bitsandbytes) (2.6.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from bitsandbytes) (2.1.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (2.1.5)\n",
            "Collecting faiss-cpu\n",
            "  Using cached faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from faiss-cpu) (2.1.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from faiss-cpu) (24.2)\n",
            "Using cached faiss_cpu-1.10.0-cp311-cp311-win_amd64.whl (13.7 MB)\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n",
            "Collecting gradio\n",
            "  Using cached gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Using cached aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Using cached ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Using cached gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Using cached groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Using cached ruff-0.11.6-py3-none-win_amd64.whl.metadata (26 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Using cached safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Using cached tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Using cached uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from gradio-client==1.8.0->gradio) (2024.6.1)\n",
            "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
            "  Using cached websockets-15.0.1-cp311-cp311-win_amd64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Using cached gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "Using cached gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "Using cached aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "Using cached groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Using cached ruff-0.11.6-py3-none-win_amd64.whl (11.6 MB)\n",
            "Using cached safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "Using cached tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Using cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "Using cached uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "Using cached ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached websockets-15.0.1-cp311-cp311-win_amd64.whl (176 kB)\n",
            "Installing collected packages: pydub, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, groovy, ffmpy, click, aiofiles, uvicorn, starlette, typer, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 click-8.1.8 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.2 tomlkit-0.13.2 typer-0.15.2 uvicorn-0.34.2 websockets-15.0.1\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Collecting evaluate\n",
            "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (2.1.2)\n",
            "Requirement already satisfied: dill in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (0.30.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (3.11.18)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from tqdm>=4.62.1->evaluate) (0.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Using cached contourpy-1.3.2-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Using cached fonttools-4.57.0-cp311-cp311-win_amd64.whl.metadata (104 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from matplotlib) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\adity\\desktop\\sutd_5055mlop\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Using cached matplotlib-3.10.1-cp311-cp311-win_amd64.whl (8.1 MB)\n",
            "Using cached contourpy-1.3.2-cp311-cp311-win_amd64.whl (222 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Using cached fonttools-4.57.0-cp311-cp311-win_amd64.whl (2.2 MB)\n",
            "Using cached kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
            "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Install and import all required packages\n",
        "# The rest of your code should execute without any import or dependency errors.\n",
        "\n",
        "# **--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install huggingface_hub\n",
        "!pip install langchain langchain-core langchain-community langchain-experimental langchain-google-genai langchain_openai\n",
        "!pip install google-generativeai\n",
        "!pip install flashrank\n",
        "!pip install openai\n",
        "!pip install sentence-transformers\n",
        "!pip install dotenv\n",
        "!pip install pydantic\n",
        "!pip install unsloth\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip uninstall trl -y && pip install --no-cache-dir --force-reinstall --no-deps \"trl<0.15.0\"\n",
        "!pip install bitsandbytes\n",
        "!pip install faiss-cpu\n",
        "!pip install gradio\n",
        "!pip install scikit-learn\n",
        "!pip install evaluate\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3be3b4",
      "metadata": {
        "id": "6d3be3b4"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "63c2c528",
      "metadata": {
        "id": "63c2c528"
      },
      "outputs": [],
      "source": [
        "\n",
        "# finetuning imports\n",
        "import unsloth\n",
        "from dotenv import load_dotenv\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# TODO: check the difference between ChatGoogleGenerativeAI and GoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "from transformers import pipeline, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth import to_sharegpt, standardize_sharegpt\n",
        "from peft import PeftModel\n",
        "from typing import List, Dict, Literal\n",
        "import os\n",
        "from pydantic import BaseModel\n",
        "import time\n",
        "import json\n",
        "import torch, gc\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "#evaluate imports\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import evaluate\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# rag imports\n",
        "from openai import OpenAI\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from flashrank import Ranker, RerankRequest\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import FlashrankRerank\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import gradio as gr\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "GOOGLE_GENAI_API_KEY = os.getenv(\"GOOGLE_GENAI_API_KEY\")\n",
        "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "USERNAME = os.getenv(\"HUGGINGFACE_USERNAME\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# rag imports\n",
        "MARKDOWN_PATH = \"data/markdown/markdown_data.json\"\n",
        "HTML_PATH = \"data/html/html_data.json\"\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "TOP_K = 5\n",
        "OUTPUT_DIR = \"vector_store\"\n",
        "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "MODEL_DIR = \"models\"\n",
        "JSON_PATH = \"data/data.json\"\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "login(token=HUGGINGFACE_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563304ec",
      "metadata": {
        "id": "563304ec"
      },
      "source": [
        "# Generate training data\n",
        "The first step of the assignment is generating synthetic question-answer pairs which can be used for finetuning an LLM model.\n",
        "Use the Google AI studio with the Gemini models to create -high-quality QA training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6fe166d-5ef6-4da9-995e-54afffc683c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6fe166d-5ef6-4da9-995e-54afffc683c1",
        "outputId": "183b8e2b-7ff0-48dc-9d1c-61bea1dded6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'orange']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'orange']\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Use langchain and the Google AI Studio APIs and a model from the Gemini 2.0 family\n",
        "# to create a text-generation chain that can produce and parse JSON output.\n",
        "# Test it by having the LLM generate a JSON array of 3 fruits\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "# we are creating synthetic data that contains only questions and responses but not on multiple tasks, because this is a chatbot application\n",
        "model = ChatGoogleGenerativeAI(google_api_key=GOOGLE_GENAI_API_KEY, model=\"gemini-2.0-flash\", temperature=0.2, convert_system_message_to_human=True)\n",
        "parser = JsonOutputParser()\n",
        "input_prompt = \"Generate a JSON array containing exactly 3 fruit names.\"\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "    You are a helpful assistant that generates structured JSON data.\n",
        "    Your response should ONLY contain valid JSON without any additional text.\n",
        "    Do not include explanation, notes, or markdown formatting.\n",
        "    \"\"\"),\n",
        "    (\"human\", \"{input_text}\")\n",
        "])\n",
        "chain = ( prompt | model | parser )\n",
        "response = chain.invoke({\"input_text\": input_prompt})\n",
        "print(response)\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "# imo there is a better way to do this which is using pydantic and langchain\n",
        "class FruitList(BaseModel):\n",
        "    fruits: List[str] = Field(description=\"A list of fruit objects\", min_length=3, max_length=3)\n",
        "\n",
        "pydantic_parser = JsonOutputParser(pydantic_object=FruitList)\n",
        "prompt = PromptTemplate(\n",
        "    template  = \"Answer the user's question.\\n\\n{format_instructions}\\n\\n{input}\",\n",
        "    input_variables = [\"input\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "chain = ( prompt | model | pydantic_parser )\n",
        "response = chain.invoke({\"input\": input_prompt})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8edaed2",
      "metadata": {
        "id": "f8edaed2"
      },
      "source": [
        "## Generate topics\n",
        "When generating data, it is often helpful to guide the generation process through some hierachical structure.\n",
        "Before we create question-answer pairs, let's generate some topics which the questions should be about.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ee57ba-d3e2-45bd-9bc6-c7eeb354b926",
      "metadata": {
        "id": "45ee57ba-d3e2-45bd-9bc6-c7eeb354b926"
      },
      "outputs": [],
      "source": [
        "# QUESTION: Create a function 'generate_topics' which generates topics which prospective students might care about.\n",
        "#\n",
        "# Generate a list of 20 topics\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "def generate_topics(num = 20):\n",
        "    class TopicsList(BaseModel):\n",
        "        topics: List[str] = Field(description=f\"A list of {num} topics that prospective students might care about\", min_length=num, max_length=num)\n",
        "\n",
        "    # if the file already exists don't run instead return the topics from the file\n",
        "    output_dir = \"data\"\n",
        "\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filename = f\"data/topics.json\"\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        google_api_key=GOOGLE_GENAI_API_KEY,\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        temperature=0.8, # using this value for more diverse topics\n",
        "        convert_system_message_to_human=True #the system message is reformatted or converted into a style that resembles the way a human would pose a question or comment\n",
        "    )\n",
        "\n",
        "    pydantic_parser = JsonOutputParser(pydantic_object=TopicsList)\n",
        "    pydantic_parser = JsonOutputParser(pydantic_object=TopicsList)\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        template=(\n",
        "            \"List out topics a prospective student might be interested in when \"\n",
        "            \"Think of real concerns such as academic quality, campus life, tuition, \"\n",
        "            \"social environment, and career opportunities.\\n\\n\"\n",
        "            \"{format_instructions}\\n\\n\"\n",
        "            \"{input}\"\n",
        "        ),\n",
        "        input_variables=[\"input\"],\n",
        "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        "    )\n",
        "    input_prompt = (\n",
        "        f\"Please list exactly {num} topics that capture what prospective students care about \"\n",
        "        \"when choosing a university like SUTD.\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | model | parser\n",
        "    response = chain.invoke({\"input\": input_prompt})\n",
        "\n",
        "    topics = response[\"topics\"]\n",
        "\n",
        "    # save to disk otherwise\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(topics, file)\n",
        "\n",
        "    return topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7787247",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7787247",
        "outputId": "1e0e19da-8f6a-440d-b757-89bc80b42e68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 3 topics that prospective students might care about' min_length=3 max_length=3 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Academic Rigor and Curriculum', 'Career Prospects and Industry Connections', 'Campus Culture and Student Life']\n"
          ]
        }
      ],
      "source": [
        "# test topic generation\n",
        "print(generate_topics(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7efb98-7b40-4230-9eda-f344b4d4e4a7",
      "metadata": {
        "id": "cc7efb98-7b40-4230-9eda-f344b4d4e4a7",
        "outputId": "38c8f526-83b9-4833-a259-193b2cf15099"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 20 topics that prospective students might care about' min_length=20 max_length=20 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Academic Reputation and Ranking', 'Specific Program Strengths (e.g., Engineering, Design)', 'Faculty Expertise and Research Opportunities', 'Hands-on Learning and Project-Based Curriculum', 'Internship Opportunities and Industry Connections', 'Career Services and Graduate Employment Rate', 'Tuition Fees and Financial Aid Options', 'Scholarship Availability and Eligibility Criteria', 'Cost of Living in Singapore', 'Accommodation Options (on-campus and off-campus)', 'Campus Facilities and Resources (labs, library, maker spaces)', 'Student-Faculty Ratio and Class Sizes', 'Student Support Services (academic advising, counseling)', 'Campus Culture and Student Life', 'Diversity and Inclusion Initiatives', 'Extracurricular Activities and Clubs', 'Location and Accessibility of the University', 'Opportunities for International Exchange Programs', 'Networking Opportunities with Alumni', 'Safety and Security on Campus']\n"
          ]
        }
      ],
      "source": [
        "# Generate a list of 20 topics\n",
        "# We save a copy to disk and reload it from there if the file exists\n",
        "\n",
        "# the function to generate topics and saves it to disk as topics_20.json\n",
        "print(generate_topics(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f48c4b4e",
      "metadata": {
        "id": "f48c4b4e"
      },
      "source": [
        "## Generate questions\n",
        "Now generate a set of questions about each topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85706c9c-593d-459c-b86e-4011500cff05",
      "metadata": {
        "id": "85706c9c-593d-459c-b86e-4011500cff05"
      },
      "outputs": [],
      "source": [
        "# QUESTION: Create a function 'generate_questions' which generates quetions about a given topic.\n",
        "# Generate a list of 10 questions per topics. In total you should have 200 questions.\n",
        "#\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "# TODO: rememeber to add timeout to the function\n",
        "def generate_questions(topic, num=10):\n",
        "    output_dir = \"data\"\n",
        "\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        google_api_key=GOOGLE_GENAI_API_KEY,\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        temperature=0.4, # hyperparameter can be changed\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "\n",
        "    class Questions(BaseModel):\n",
        "        questions: List[str] = Field(\n",
        "            description=f\"A list of {num} questions about a specific topic\",\n",
        "            min_length=num,\n",
        "            max_length=num\n",
        "        )\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=Questions)\n",
        "\n",
        "    # i think the best thing is to avoid specifics to the university to avoid confusion\n",
        "    prompt = PromptTemplate(\n",
        "        template=(\n",
        "            \"Imagine you are a prospective university student wanting to know more about a specific aspect. \"\n",
        "            \"For the topic provided, generate exactly {num_questions} questions that you might naturally ask. \"\n",
        "            \"Topic: {topic}\\n\\n\"\n",
        "            \"{format_instructions}\"\n",
        "        ),\n",
        "        input_variables=[\"topic\", \"num_questions\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "    )\n",
        "    chain = prompt | model | parser\n",
        "\n",
        "    questions_data = {}\n",
        "\n",
        "    try:\n",
        "        print(f\"Generating questions for topic: {topic}\")\n",
        "        response = chain.invoke({\"topic\": topic, \"num_questions\": num})\n",
        "        questions_data[topic] = response[\"questions\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating questions for topic '{topic}': {e}\")\n",
        "\n",
        "    return questions_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b3c9080-c3d0-458e-8c25-fa869fe0ae37",
      "metadata": {
        "id": "1b3c9080-c3d0-458e-8c25-fa869fe0ae37",
        "outputId": "65c1a88b-5ad6-488c-e144-33380b5a7a47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 3 questions about a specific topic' min_length=3 max_length=3 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Academic Reputation and Program Quality\n",
            "{'Academic Reputation and Program Quality': ['What specific accreditations does the [Program Name] program hold, and how do these accreditations benefit students?', 'Could you provide data on graduate employment rates and the types of positions graduates typically obtain after completing the [Program Name] program?', 'How does the university ensure the curriculum for the [Program Name] program remains current and relevant to industry trends and advancements?']}\n"
          ]
        }
      ],
      "source": [
        "# test it\n",
        "print(generate_questions(\"Academic Reputation and Program Quality\", 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879af438-7482-4b66-ba7a-a888e554df5e",
      "metadata": {
        "id": "879af438-7482-4b66-ba7a-a888e554df5e",
        "outputId": "680e8e95-3cea-460e-ee89-8806b7f45f5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Academic Reputation and Ranking\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Specific Program Strengths (e.g., Engineering, Design)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Faculty Expertise and Research Opportunities\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Hands-on Learning and Project-Based Curriculum\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Internship Opportunities and Industry Connections\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Career Services and Graduate Employment Rate\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Tuition Fees and Financial Aid Options\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Scholarship Availability and Eligibility Criteria\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Cost of Living in Singapore\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Accommodation Options (on-campus and off-campus)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Campus Facilities and Resources (labs, library, maker spaces)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Student-Faculty Ratio and Class Sizes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Student Support Services (academic advising, counseling)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Campus Culture and Student Life\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Diversity and Inclusion Initiatives\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Extracurricular Activities and Clubs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Location and Accessibility of the University\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Opportunities for International Exchange Programs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Networking Opportunities with Alumni\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Safety and Security on Campus\n"
          ]
        }
      ],
      "source": [
        "# # QUESTION: Now let's put it together and generate 10 questions for each topic. Save the questions in a local file.\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "with open(\"data/topics.json\", \"r\") as f:\n",
        "    topics = json.load(f)\n",
        "\n",
        "rate_limit = 15\n",
        "requests_made = 0\n",
        "all_questions = {}\n",
        "\n",
        "for i, topic in enumerate(topics):\n",
        "    if requests_made >= rate_limit:\n",
        "        time.sleep(60)\n",
        "        requests_made = 0\n",
        "    response = generate_questions(topic)\n",
        "    all_questions[topic] = response[topic]\n",
        "    requests_made += 1\n",
        "\n",
        "with open(\"data/questions.json\", \"w\") as f:\n",
        "    json.dump(all_questions, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35dd1d4",
      "metadata": {
        "id": "f35dd1d4"
      },
      "source": [
        "## Generate Answers\n",
        "\n",
        "Now create answers for the questions.\n",
        "\n",
        "You can use the Google AI Studio Gemini model (assuming that they are good enough to generate good answers), your RAG system from assignment 3 or any other method you choose to generate answers for your question dataset.\n",
        "\n",
        "Note: it is normal that some LLM calls fail, even with retry, so maybe you end up with less than 200 QA pairs but it should be at least 160 QA pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e785dd-ab6f-41f8-961b-bf6f9ae24a06",
      "metadata": {
        "id": "e4e785dd-ab6f-41f8-961b-bf6f9ae24a06"
      },
      "outputs": [],
      "source": [
        "# QUESTION: Generate answers to al your questions using Gemini, your SUTD RAG system or any other method.\n",
        "# Split your dataset in to 80% training and 20% test dataset.\n",
        "# Store all questions and answer pairs in a huggingface dataset `sutd_qa_dataset` and push it to your Huggingface hub.\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
        "\n",
        "# generate answers to al the questions using Gemini and then split the dataset in to 80% training and 20% test dataset.\n",
        "def generate_answer(question):\n",
        "    class Answer(BaseModel):\n",
        "        answer: str = Field(description=\"The answer to the question\")\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=Answer)\n",
        "    prompt = PromptTemplate(\n",
        "        template=(\n",
        "            \"Answer the following question in a friendly, clear, and brief manner, as though you \"\n",
        "            \"are advising a prospective student. Use simple language and get straight to the point.\\n\\n\"\n",
        "            \"{format_instructions}\\n\\n\"\n",
        "            \"{question}\"\n",
        "        ),\n",
        "        input_variables=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "    )\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        google_api_key=GOOGLE_GENAI_API_KEY,\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        temperature=0.3,\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "    chain = prompt | model | parser\n",
        "    return chain.invoke({\"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ad13a0",
      "metadata": {
        "id": "47ad13a0",
        "outputId": "e480cd40-0fa4-4275-f0d2-3be7d73cadd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training size: 160\n",
            "Test size: 40\n"
          ]
        }
      ],
      "source": [
        "# now split the dataset in to 80% training and 20% test dataset\n",
        "\n",
        "# load the questions from the json\n",
        "with open(\"data/questions.json\", \"r\") as f:\n",
        "    questions_data = json.load(f)\n",
        "\n",
        "# flattening the questions data with topic as the key\n",
        "flat_questions = []\n",
        "for topic, questions in questions_data.items():\n",
        "    for question in questions:\n",
        "        flat_questions.append({\"topic\": topic, \"question\": question})\n",
        "\n",
        "questions_df = pd.DataFrame(flat_questions)\n",
        "\n",
        "# splits\n",
        "train_df, test_df = train_test_split(questions_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training size: {len(train_df)}\")\n",
        "print(f\"Test size: {len(test_df)}\")\n",
        "\n",
        "# save\n",
        "train_df.to_csv(\"data/train.csv\", index=False)\n",
        "test_df.to_csv(\"data/test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26209b06",
      "metadata": {
        "id": "26209b06",
        "outputId": "b4764b56-6fa0-453f-9dd1-24fad5c5be22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Response:\n",
            "SUTD was founded in 2009.\n"
          ]
        }
      ],
      "source": [
        "# test the chain\n",
        "question = \"When was SUTD founded?\"\n",
        "\n",
        "# Now run the answer generation chain\n",
        "response = generate_answer(question)\n",
        "print(\"\\nModel Response:\")\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80228b92",
      "metadata": {
        "id": "80228b92",
        "outputId": "fda84ad2-3671-4d11-c426-bfd5bf2976f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating answers for the training dataset...\n",
            "Resuming from existing file: data/train.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 1/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 2/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 3/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 4/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 5/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 6/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 7/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 8/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 9/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 10/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 11/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 12/160\n",
            "Rate limit reached. Sleeping for 49.00 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 13/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 14/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 15/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 16/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 17/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 18/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 19/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 20/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 21/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 22/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 23/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 24/160\n",
            "Rate limit reached. Sleeping for 47.67 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 25/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 26/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 27/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 28/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 29/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 30/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 31/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 32/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 33/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 34/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 35/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 36/160\n",
            "Rate limit reached. Sleeping for 46.32 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 37/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 38/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 39/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 40/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 41/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 42/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 43/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 44/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 45/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 46/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 47/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 48/160\n",
            "Rate limit reached. Sleeping for 46.00 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 49/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 50/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 51/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 52/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 53/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 54/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 55/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 56/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 57/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 58/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 59/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 60/160\n",
            "Rate limit reached. Sleeping for 45.80 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 61/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 62/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 63/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 64/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 65/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 66/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 67/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 68/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 69/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 70/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 71/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 72/160\n",
            "Rate limit reached. Sleeping for 40.45 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 73/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 74/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 75/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 76/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 77/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 78/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 79/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 80/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 81/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 82/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 83/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 84/160\n",
            "Rate limit reached. Sleeping for 41.61 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 85/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 86/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 87/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 88/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 89/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 90/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 91/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 92/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 93/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 94/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 95/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 96/160\n",
            "Rate limit reached. Sleeping for 41.78 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 97/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 98/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 99/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 100/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 101/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 102/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 103/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 104/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 105/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 106/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 107/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 108/160\n",
            "Rate limit reached. Sleeping for 44.41 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 109/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 110/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 111/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 112/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 113/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 114/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 115/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 116/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 117/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 118/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 119/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 120/160\n",
            "Rate limit reached. Sleeping for 41.98 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 121/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 122/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 123/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 124/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 125/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 126/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 127/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 128/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 129/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 130/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 131/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 132/160\n",
            "Rate limit reached. Sleeping for 50.14 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 133/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 134/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 135/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 136/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 137/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 138/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 139/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 140/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 141/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 142/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 143/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 144/160\n",
            "Rate limit reached. Sleeping for 50.57 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 145/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 146/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 147/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 148/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 149/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 150/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 151/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 152/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 153/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 154/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 155/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 156/160\n",
            "Rate limit reached. Sleeping for 50.54 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 157/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 158/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 159/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 160/160\n",
            "Finished writing data/train.csv\n",
            "Generating answers for the testing dataset...\n",
            "Resuming from existing file: data/test.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 2/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 3/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 4/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 5/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 6/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 7/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 8/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 9/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 10/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 11/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 12/40\n",
            "Rate limit reached. Sleeping for 50.96 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 13/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 14/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 15/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 16/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 17/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 18/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 19/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 20/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 21/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 22/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 23/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 24/40\n",
            "Rate limit reached. Sleeping for 50.58 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 25/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 26/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 27/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 28/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 29/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 30/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 31/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 32/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 33/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 34/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 35/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 36/40\n",
            "Rate limit reached. Sleeping for 50.87 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 37/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 38/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 39/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 40/40\n",
            "Finished writing data/test.csv\n"
          ]
        }
      ],
      "source": [
        "# now run the chain for all questions to collect context and generate answers\n",
        "\n",
        "# load the questions\n",
        "def process_dataset(csv_file, output_file):\n",
        "    # check if the output file already exists to resume from previous run (IT CRASHED)\n",
        "    try:\n",
        "        df = pd.read_csv(output_file)\n",
        "        print(f\"Resuming from existing file: {output_file}\")\n",
        "    except FileNotFoundError:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        df['answer'] = None  # add empty answer column to be filled in\n",
        "\n",
        "    requests_made = 0\n",
        "    rate_limit = 12  # reduced from 15 to 12 to be safer\n",
        "    count = 0\n",
        "    total = len(df)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # track which rows we've already processed\n",
        "    processed_rows = 0\n",
        "    for index, row in df.iterrows():\n",
        "        # skip rows that already have answers\n",
        "        if pd.notna(row.get('answer')):\n",
        "            processed_rows += 1\n",
        "            continue\n",
        "\n",
        "        question = row['question']\n",
        "\n",
        "        # rate limit by time window (60 seconds) and requests made\n",
        "        current_time = time.time()\n",
        "        elapsed_time = current_time - start_time\n",
        "        if requests_made >= rate_limit:\n",
        "            remaining_time = 60 - elapsed_time\n",
        "            # if requests made is greater than rate limit, and time has elapsed is greater than 60 seconds, sleep for remaining time\n",
        "            if remaining_time > 0:\n",
        "                print(f\"Rate limit reached. Sleeping for {remaining_time:.2f} seconds...\")\n",
        "                time.sleep(remaining_time)\n",
        "            # reset counter and time window\n",
        "            requests_made = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "        # generate answer\n",
        "        try:\n",
        "            answer = generate_answer(question=question)\n",
        "            df.at[index, 'answer'] = answer[\"answer\"]\n",
        "\n",
        "            # Save progress after each successful answer\n",
        "            if processed_rows % 5 == 0:  # Save every 5 processed items\n",
        "                df.to_csv(output_file, index=False)\n",
        "\n",
        "            count += 1\n",
        "            requests_made += 1\n",
        "            processed_rows += 1\n",
        "            print(f\"Processing {csv_file}: {processed_rows}/{total}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing question: {question}\")\n",
        "            print(f\"Error: {e}\")\n",
        "            # save progress asap\n",
        "            df.to_csv(output_file, index=False)\n",
        "\n",
        "            # if quota exceeded, wait longer\n",
        "            if \"429\" in str(e) or \"exceeded\" in str(e).lower() or \"ResourceExhausted\" in str(e):\n",
        "                wait_time = 120  # 2min wait time\n",
        "                print(f\"API quota exceeded. Waiting for {wait_time} seconds before retrying...\")\n",
        "                time.sleep(wait_time)\n",
        "                requests_made = 0  # reset\n",
        "                start_time = time.time()\n",
        "            continue\n",
        "\n",
        "    # save the complete dataset\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Finished writing {output_file}\")\n",
        "    return df\n",
        "\n",
        "print(\"Generating answers for the training dataset...\")\n",
        "train_with_answers = process_dataset(\"data/train.csv\", \"data/train.csv\")\n",
        "\n",
        "print(\"Generating answers for the testing dataset...\")\n",
        "test_with_answers = process_dataset(\"data/test.csv\", \"data/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b832ac7",
      "metadata": {
        "id": "5b832ac7",
        "outputId": "6929c66d-a27f-4e07-b6cc-462b009403dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating parquet from Arrow format: 100%|| 1/1 [00:00<00:00, 997.69ba/s]\n",
            "Uploading the dataset shards: 100%|| 1/1 [00:01<00:00,  1.48s/it]\n",
            "Creating parquet from Arrow format: 100%|| 1/1 [00:00<00:00, 998.88ba/s]\n",
            "Uploading the dataset shards: 100%|| 1/1 [00:01<00:00,  1.39s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/adi0308/sutd_qa_dataset/commit/0a7d8b193b7e016f64c87ec56af251f6e2f84340', commit_message='Upload dataset', commit_description='', oid='0a7d8b193b7e016f64c87ec56af251f6e2f84340', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/adi0308/sutd_qa_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='adi0308/sutd_qa_dataset'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# push to huggingface\n",
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "# convert to huggingface format\n",
        "train_dataset = Dataset.from_pandas(train_with_answers)\n",
        "test_dataset = Dataset.from_pandas(test_with_answers)\n",
        "\n",
        "sutd_qa_dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "\n",
        "# huggingface push\n",
        "# TODO: change username to .env\n",
        "sutd_qa_dataset.push_to_hub(f\"{USERNAME}/sutd_qa_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518dbba2-b593-48ca-abe0-ea8b2423bd19",
      "metadata": {
        "id": "518dbba2-b593-48ca-abe0-ea8b2423bd19"
      },
      "source": [
        "# Finetune Llama 3.2 1B model\n",
        "\n",
        "Now use your SUTD QA dataset training data set to finetune a smaller Llama 3.2 1B LLM using parameter-efficient finetuning (PEFT).\n",
        "We recommend the unsloth library but you are free to choose other frameworks. You can decide the parameters for the finetuning.\n",
        "Push your finetuned model to Huggingface.\n",
        "\n",
        "Then we will compare the finetuned and non-finetuned LLMs with and without RAG to see if we were able to improve the SUTD chatbot answer quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a684028-8dec-4297-a2c4-f659d2f32a26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a684028-8dec-4297-a2c4-f659d2f32a26",
        "outputId": "9c7e4728-421c-4efd-ef63-a2d4aa224f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.1.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Finetune a Llama 3.2 1B model on the training split of your SUTD QA dataset.\n",
        "# You need to prepare your dataset accordingly and set the hyperparameters for the training.\n",
        "# Push your finetuned model to the Hugginface model hub {YOUR_HF_NAME}/llama-3.2-1B-sutdqa\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (50 points)---\n",
        "# following the docs at: https://docs.unsloth.ai/basics/tutorial-how-to-finetune-llama-3-and-use-in-ollama\n",
        "# using base llama 3.2 and not instruct tuned: https://huggingface.co/unsloth/Llama-3.2-1B-bnb-4bit\n",
        "\n",
        "raw = load_dataset(f\"{USERNAME}/sutd_qa_dataset\")\n",
        "\n",
        "# i tried using to_sharegpt method available in unsloth but it didn't work\n",
        "# so built a custom function that takes in a batch and returns a list of formatted questions and answers\n",
        "def fmt_qa(batch):\n",
        "    return [f\"Question: {q}\\nAnswer: {a}\"\n",
        "            for q,a in zip(batch[\"question\"], batch[\"answer\"])]\n",
        "\n",
        "# instead of loading 4 bit config through\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_quant_type='nf4',\n",
        "#     bnb_4bit_compute_dtype=compute_dtype,\n",
        "#     bnb_4bit_use_double_quant=False,\n",
        "# )\n",
        "\n",
        "max_seq_length = 512\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\", # using this model from unsloth which is already set up for 4-bit quantization\n",
        "    load_in_4bit=True, # 4-bit quantization for memory efficiency\n",
        "    device_map=\"auto\",\n",
        "    max_seq_length=max_seq_length,\n",
        ")\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    base_model,\n",
        "    r=16,\n",
        "    target_modules=[\n",
        "      \"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "      \"gate_proj\",\"up_proj\",\"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        ")\n",
        "\n",
        "OUTPUT_MODEL = f\"{USERNAME}/llama-3.2-1B-sutdqa\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"outputs\",\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size= 2,\n",
        "    gradient_accumulation_steps= 4,\n",
        "    learning_rate = 1e-4,\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    save_strategy = \"epoch\",\n",
        "    push_to_hub = True,\n",
        "    hub_model_id = OUTPUT_MODEL,\n",
        "    hub_token = HUGGINGFACE_TOKEN,\n",
        "    logging_steps = 10,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer, # passing the tokenizer here is important\n",
        "    train_dataset = raw[\"train\"],\n",
        "    eval_dataset = raw[\"test\"],\n",
        "    dataset_text_field = None,\n",
        "    formatting_func = fmt_qa,\n",
        "    max_seq_length= max_seq_length,\n",
        "    packing = False,\n",
        "    args = training_args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8daceeaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "8daceeaf",
        "outputId": "c92d9027-7185-404a-9ecc-b04d5473e8d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 160 | Num Epochs = 5 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 11,272,192/1,000,000,000 (1.13% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 01:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.396300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.884600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.531000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.474400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.307400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.256300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.143200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.117300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.040300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.034500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=1.418526668548584, metrics={'train_runtime': 91.2855, 'train_samples_per_second': 8.764, 'train_steps_per_second': 1.095, 'total_flos': 262697930932224.0, 'train_loss': 1.418526668548584, 'epoch': 5.0})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finetuning run\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kRbEOp2cVpjJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "kRbEOp2cVpjJ",
        "outputId": "e7af9181-fe5f-482f-cbe8-11da8e963bd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/adi0308/llama-3.2-1B-sutdqa/commit/8b73454a5d3ae8fa2dc722db41e595f079d82c30', commit_message='End of training', commit_description='', oid='8b73454a5d3ae8fa2dc722db41e595f079d82c30', pr_url=None, repo_url=RepoUrl('https://huggingface.co/adi0308/llama-3.2-1B-sutdqa', endpoint='https://huggingface.co', repo_type='model', repo_id='adi0308/llama-3.2-1B-sutdqa'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# push to huggingface\n",
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4268373a-9d77-4787-a0d7-a6df23cd94de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539,
          "referenced_widgets": [
            "1505550171844b05aba36ddcab4e30be",
            "5fb364b92979456e87f041f3504384a0",
            "6830f1d302da4c4caf25c287d243e297",
            "802ddb6311c7407a92ab200059e984b2",
            "81be84336db744e7a959328b26308bf5",
            "b16cd1d5ca5240fdb24b2649a420560b",
            "7f183678fea54eac8b04487c7ae5e1e2",
            "b42830cf2d9c42ffb75bf9aa2d299a27",
            "7efae6b70bd84ecd90929bfefec025bd",
            "41650e7ae27b44fbbbf1d495120df97c",
            "5197e000d3614e27a6ebb91c350f92c0",
            "ff7e8a81ab904f69a0bc0649b1aaef0f",
            "cb7dffce26da4ffe8b4c56c731863cea",
            "c142e7ff3af14eca97a847b41fd79e11",
            "b03b1540a8114b1c983aa2b22071a6a8",
            "2328c87d892245fab8d60b0881c81f66",
            "b156bcf49fa54198b5737c26ac720190",
            "2474bdbbb1a44bed8a6142f60b8ebebb",
            "e7d3cfb1ca3b40ec927b70229cb6c17a",
            "51dd523836274f47b1b1a9cdbfb7be77",
            "750c89df3ea64b909af01af2e5757e73",
            "1730f1e02ec54d32b4c3adaed7148817",
            "cc4176769d20414b8e3379b18ddd1fd3",
            "75af545a2b3649e6b89b575597444631",
            "d41531f7ea304618ba54c1195b4c7f0c",
            "55eeb755f55c4bd488c74985c94dd531",
            "848078a59c574c3892e4ea5ed1040deb",
            "5995f4547a9c4105a6abe9d8f9617e68",
            "221a50f58f7443c69e65e1179b2ded74",
            "45046b24823e404cb6cb1372a4f29345",
            "02e2ce31f68a4bddb2713f27dd2baf6c",
            "b6c931e1af13423198a79e89ad368075",
            "25ea136f8d4e4f59a8102c1af06edb94"
          ]
        },
        "id": "4268373a-9d77-4787-a0d7-a6df23cd94de",
        "outputId": "07a9d327-7570-434e-af55-a897e6c50ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1505550171844b05aba36ddcab4e30be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff7e8a81ab904f69a0bc0649b1aaef0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "<ipython-input-5-842478e321e1>:23: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  hf_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc4176769d20414b8e3379b18ddd1fd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.19 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n",
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Load a non-finetuned Llama 3.2 1B model and your finetuned SUTD QA Llama 3.2 1B model\n",
        "# Ask it a simple test question (e.g. \"What is special about SUTD?\") to check that both models can generated answers\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (10 points)---\n",
        "# load the models using the huggingface pipeline from langchain\n",
        "# 1) Base (unfinetuned) Llama3.2 4bit\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "infer_base = FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "pipe_base = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_base,\n",
        "    tokenizer  = tokenizer,\n",
        "    device_map = \"auto\",\n",
        ")\n",
        "\n",
        "# adding a bind to allow to skip the Question when asnwering\n",
        "hf_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n",
        "\n",
        "# finetuned\n",
        "finetuned_model_id = f\"{USERNAME}/llama-3.2-1B-sutdqa\"\n",
        "finetune_model, _ = FastLanguageModel.from_pretrained(\n",
        "    finetuned_model_id,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "infer_finetune = FastLanguageModel.for_inference(finetune_model)\n",
        "\n",
        "pipe_finetune = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_finetune,\n",
        "    tokenizer = tokenizer,\n",
        "    device_map = \"auto\",\n",
        ")\n",
        "\n",
        "hf_finetune = HuggingFacePipeline(pipeline=pipe_finetune).bind(skip_prompt=True)\n",
        "\n",
        "# prompt template to make it consistent with the training data used to finetune the model\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Question: {question}\\nAnswer:\"\n",
        ")\n",
        "\n",
        "llm_base = prompt | hf_base\n",
        "llm_finetune = prompt | hf_finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a3ff291f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ff291f",
        "outputId": "af800f54-a8d5-4d92-95f3-e518e2c8a54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is special about SUTD?\n",
            "Answer base:  SUTD is a rare subtype of T-cell lymphoma with a very poor prognosis. The disease is characterized by a high frequency of mutations in the BIM gene, which encodes a BCL6 homologue. The disease is also characterized by a high frequency of mutations in the BIM gene, which encodes a BCL6 homologue.\n",
            "---------\n",
            "Answer finetune:  SUTD offers a unique blend of engineering, design, and entrepreneurial thinking. It's a great place to learn both practical skills and creativity. Plus, you'll be part of a vibrant community of like-minded students.\n"
          ]
        }
      ],
      "source": [
        "# try out the llms\n",
        "query = \"What is special about SUTD?\"\n",
        "\n",
        "print(\"Question:\", query)\n",
        "response_base = llm_base.invoke(query,  pipeline_kwargs={\"max_new_tokens\": 512})\n",
        "print(\"Answer base:\", response_base)\n",
        "\n",
        "print(\"---------\")\n",
        "response_finetune = llm_finetune.invoke(query, pipeline_kwargs={\"max_new_tokens\": 512})\n",
        "print(\"Answer finetune:\", response_finetune)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abd9d89f",
      "metadata": {},
      "source": [
        "## Evaluating finetuned model and base model using test data pushed to hugging face\n",
        "\n",
        "#### Note: This is not a required part of the assignment. We are simply running it to check if the finetuned model is performing better than the base model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6075ba0",
      "metadata": {},
      "source": [
        "The reason for the low BLEU score is that it only recognizes exact word matches between the reference and generated answers. It doesn't understand synonyms, paraphrases, or alternative ways of expressing the same information.\n",
        "\n",
        "The metric lacks any concept of meaning. Two answers can convey identical information using different vocabulary, and BLEU will assign a low score despite semantic equivalence.\n",
        "\n",
        "Hence, the cosine similarity score is more appropriate for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f7124ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
            "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Windows.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.6. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_35560\\3539689893.py:19: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  hf_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA GeForce RTX 3050 Laptop GPU. Num GPUs = 1. Max memory: 4.0 GB. Platform: Windows.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.6. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.19 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n",
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "# evaluating the base models using bleu and cosine  similarity score\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "infer_base = FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "pipe_base = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_base,\n",
        "    tokenizer  = tokenizer,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 100,\n",
        ")\n",
        "\n",
        "# adding a bind to allow to skip the Question when asnwering\n",
        "hf_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n",
        "\n",
        "# finetuned\n",
        "finetuned_model_id = f\"{USERNAME}/llama-3.2-1B-sutdqa\"\n",
        "finetune_model, _ = FastLanguageModel.from_pretrained(\n",
        "    finetuned_model_id,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "infer_finetune = FastLanguageModel.for_inference(finetune_model)\n",
        "\n",
        "pipe_finetune = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_finetune,\n",
        "    tokenizer = tokenizer,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 100,\n",
        ")\n",
        "\n",
        "hf_finetune = HuggingFacePipeline(pipeline=pipe_finetune).bind(skip_prompt=True)\n",
        "\n",
        "# prompt template to make it consistent with the training data used to finetune the model\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Question: {question}\\nAnswer:\"\n",
        ")\n",
        "\n",
        "llm_base = prompt | hf_base\n",
        "llm_finetune = prompt | hf_finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "55047aa2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bleu_scores(responses: List[str], answers: List[str]) -> Dict[str, float]:\n",
        "    bleu = evaluate.load(\"bleu\")\n",
        "\n",
        "    # corpus-level BLEU (calculate once across all examples)\n",
        "    refs = [[a] for a in answers]  # BLEU wants a List[List[str]] for references\n",
        "    print(\"Computing corpus-level BLEU score...\")\n",
        "    out = bleu.compute(predictions=responses, references=refs)\n",
        "    corpus_score = out[\"bleu\"]\n",
        "    return corpus_score\n",
        "\n",
        "# using sklearn\n",
        "# def cosine_similarity_score(responses: List[str], answers: List[str]) -> float:\n",
        "#     # TODO: traverse and average\n",
        "#     corpus = responses + answers\n",
        "#     vectorizer = TfidfVectorizer().fit(corpus)\n",
        "\n",
        "#     # converting it into TF-IDF matrices (typically you would use embedding modelss)\n",
        "#     resp_vecs = vectorizer.transform(responses)\n",
        "#     ans_vecs = vectorizer.transform(answers)\n",
        "\n",
        "#     sim_matrix = cosine_similarity(resp_vecs, ans_vecs)  # dense array\n",
        "#     pairwise_sims = np.diag(sim_matrix)  # extract similarities for corresponding pairs\n",
        "\n",
        "#     return float(np.mean(pairwise_sims))\n",
        "\n",
        "# using the same function but using openai embeddings to check semantic similarity\n",
        "def cosine_similarity_score(client: OpenAI, responses: List[str], answers: List[str]) -> float:\n",
        "    total = len(responses)\n",
        "    response_embeddings = []\n",
        "    for i, response in enumerate(responses):\n",
        "        print(f\"Processing response {i+1}/{total}\")\n",
        "        embedding = client.embeddings.create(model=\"text-embedding-ada-002\", input=response).data[0].embedding\n",
        "        response_embeddings.append(embedding)\n",
        "\n",
        "    answer_embeddings = []\n",
        "    for answer in answers:\n",
        "        embedding = client.embeddings.create(model=\"text-embedding-ada-002\",input=answer).data[0].embedding\n",
        "        answer_embeddings.append(embedding)\n",
        "\n",
        "    # convert embeddings to numpy arrays\n",
        "    response_embeddings = np.array(response_embeddings)\n",
        "    answer_embeddings = np.array(answer_embeddings)\n",
        "\n",
        "    # now calculating pairwise cosine similarities\n",
        "    similarities = []\n",
        "    for i in range(len(response_embeddings)):\n",
        "        similarity = cosine_similarity([response_embeddings[i]], [answer_embeddings[i]])[0][0]\n",
        "        similarities.append(similarity)\n",
        "\n",
        "    # mean similarity\n",
        "    return float(np.mean(similarities))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a54fcb14",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base: Question 1/40\n",
            "Base: Question 2/40\n",
            "Base: Question 3/40\n",
            "Base: Question 4/40\n",
            "Base: Question 5/40\n",
            "Base: Question 6/40\n",
            "Base: Question 7/40\n",
            "Base: Question 8/40\n",
            "Base: Question 9/40\n",
            "Base: Question 10/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Base: Question 11/40\n",
            "Base: Question 12/40\n",
            "Base: Question 13/40\n",
            "Base: Question 14/40\n",
            "Base: Question 15/40\n",
            "Base: Question 16/40\n",
            "Base: Question 17/40\n",
            "Base: Question 18/40\n",
            "Base: Question 19/40\n",
            "Base: Question 20/40\n",
            "Base: Question 21/40\n",
            "Base: Question 22/40\n",
            "Base: Question 23/40\n",
            "Base: Question 24/40\n",
            "Base: Question 25/40\n",
            "Base: Question 26/40\n",
            "Base: Question 27/40\n",
            "Base: Question 28/40\n",
            "Base: Question 29/40\n",
            "Base: Question 30/40\n",
            "Base: Question 31/40\n",
            "Base: Question 32/40\n",
            "Base: Question 33/40\n",
            "Base: Question 34/40\n",
            "Base: Question 35/40\n",
            "Base: Question 36/40\n",
            "Base: Question 37/40\n",
            "Base: Question 38/40\n",
            "Base: Question 39/40\n",
            "Base: Question 40/40\n",
            "Evaluating fine-tuned model on 40 questions...\n",
            "Fine-tuned: Question 1/40\n",
            "Fine-tuned: Question 2/40\n",
            "Fine-tuned: Question 3/40\n",
            "Fine-tuned: Question 4/40\n",
            "Fine-tuned: Question 5/40\n",
            "Fine-tuned: Question 6/40\n",
            "Fine-tuned: Question 7/40\n",
            "Fine-tuned: Question 8/40\n",
            "Fine-tuned: Question 9/40\n",
            "Fine-tuned: Question 10/40\n",
            "Fine-tuned: Question 11/40\n",
            "Fine-tuned: Question 12/40\n",
            "Fine-tuned: Question 13/40\n",
            "Fine-tuned: Question 14/40\n",
            "Fine-tuned: Question 15/40\n",
            "Fine-tuned: Question 16/40\n",
            "Fine-tuned: Question 17/40\n",
            "Fine-tuned: Question 18/40\n",
            "Fine-tuned: Question 19/40\n",
            "Fine-tuned: Question 20/40\n",
            "Fine-tuned: Question 21/40\n",
            "Fine-tuned: Question 22/40\n",
            "Fine-tuned: Question 23/40\n",
            "Fine-tuned: Question 24/40\n",
            "Fine-tuned: Question 25/40\n",
            "Fine-tuned: Question 26/40\n",
            "Fine-tuned: Question 27/40\n",
            "Fine-tuned: Question 28/40\n",
            "Fine-tuned: Question 29/40\n",
            "Fine-tuned: Question 30/40\n",
            "Fine-tuned: Question 31/40\n",
            "Fine-tuned: Question 32/40\n",
            "Fine-tuned: Question 33/40\n",
            "Fine-tuned: Question 34/40\n",
            "Fine-tuned: Question 35/40\n",
            "Fine-tuned: Question 36/40\n",
            "Fine-tuned: Question 37/40\n",
            "Fine-tuned: Question 38/40\n",
            "Fine-tuned: Question 39/40\n",
            "Fine-tuned: Question 40/40\n"
          ]
        }
      ],
      "source": [
        "raw_data = load_dataset(f\"{USERNAME}/sutd_qa_dataset\")\n",
        "\n",
        "questions = raw_data[\"test\"][\"question\"]\n",
        "answers = raw_data[\"test\"][\"answer\"]\n",
        "\n",
        "# get model answers\n",
        "# added debugging to see if the model is working\n",
        "base_answers = []\n",
        "for i, question in enumerate(questions):\n",
        "    print(f\"Base: Question {i+1}/{len(questions)}\")\n",
        "    try:\n",
        "        answer = llm_base.invoke(question, pipeline_kwargs={\"max_new_tokens\": 100})\n",
        "        base_answers.append(answer)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with base model: {e}\")\n",
        "\n",
        "finetune_answers = []\n",
        "print(f\"Evaluating fine-tuned model on {len(questions)} questions...\")\n",
        "for i, question in enumerate(questions):\n",
        "    print(f\"Fine-tuned: Question {i+1}/{len(questions)}\")\n",
        "    try:\n",
        "        answer = llm_finetune.invoke(question, pipeline_kwargs={\"max_new_tokens\": 100})\n",
        "        finetune_answers.append(answer)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with fine-tuned model: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2f1662cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing corpus-level BLEU score...\n",
            "Computing corpus-level BLEU score...\n",
            "Processing response 1/40\n",
            "Processing response 2/40\n",
            "Processing response 3/40\n",
            "Processing response 4/40\n",
            "Processing response 5/40\n",
            "Processing response 6/40\n",
            "Processing response 7/40\n",
            "Processing response 8/40\n",
            "Processing response 9/40\n",
            "Processing response 10/40\n",
            "Processing response 11/40\n",
            "Processing response 12/40\n",
            "Processing response 13/40\n",
            "Processing response 14/40\n",
            "Processing response 15/40\n",
            "Processing response 16/40\n",
            "Processing response 17/40\n",
            "Processing response 18/40\n",
            "Processing response 19/40\n",
            "Processing response 20/40\n",
            "Processing response 21/40\n",
            "Processing response 22/40\n",
            "Processing response 23/40\n",
            "Processing response 24/40\n",
            "Processing response 25/40\n",
            "Processing response 26/40\n",
            "Processing response 27/40\n",
            "Processing response 28/40\n",
            "Processing response 29/40\n",
            "Processing response 30/40\n",
            "Processing response 31/40\n",
            "Processing response 32/40\n",
            "Processing response 33/40\n",
            "Processing response 34/40\n",
            "Processing response 35/40\n",
            "Processing response 36/40\n",
            "Processing response 37/40\n",
            "Processing response 38/40\n",
            "Processing response 39/40\n",
            "Processing response 40/40\n",
            "Processing response 1/40\n",
            "Processing response 2/40\n",
            "Processing response 3/40\n",
            "Processing response 4/40\n",
            "Processing response 5/40\n",
            "Processing response 6/40\n",
            "Processing response 7/40\n",
            "Processing response 8/40\n",
            "Processing response 9/40\n",
            "Processing response 10/40\n",
            "Processing response 11/40\n",
            "Processing response 12/40\n",
            "Processing response 13/40\n",
            "Processing response 14/40\n",
            "Processing response 15/40\n",
            "Processing response 16/40\n",
            "Processing response 17/40\n",
            "Processing response 18/40\n",
            "Processing response 19/40\n",
            "Processing response 20/40\n",
            "Processing response 21/40\n",
            "Processing response 22/40\n",
            "Processing response 23/40\n",
            "Processing response 24/40\n",
            "Processing response 25/40\n",
            "Processing response 26/40\n",
            "Processing response 27/40\n",
            "Processing response 28/40\n",
            "Processing response 29/40\n",
            "Processing response 30/40\n",
            "Processing response 31/40\n",
            "Processing response 32/40\n",
            "Processing response 33/40\n",
            "Processing response 34/40\n",
            "Processing response 35/40\n",
            "Processing response 36/40\n",
            "Processing response 37/40\n",
            "Processing response 38/40\n",
            "Processing response 39/40\n",
            "Processing response 40/40\n",
            "BLEU score for base model: 0.01672386754449274\n",
            "BLEU score for finetuned model: 0.09485487231433141\n",
            "Cosine similarity score for base model: 0.8494885679351881\n",
            "Cosine similarity score for finetuned model: 0.8889794284537365\n"
          ]
        }
      ],
      "source": [
        "#calculating the bleu scores\n",
        "bleu_score_base = bleu_scores(base_answers, answers)\n",
        "bleu_score_finetune = bleu_scores(finetune_answers, answers)\n",
        "\n",
        "#calculating the cosine_similarity scores\n",
        "cosine_similarity_base = cosine_similarity_score(client, base_answers, answers)\n",
        "cosine_similarity_finetune = cosine_similarity_score(client, finetune_answers, answers)\n",
        "\n",
        "print(f\"BLEU score for base model: {bleu_score_base}\")\n",
        "print(f\"BLEU score for finetuned model: {bleu_score_finetune}\")\n",
        "\n",
        "print(f\"Cosine similarity score for base model: {cosine_similarity_base}\")\n",
        "print(f\"Cosine similarity score for finetuned model: {cosine_similarity_finetune}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d01c764f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BLEU score improvement: 467.18%\n",
            "Cosine similarity improvement: 4.65%\n"
          ]
        }
      ],
      "source": [
        "# plotting\n",
        "# i need to calculate the improvement in bleu and cosine similarity scores\n",
        "bleu_improvement = ((bleu_score_finetune - bleu_score_base) / bleu_score_base) * 100 if bleu_score_base > 0 else float('inf')\n",
        "cosine_improvement = ((cosine_similarity_finetune - cosine_similarity_base) / cosine_similarity_base) * 100 if cosine_similarity_base > 0 else float('inf')\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "models = ['Base', 'Fine-tuned']\n",
        "bleu_scores = [bleu_score_base, bleu_score_finetune]\n",
        "cosine_scores = [cosine_similarity_base, cosine_similarity_finetune]\n",
        "\n",
        "# simple bar plots\n",
        "ax1.bar(models, bleu_scores)\n",
        "ax1.set_title('BLEU Score')\n",
        "ax1.text(1, bleu_scores[1], f'+{bleu_improvement:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "ax2.bar(models, cosine_scores)\n",
        "ax2.set_title('Cosine Similarity')\n",
        "ax2.text(1, cosine_scores[1], f'+{cosine_improvement:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/model_comparison.png')\n",
        "plt.show()\n",
        "\n",
        "print(f\"BLEU score improvement: {bleu_improvement:.2f}%\")\n",
        "print(f\"Cosine similarity improvement: {cosine_improvement:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc277373",
      "metadata": {
        "id": "cc277373"
      },
      "source": [
        "# Integrate and evaluate\n",
        "\n",
        "Now integrate both the non-finetuned Llama 3.2 1B model and your finetuned model into your SUTD chatbot RAG system.\n",
        "Generate responses to the 20 questions you have collected in assignment 3 using these 4 appraoches\n",
        "1. non-finetuned Llama 3.2 1B model without RAG\n",
        "2. finetuned Llama 3.2 1B SUTD QA model without RAG\n",
        "3. non-finetuned Llama 3.2 1B model with RAG\n",
        "4. finetuned Llama 3.2 1B SUTD QA model with RAG\n",
        "\n",
        "Compare the responses and decide what system produces the most accurate and high quality responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "da455368",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da455368",
        "outputId": "ad576b5d-b40c-40b4-b52d-c21a08802b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ms-marco-MiniLM-L-12-v2.zip: 100%|| 21.6M/21.6M [00:00<00:00, 122MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Re-create the RAG chatbot system you have created in assignment 3 but with the Llama 3.2 1B (non-tuned and finetuned) models\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
        "# rag setup\n",
        "# chunking\n",
        "def get_data(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def extract_all_internal_urls(text):\n",
        "    matches = re.findall(r'\\[([^\\]]+)\\]\\((https?://[^)]+)\\)', text)\n",
        "    return [{\"text\": t, \"url\": u} for t,u in matches if 'sutd.edu.sg' in u]\n",
        "\n",
        "def extract_pillar(title, url):\n",
        "    for p in [\"ISTD\",\"ESD\",\"EPD\",\"ASD\",\"DAI\",\"HASS\",\"SMT\"]:\n",
        "        if p in title or p.lower() in url.lower():\n",
        "            return p\n",
        "    return \"General\"\n",
        "\n",
        "json_data = get_data(MARKDOWN_PATH)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=OPENAI_API_KEY)\n",
        "text_splitter = SemanticChunker(embeddings, breakpoint_threshold_type=\"gradient\", breakpoint_threshold_amount=85)\n",
        "all_chunks = []\n",
        "for item in json_data:\n",
        "    md = item[\"markdown\"]\n",
        "    if not md: continue\n",
        "    meta = {\n",
        "        \"title\": item[\"title\"],\n",
        "        \"url\": item[\"url\"],\n",
        "        \"description\": item.get(\"description\",\"\"),\n",
        "        \"source\": item[\"url\"],\n",
        "        \"pillar\": extract_pillar(item[\"title\"],item[\"url\"]),\n",
        "        \"internal_urls\": extract_all_internal_urls(md)\n",
        "    }\n",
        "    docs = text_splitter.create_documents([md], metadatas=[meta])\n",
        "    all_chunks.extend(docs)\n",
        "\n",
        "# indexing\n",
        "vector_store = FAISS.from_documents(all_chunks, embeddings)\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":TOP_K})\n",
        "\n",
        "# reranker and compresssion\n",
        "ranker = Ranker(model_name=\"ms-marco-MiniLM-L-12-v2\")\n",
        "compressor = FlashrankRerank(model=\"ms-marco-MiniLM-L-12-v2\", top_n=3)\n",
        "compression_retriever = ContextualCompressionRetriever(base_retriever=retriever, base_compressor=compressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "VE_C6azBF7vE",
      "metadata": {
        "id": "VE_C6azBF7vE"
      },
      "outputs": [],
      "source": [
        "# 20 questions from the previous RAG\n",
        "questions = [\n",
        "    \"What are the admissions deadlines for SUTD?\",\n",
        "    \"Is there financial aid available?\",\n",
        "    \"What is the minimum score for the Mother Tongue Language?\",\n",
        "    \"Do I require reference letters?\",\n",
        "    \"Can polytechnic diploma students apply?\",\n",
        "    \"Do I need SAT score?\",\n",
        "    \"How many PhD students does SUTD have?\",\n",
        "    \"How much are the tuition fees for Singaporeans?\",\n",
        "    \"How much are the tuition fees for international students?\",\n",
        "    \"Is there a minimum CAP?\",\n",
        "    \"What is SUTDs mission and vision?\",\n",
        "    \"When was SUTD officially inaugurated?\",\n",
        "    \"Which core values does SUTD emphasize?\",\n",
        "    \"Where is SUTD located, and how can it be contacted?\",\n",
        "    \"What different SUTD offices or departments can I reach out to?\",\n",
        "    \"What are the key components of the Freshmore curriculum at SUTD?\",\n",
        "    \"Which elective modules are available for Freshmore students in Term 3?\",\n",
        "    \"What courses are offered within the Design and Artificial Intelligence pillar?\",\n",
        "    \"Who are some of the instructors teaching the courses in the DAI program?\",\n",
        "    \"What are the main steps involved in the SUTD application process?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cSg29WmESaUr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSg29WmESaUr",
        "outputId": "0598b84c-637e-4a98-ae5f-a0a92d60d746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/20] Processing question: What are the admissions deadlines for SUTD?\n",
            "\n",
            "Answer:  For the 2021/22 academic year, SUTD admissions deadlines are as follows:\n",
            "For applicants who have received a conditional offer from SUTD, the admissions deadline is 1 October 2020.\n",
            "For applicants who have received an unconditional offer from SUTD, the admissions deadline is 15 January 2021.\n",
            "For applicants who have received a conditional offer from SUTD, the admissions deadline is 15 January 2021.\n",
            "For applicants who have received an unconditional offer from\n",
            "\n",
            "[2/20] Processing question: Is there financial aid available?\n",
            "\n",
            "Answer:  Yes, there is financial aid available for a variety of reasons. Financial aid can be in the form of a scholarship or a grant. Scholarships are awarded to students based on academic achievement and/or financial need. Grants are awarded to students based on their financial need.\n",
            "Q: Is there financial aid available?\n",
            "A: Yes, there is financial aid available for a variety of reasons. Financial aid can be in the form of a scholarship or a grant. Scholarships are awarded to students based on academic achievement\n",
            "\n",
            "[3/20] Processing question: What is the minimum score for the Mother Tongue Language?\n",
            "\n",
            "Answer:  3\n",
            "Explanation: 3 is the minimum score for the mother tongue language. If a child does not speak his or her mother tongue language at home, the score is 3. If a child speaks his or her mother tongue language at home, the score is 4.\n",
            "\n",
            "[4/20] Processing question: Do I require reference letters?\n",
            "\n",
            "Answer:  Yes. You should always provide reference letters. In fact, if you dont provide reference letters, the committee may not even consider your application. If you are applying for a fellowship, you need to provide at least one letter of recommendation from a professional, such as a neurologist. If you are applying for a position, you need to provide at least one letter of recommendation from a professional, such as a psychologist or psychiatrist.\n",
            "If you are applying for a position, you should provide a letter\n",
            "\n",
            "[5/20] Processing question: Can polytechnic diploma students apply?\n",
            "\n",
            "Answer:  Yes, polytechnic diploma holders can apply for the admission in any of the UG courses in the University of Delhi.\n",
            "How to get admission in polytechnic diploma courses in Delhi?\n",
            "Answer: The admission process for polytechnic diploma courses in Delhi is very simple. The candidate must have passed his/her 10th class examination with minimum 50% marks and must have completed the course within 2 years.\n",
            "What are the eligibility criteria for admission in polytechnic diploma courses in Delhi?\n",
            "\n",
            "\n",
            "[6/20] Processing question: Do I need SAT score?\n",
            "\n",
            "Answer:  SAT score is not mandatory for admissions. It is a mandatory requirement for some colleges, however, it is not a mandatory requirement for all colleges. Some colleges may ask you to submit SAT scores as part of the admission process.\n",
            "Is it good to have SAT score?\n",
            "SAT score is not a mandatory requirement for admissions. It is a mandatory requirement for some colleges, however, it is not a mandatory requirement for all colleges. Some colleges may ask you to submit SAT scores as part of the admission process.\n",
            "\n",
            "\n",
            "[7/20] Processing question: How many PhD students does SUTD have?\n",
            "\n",
            "Answer:  40 PhD students.\n",
            "What is SUTD's research focus?\n",
            "SUTD is one of the leading institutions in Southeast Asia in research in engineering and the sciences. We have 40 PhD students currently pursuing their research degrees. Our research focus is in the areas of engineering, sciences, biomedical engineering, and social sciences.\n",
            "What is the curriculum like at SUTD?\n",
            "SUTD has a three-year PhD program in engineering, the sciences, and biomedical engineering. Our students are encouraged to take\n",
            "\n",
            "[8/20] Processing question: How much are the tuition fees for Singaporeans?\n",
            "\n",
            "Answer:  For Singaporeans, the tuition fees are $3,000 per year for the diploma and $4,000 for the degree.\n",
            "What are the tuition fees for Singaporeans?\n",
            "Answer: For Singaporeans, the tuition fees are $3,000 per year for the diploma and $4,000 for the degree.\n",
            "How much is tuition for Singaporeans?\n",
            "Answer: For Singaporeans, the tuition fees are $3,000 per year for the diploma and $4,000 for the degree.\n",
            "What\n",
            "\n",
            "[9/20] Processing question: How much are the tuition fees for international students?\n",
            "\n",
            "Answer:  The tuition fees for international students are the same as those for domestic students. However, some universities may charge a higher fee for international students.\n",
            "How much are the tuition fees for international students?\n",
            "Answer: The tuition fees for international students are the same as those for domestic students. However, some universities may charge a higher fee for international students.\n",
            "How much are the tuition fees for international students?\n",
            "Answer: The tuition fees for international students are the same as those for domestic students. However, some universities may\n",
            "\n",
            "[10/20] Processing question: Is there a minimum CAP?\n",
            "\n",
            "Answer:  No. There is no minimum CAP in the book. There is a minimum for the author, but not for the reader.\n",
            "\n",
            "[11/20] Processing question: What is SUTDs mission and vision?\n",
            "\n",
            "Answer:  SUTDs mission is to provide a safe, healthy, nurturing and caring environment for all children and to prepare them to be productive citizens in a global society. SUTDs vision is to be the most sought after school in the world.\n",
            "\n",
            "[12/20] Processing question: When was SUTD officially inaugurated?\n",
            "\n",
            "Answer:  2013\n",
            "Explanation: SUTD is the first Indian study to show that the treatment of choice in patients with SUTD is a combination of methotrexate and cyclophosphamide. It is the first Indian study to show that the treatment of choice in patients with SUTD is a combination of methotrexate and cyclophosphamide.\n",
            "\n",
            "[13/20] Processing question: Which core values does SUTD emphasize?\n",
            "\n",
            "Answer:  (1) Autonomy\n",
            "(2) Beneficence\n",
            "(3) Non-maleficence\n",
            "(4) Justice\n",
            "(5) Truthfulness\n",
            "(6) Patience\n",
            "(7) Fairness\n",
            "(8) Compassion\n",
            "(9) Respect for others' dignity\n",
            "(10) Honesty\n",
            "(11) Respect for all life\n",
            "(12) Truthfulness\n",
            "(13) Care\n",
            "(14) Compassion\n",
            "(15) Trust\n",
            "(16) Truth\n",
            "\n",
            "[14/20] Processing question: Where is SUTD located, and how can it be contacted?\n",
            "\n",
            "Answer:  SUTD is located at 1st Floor, 9th Cross, 3rd Block, Jayanagar, Bangalore. You can contact us via our email id: [emailprotected]\n",
            "What is the purpose of SUTD?\n",
            "SUTD is a non-profit organization that aims to provide holistic education to young people. Our mission is to empower young people to become leaders in their communities. We believe that every individual has the potential to make a difference, and we are committed to\n",
            "\n",
            "[15/20] Processing question: What different SUTD offices or departments can I reach out to?\n",
            "\n",
            "Answer:  We have an SUTD office in each of our campuses, and we have a variety of departments and committees that can help you with your transition. These include: Student Affairs, Academic Affairs, Student Services, Career Services, Student Health Services, and Student Government.\n",
            "In addition, we have a variety of committees that are open to all students, including the SUTD Council, the SUTD Student Advisory Board, the SUTD Student Advisory Board Executive Committee, and the SUTD Student\n",
            "\n",
            "[16/20] Processing question: What are the key components of the Freshmore curriculum at SUTD?\n",
            "\n",
            "Answer:  The Freshmore curriculum at SUTD is a unique, interdisciplinary, and integrative course of study that is based on the philosophy of the arts and sciences. It is a highly structured, multi-dimensional, and comprehensive approach to education that emphasizes the integration of the arts and sciences.\n",
            "The curriculum at SUTD is divided into two main components: the arts and sciences. The arts are represented by the Visual Arts, Music, and Dance departments. The sciences are represented by the Mathematics, Physics, and\n",
            "\n",
            "[17/20] Processing question: Which elective modules are available for Freshmore students in Term 3?\n",
            "\n",
            "Answer:  Freshmore elective modules are available for students in Term 3. Please see the elective module timetable for more information.\n",
            "What is the purpose of the elective modules?\n",
            "The purpose of the elective modules is to provide students with an opportunity to engage with a specific theme in a way that is not possible in the main curriculum. It also provides an opportunity to develop a deeper understanding of the theme.\n",
            "What are the main elective modules?\n",
            "The main elective modules are:\n",
            "What is the difference between elective modules and electives\n",
            "\n",
            "[18/20] Processing question: What courses are offered within the Design and Artificial Intelligence pillar?\n",
            "\n",
            "Answer:  Within the Design and Artificial Intelligence pillar, courses are offered in the following areas:\n",
            "Artificial Intelligence (AI)  courses on the following areas:\n",
            "Machine Learning (ML)  courses on the following areas:\n",
            "Natural Language Processing (NLP)  courses on the following areas:\n",
            "Design & AI\n",
            "Design & AI  courses on the following areas:\n",
            "Data Science  courses on the following areas:\n",
            "Design & AI  courses on the following areas:\n",
            "Data Science  courses on the following areas:\n",
            "Design & AI\n",
            "\n",
            "[19/20] Processing question: Who are some of the instructors teaching the courses in the DAI program?\n",
            "\n",
            "Answer:  DAI instructors are drawn from the public and private sectors, and from all walks of life. They are from a wide range of disciplines, including law, engineering, business, medicine, psychology, education, and government. They are drawn from the public and private sectors, and from all walks of life. In addition to their academic credentials, they bring a wealth of practical experience to their teaching.\n",
            "What is the DAI program?\n",
            "The DAI program is designed to give students the opportunity to develop the\n",
            "\n",
            "[20/20] Processing question: What are the main steps involved in the SUTD application process?\n",
            "\n",
            "Answer:  SUTD is an acronym for the following:\n",
            "Sexually Transmitted Infections Diagnosis\n",
            "Treatment, Education and Support\n",
            "The SUTD application process begins with an online application. If you are applying for SUTD because you are a woman, you will need to complete a questionnaire in order to be considered. If you are applying for SUTD because you are a man, you will need to complete a questionnaire in order to be considered. If you are applying for SUTD because you\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# non-finetune without RAG\n",
        "# TODO: the issue is the max_new_tokens is not working correctly and its generating more than it gives\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "infer_base = FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "pipe_base = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_base,\n",
        "    tokenizer= tokenizer,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 100 # keeping the token output short for speed and quality purposes\n",
        ")\n",
        "\n",
        "llm_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Question: {question}\\nAnswer:\"\n",
        ")\n",
        "chain_base = prompt | llm_base\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"[{i}/{len(questions)}] Processing question: {q}\\n\")\n",
        "    ans = chain_base.invoke(q)\n",
        "    print(f\"Answer: {ans}\\n\")\n",
        "    results.append({\"Question\": q, \"Answer\": ans})\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"no_rag_base.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "nRg8IgNwGJUB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRg8IgNwGJUB",
        "outputId": "fea36a4d-116e-4d87-aa5c-ce1572b9e0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/20] Processing question: What are the admissions deadlines for SUTD?\n",
            "\n",
            "Answer:  SUTD admissions deadlines for the 2019/2020 academic year are as follows:\n",
            "First year applicants - October 15, 2018\n",
            "Second year applicants - October 15, 2018\n",
            "Third year applicants - October 15, 2018\n",
            "Fourth year applicants - October 15, 2018\n",
            "Application materials must be submitted by October 15, 2018.\n",
            "Note: Applicants who are admitted to SUTD will be notified by February 1, \n",
            "\n",
            "[2/20] Processing question: Is there financial aid available?\n",
            "\n",
            "Answer:  Yes, there is financial aid available to all students who are in need of financial assistance. The College offers financial aid to qualified students who are in need of financial assistance. The College is committed to providing financial assistance to qualified students who are in need of financial assistance. The College provides need-based financial aid to students who meet the requirements of the College. The College also provides merit-based financial aid to students who meet the requirements of the College. The College provides need-based financial aid to students who meet the\n",
            "\n",
            "[3/20] Processing question: What is the minimum score for the Mother Tongue Language?\n",
            "\n",
            "Answer:  4.0\n",
            "Explanation: The minimum score for the Mother Tongue Language is 4.0. The minimum score for the Language Competency is 4.0. The minimum score for the Language Proficiency is 4.0.\n",
            "\n",
            "[4/20] Processing question: Do I require reference letters?\n",
            "\n",
            "Answer:  You will require a reference letter from a professional. The reference letter should be from someone who is well placed to assess your abilities and experience. They should have a good knowledge of your work and be able to comment on your suitability for the role.\n",
            "\n",
            "[5/20] Processing question: Can polytechnic diploma students apply?\n",
            "\n",
            "Answer:  Yes, Polytechnic diploma holders can apply for admission in the 2nd year of M.Sc. (Applied Geology) course.\n",
            "What is the eligibility for polytechnic diploma holders to apply for M.Sc. (Applied Geology) course?\n",
            "Can polytechnic diploma holders apply for M.Sc. (Applied Geology) course?\n",
            "No, polytechnic diploma holders cannot apply for M.Sc. (Applied Geology) course.\n",
            "What is the duration of the course?\n",
            "The duration of\n",
            "\n",
            "[6/20] Processing question: Do I need SAT score?\n",
            "\n",
            "Answer:  SAT scores are not required by most colleges and universities. However, many colleges and universities require SAT scores to be submitted. The SAT is a standardized test that measures your ability in reading, writing, math, and science.\n",
            "The SAT is a standardized test that measures your ability in reading, writing, math, and science. It is a test that is given to students who are interested in attending college. It is a test that is given to students who are interested in attending college.\n",
            "What are the requirements\n",
            "\n",
            "[7/20] Processing question: How many PhD students does SUTD have?\n",
            "\n",
            "Answer:  SUTD has 10 PhD students. They are all PhD students in the SUTD Doctoral College.\n",
            "What is the main theme of the paper?\n",
            "The main theme of the paper is that the development of robots will be very different from that of the human race. The paper will discuss the different robots and how they will develop in the future. The paper will also discuss the different types of robots and how they will be developed in the future.\n",
            "The paper will also discuss the different types of\n",
            "\n",
            "[8/20] Processing question: How much are the tuition fees for Singaporeans?\n",
            "\n",
            "Answer:  For Singaporeans, the tuition fees are not applicable. For foreigners, the tuition fees are applicable to all programmes. For Singaporeans, the tuition fees are not applicable.\n",
            "What is the tuition fee for Singaporean students?\n",
            "For Singaporean students, the tuition fee is not applicable.\n",
            "How much is the tuition fee for foreign students?\n",
            "The tuition fees for foreign students are applicable for all programmes. The tuition fees for foreign students are not applicable for Singaporeans.\n",
            "How much is the tuition fee for international students\n",
            "\n",
            "[9/20] Processing question: How much are the tuition fees for international students?\n",
            "\n",
            "Answer:  The tuition fees for international students is determined by the level of study and the type of institution. For example, for the bachelor degree, the tuition fees for international students may be higher than the tuition fees for local students. For the master degree, the tuition fees for international students may be lower than the tuition fees for local students. For the doctoral degree, the tuition fees for international students may be even lower than the tuition fees for local students.\n",
            "Answer: The tuition fees for international students are determined by\n",
            "\n",
            "[10/20] Processing question: Is there a minimum CAP?\n",
            "\n",
            "Answer:  No. The minimum CAP is 5.6.\n",
            "How do I calculate my minimum CAP?\n",
            "How is minimum CAP calculated?\n",
            "The minimum CAP is calculated by dividing the total score by 100. The minimum CAP is 5.6.\n",
            "What is the minimum CAP?\n",
            "The minimum CAP is 5.6.\n",
            "\n",
            "[11/20] Processing question: What is SUTDs mission and vision?\n",
            "\n",
            "Answer:  SUTDs mission and vision is to provide a platform for the sharing of knowledge, experience and resources among all the stakeholders in the society. SUTDs vision is to be a leading centre of excellence for the development of talent and skills in the fields of Information Technology and Business Administration.\n",
            "SUTDs mission is to develop and nurture students and staff for the purpose of creating a society where knowledge and skills are shared and where the best practices are adopted.\n",
            "SUTDs vision is to\n",
            "\n",
            "[12/20] Processing question: When was SUTD officially inaugurated?\n",
            "\n",
            "Answer:  2012\n",
            "Explanation: SUTD was officially inaugurated in 2012.\n",
            "\n",
            "[13/20] Processing question: Which core values does SUTD emphasize?\n",
            "\n",
            "Answer:  SUTD emphasizes the following core values: 1. Truth 2. Integrity 3. Respect 4. Responsibility\n",
            "Answer: SUTD emphasizes the following core values: 1. Truth 2. Integrity 3. Respect 4. Responsibility\n",
            "Answer: SUTD emphasizes the following core values: 1. Truth 2. Integrity 3. Respect 4. Responsibility\n",
            "\n",
            "[14/20] Processing question: Where is SUTD located, and how can it be contacted?\n",
            "\n",
            "Answer:  SUTD is located in the Department of Pediatrics at the University of Maryland School of Medicine, in Baltimore, Maryland, USA. The contact details are:\n",
            "Email: sutt@som.umaryland.edu\n",
            "Address: Department of Pediatrics, University of Maryland School of Medicine, 22 N. Caroline Street, Baltimore, MD 21201, USA.\n",
            "SUTD is a non-profit organization, and has no affiliated hospital.\n",
            "What is SUTD?\n",
            "SUTD (Sarcoma and\n",
            "\n",
            "[15/20] Processing question: What different SUTD offices or departments can I reach out to?\n",
            "\n",
            "Answer:  All SUTD offices or departments can be reached out to by calling 407-699-8100 or 407-699-8101. You can also email us at admissions@sutd.edu or write to us at SUTD Admissions, 301 South College Avenue, Orlando, FL 32804.\n",
            "Q: What is the admission requirement for the SUTD program?\n",
            "A: Applicants to the SUTD program are expected to have a minimum of a 3.0\n",
            "\n",
            "[16/20] Processing question: What are the key components of the Freshmore curriculum at SUTD?\n",
            "\n",
            "Answer:  The curriculum at SUTD is based on the concept of \"Freshmore\" or \"Freshman\" as it is commonly known. The curriculum is designed to be comprehensive and to cover the full spectrum of the curriculum in the first two years of a student's life. It is designed to be comprehensive in terms of the subjects that are covered, the length of time that they are covered and the number of times that they are covered. It is designed to be comprehensive in terms of the number of students\n",
            "\n",
            "[17/20] Processing question: Which elective modules are available for Freshmore students in Term 3?\n",
            "\n",
            "Answer:  The following elective modules are available for Freshmore students in Term 3:\n",
            "  1. Human Rights and Social Justice\n",
            "  2. Social Inclusion and Social Justice\n",
            "  3. Social Inclusion and Social Justice\n",
            "  4. Social Inclusion and Social Justice\n",
            "  5. Social Inclusion and Social Justice\n",
            "  6. Social Inclusion and Social Justice\n",
            "  7. Social Inclusion and Social Justice\n",
            "  8. Social Inclusion and Social\n",
            "\n",
            "[18/20] Processing question: What courses are offered within the Design and Artificial Intelligence pillar?\n",
            "\n",
            "Answer:  The Design and Artificial Intelligence pillar includes courses on the following topics:\n",
            "Design for AI\n",
            "Artificial Intelligence (AI) is a subset of the broader field of machine learning. Machine learning is the ability of machines to learn and make predictions on their own. AI is the subset of machine learning that is focused on creating machines that can make decisions and take actions based on their environment. AI is used in a wide range of applications, including healthcare, finance, and transportation. AI is also used in research and\n",
            "\n",
            "[19/20] Processing question: Who are some of the instructors teaching the courses in the DAI program?\n",
            "\n",
            "Answer:  Dr. Paul E. Johnson, Dr. Robert L. Schutt, Dr. Charles H. Hirsch, Dr. Robert S. Kohn, Dr. Robert J. Gorman, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S.\n",
            "\n",
            "[20/20] Processing question: What are the main steps involved in the SUTD application process?\n",
            "\n",
            "Answer:  The SUTD application process includes the following main steps:\n",
            "1. Online application: The first step is to complete the online application form, which includes personal details, academic and work experience, and contact information.\n",
            "2. Application fee: The applicant must pay an application fee of $60 to complete the application form.\n",
            "3. Online submission: Once the application is complete, the applicant must submit the application form electronically to the SUTD application portal.\n",
            "4. Interview: The next step is to attend\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# finetuned without RAG\n",
        "finetune_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    f\"{USERNAME}/llama-3.2-1B-sutdqa\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "infer_finetune = FastLanguageModel.for_inference(finetune_model)\n",
        "pipe_finetune = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_finetune,\n",
        "    tokenizer= tokenizer,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 100 # keeping the token output short for speed and quality purposes\n",
        ")\n",
        "llm_finetune = HuggingFacePipeline(pipeline=pipe_finetune).bind(skip_prompt=True)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Question: {question}\\nAnswer:\"\n",
        ")\n",
        "chain_finetune = prompt | llm_finetune\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"[{i}/{len(questions)}] Processing question: {q}\\n\")\n",
        "    ans = chain_base.invoke(q)\n",
        "    print(f\"Answer: {ans}\\n\")\n",
        "    results.append({\"Question\": q, \"Answer\": ans})\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"no_rag_finetune.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "R578KyTBGJHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R578KyTBGJHM",
        "outputId": "aed7f0aa-e52a-4075-a263-f345a2529752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ 1/20 ] Processing: What are the admissions deadlines for SUTD?\n",
            "Context snippets: # Graduate Admission... | We only accept appli... | # Admission Requirem...\n",
            "Answer:  Answer: Application closes: 13 April 2025 (September 2025 intake)\n",
            "    Question: What are the minimum requirements for admission to SUTD?\n",
            "     Answer: Find out more about the minimum academic requirements for admission for the qualification you are applying under here:\n",
            "\n",
            "    * [Singapore-Cambridge GCE A-Level](https://www.sutd.edu.sg/admissions/undergraduate/singapore-cambridge-gce-a-level/criteria-for-admission)\n",
            "    * [Local\n",
            "\n",
            "\n",
            "[ 2/20 ] Processing: Is there financial aid available?\n",
            "Context snippets: - **UPLOAD** the sup... | In your appeal, plea... | We endeavour to prov...\n",
            "Answer:  Answer: Yes. You may apply for [financial aid](https://www.sutd.edu.sg/admissions/undergraduate/financing-options-and-aid/financial-aid/) and/or [scholarships administered by SUTD](https://www.sutd.edu.sg/admissions/undergraduate/scholarship/sutd-administered/). You may also apply for [Tuition Grant](https://www.sutd.edu.sg/admissions/undergraduate/education-exp\n",
            "\n",
            "\n",
            "[ 3/20 ] Processing: What is the minimum score for the Mother Tongue Language?\n",
            "Context snippets: 1. Successfully comp... | - The minor will be ... | English proficiency ...\n",
            "Answer:  Answer: 60%\n",
            "    Question: What is the minimum score for the Personal Insight Question?\n",
            "     Answer: 60%\n",
            "    Question: What is the minimum score for the Recommendation/Testimonial?\n",
            "     Answer: 60%\n",
            "    Question: What is the minimum score for the Outstanding/ Relevant Achievements?\n",
            "     Answer: 60%\n",
            "    Question: What is the minimum score for the Academic Transcript?\n",
            "     Answer: 60%\n",
            "\n",
            "## Academic Transcript\n",
            "- The minimum grade requirement for the academic transcript is\n",
            "\n",
            "\n",
            "[ 4/20 ] Processing: Do I require reference letters?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | # Admission Requirem...\n",
            "Answer:  Answer: Yes. At least one reference letter should be provided by a teacher from your school or any other relevant educational institution.\n",
            "    Question: Do I require a reference letter from an employer?\n",
            "     Answer: No. You may submit your own reference letter instead.\n",
            "\n",
            "### Testimonials\n",
            "\n",
            "    Question: Do I require a testimonial?\n",
            "     Answer: Yes. You may submit your own testimonial instead.\n",
            "\n",
            "### Qualities and traits\n",
            "\n",
            "    Question: Do I require a reference letter?\n",
            "     Answer: Yes\n",
            "\n",
            "\n",
            "[ 5/20 ] Processing: Can polytechnic diploma students apply?\n",
            "Context snippets: # Admission Requirem... | ### Frequently Asked... | ## Contact Informati...\n",
            "Answer:  Answer: Yes. Students with polytechnic diploma who have completed 2 years of polytechnic education will be eligible to apply for admission to SUTDs undergraduate programme. Students who have completed 3 years of polytechnic education will be eligible to apply for admission to SUTDs undergraduate programme.\n",
            "\n",
            "    Question: Can diploma holders with 2 years of diploma education apply?\n",
            "     Answer: Yes. Diploma holders with 2 years of diploma education will be eligible to apply for admission to\n",
            "\n",
            "\n",
            "[ 6/20 ] Processing: Do I need SAT score?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | The selection will b...\n",
            "Answer:  Answer: No, you don't need SAT score to apply to SUTD. We will accept your application without SAT score, as long as you have the required grades in the following subjects.\n",
            "    Question: Can I apply for SUTD without having the required grades?\n",
            "     Answer: No. We will accept your application without having the required grades in the following subjects. However, you will need to show your interest in SUTD through your application, such as your strong grades in Mathematics and\n",
            "\n",
            "\n",
            "[ 7/20 ] Processing: How many PhD students does SUTD have?\n",
            "Context snippets: # Graduate Admission... | [Apply now](https://... | 3. **What type of st...\n",
            "Answer:  Answer: 1500\n",
            "\n",
            "\n",
            "\n",
            "[ 8/20 ] Processing: How much are the tuition fees for Singaporeans?\n",
            "Context snippets: - **UPLOAD** the sup... | ### Contact Informat... | Please submit only o...\n",
            "Answer:  Answer: The tuition fees for Singaporean students are at least S$1,200 per year. The fees for International students are at least S$1,600 per year.\n",
            "\n",
            "    Question: What is the minimum age for admission?\n",
            "     Answer: The minimum age for admission is 16 years old.\n",
            "\n",
            "    Question: What is the maximum age for admission?\n",
            "     Answer: The maximum age for admission is 23 years old.\n",
            "\n",
            "    Question: What is the minimum English proficiency?\n",
            "     Answer: The\n",
            "\n",
            "\n",
            "[ 9/20 ] Processing: How much are the tuition fees for international students?\n",
            "Context snippets: - **UPLOAD** the sup... | Please submit only o... | # Graduate Admission...\n",
            "Answer:  Answer: We are pleased to inform you that Singapore citizens and Singapore Permanent Residents will be charged the same tuition fees as local students. We will be able to offer the same scholarship to Singapore Citizens and Singapore Permanent Residents as local students. We will be able to offer the same tuition fees as local students. We will be able to offer the same scholarship to Singapore Citizens and Singapore Permanent Residents as local students.\n",
            "    Question: How much are the tuition fees for international students?\n",
            "     Answer: We are pleased to\n",
            "\n",
            "\n",
            "[ 10/20 ] Processing: Is there a minimum CAP?\n",
            "Context snippets: These are mandatory ... | - The minor will be ... | 1. Successfully comp...\n",
            "Answer:  Answer: Yes. The minimum CAP is 6.0.\n",
            "\n",
            "    Question: How many credits are there for a minor?\n",
            "     Answer: There are 60 credits for a minor.\n",
            "\n",
            "    Question: What is the minimum CAP for a minor?\n",
            "     Answer: The minimum CAP is 6.0.\n",
            "\n",
            "    Question: How many credits are there for a minor?\n",
            "     Answer: There are 60 credits for a minor.\n",
            "\n",
            "    Question: What is the minimum CAP for a minor?\n",
            "     Answer:\n",
            "\n",
            "\n",
            "[ 11/20 ] Processing: What is SUTDs mission and vision?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | This unique approach... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Context: ## Our Mission\n",
            "**To redefine design, education and research, and draw on multiple disciplines to make a positive impact on society. We nurture technically-grounded leaders, who embrace risks and innovate towards a better tomorrow.**\n",
            "\n",
            "    Question: What is SUTDs core value?\n",
            "    Context: ## Our Core Values\n",
            "- Leadership\n",
            "- Integrity\n",
            "- Passion\n",
            "- Collaboration\n",
            "- Creativity\n",
            "\n",
            "    Question: What is SUTDs vision?\n",
            "    Context: ## Our Vision\n",
            "\n",
            "\n",
            "\n",
            "[ 12/20 ] Processing: When was SUTD officially inaugurated?\n",
            "Context snippets: This unique approach... | # AY2024 onwards\n",
            "\n",
            "*I... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: 18 July 2012\n",
            "    Question: What is SUTD's motto?\n",
            "     Answer: \"Society, Technology, Unity\"\n",
            "    Question: What is the name of the university's mascot?\n",
            "    Answer: The \"Sutradhar\"\n",
            "    Question: What is the university's motto?\n",
            "    Answer: \"Society, Technology, Unity\"\n",
            "    Question: What is the name of the university's mascot?\n",
            "    Answer: The \"Sutradhar\"\n",
            "    Question\n",
            "\n",
            "\n",
            "[ 13/20 ] Processing: Which core values does SUTD emphasize?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | The selection will b... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: Our core values are Leadership, Integrity, Passion, Collaboration, Creativity and Resilience.\n",
            "    Question: What is the vision of SUTD?\n",
            "    Answer: To redefine design, education and research, and draw on multiple disciplines to make a positive impact on society.\n",
            "    Question: How does SUTD achieve its vision?\n",
            "    Answer: To achieve our vision, we nurture technically-grounded leaders, who embrace risks and innovate towards a better tomorrow.\n",
            "    Question: What is the\n",
            "\n",
            "\n",
            "[ 14/20 ] Processing: Where is SUTD located, and how can it be contacted?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | This unique approach... | ### Contact Informat...\n",
            "Answer:  Answer: SUTD is located at 8 Somapah Road Singapore 487372. It can be contacted at +65 6303 6600 / +65 6303 6655 / [enquiry@sutd.edu.sg](mailto:enquiry@sutd.edu.sg) / [admissions@sutd.edu.sg](mailto:admissions@sutd.edu.sg)\n",
            "\n",
            "\n",
            "\n",
            "[ 15/20 ] Processing: What different SUTD offices or departments can I reach out to?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | **Consultations:** W... | 3. **What type of st...\n",
            "Answer:  Answer: SUTD has several departments and offices. Please refer to the [Faculty Directory](https://www.sutd.edu.sg/about/people/faculty) to find faculty by name or research areas. You can also reach out to the [Admissions Office](https://www.sutd.edu.sg/admissions/undergraduate/ask-admissions/) or [Graduate Admissions Office](https://www.sutd.edu.sg/gradoffice/) to ask for a specific type of programme\n",
            "\n",
            "\n",
            "[ 16/20 ] Processing: What are the key components of the Freshmore curriculum at SUTD?\n",
            "Context snippets: Some key elements of... | # Freshmore Subjects... | Learn more about our...\n",
            "Answer:  Answer: The Freshmore curriculum at SUTD consists of the following components:\n",
            "        - **Foundation:** The first three terms are common to all students and build the foundation in [Science, Mathematics and Technology (SMT)](https://www.sutd.edu.sg/smt), [Humanities, Arts and Social Sciences (HASS)](https://www.sutd.edu.sg/hass) and design.\n",
            "        - **Freshmore Subjects:** Having completed a review and revamp, S\n",
            "\n",
            "\n",
            "[ 17/20 ] Processing: Which elective modules are available for Freshmore students in Term 3?\n",
            "Context snippets: ### Extra Courses\n",
            "Fr... | In addition, record ... | Students may choose ...\n",
            "Answer:  Answer: Freshmore students in Term 3 have the following options:\n",
            "     - [Science and Technology for Healthcare](https://www.sutd.edu.sg/course/10-019-science-and-technology-for-healthcare-elective/)  Elective\n",
            "     - [Data Driven World](https://www.sutd.edu.sg/course/10-020/data-driven-world-elective/)  Elective\n",
            "     - [Designing Energy Systems](https://www.sutd.edu.sg/course/\n",
            "\n",
            "\n",
            "[ 18/20 ] Processing: What courses are offered within the Design and Artificial Intelligence pillar?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Input IDs of length 3236 > the model's max sequence length of 2048.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context snippets: # ISTD Curriculum\n",
            "\n",
            "U... | # DAI Curriculum - D... | # Minor in Artificia...\n",
            "Answer: 045\n",
            "\n",
            "\n",
            "\n",
            "[ 19/20 ] Processing: Who are some of the instructors teaching the courses in the DAI program?\n",
            "Context snippets: # DAI Courses\n",
            "\n",
            "## Un... | # DAI Curriculum - D... | # DAI Specialisation...\n",
            "Answer:  Answer: Our instructors are from the following departments and schools: \n",
            "    - Computer Science & Engineering, School of Engineering & Science, Nanyang Technological University, Singapore.\n",
            "    - Humanities, School of Humanities & Social Sciences, Nanyang Technological University, Singapore.\n",
            "    - Science, School of Humanities & Social Sciences, Nanyang Technological University, Singapore.\n",
            "    - Social Science, School of Humanities & Social Sciences, Nanyang Technological University, Singapore.\n",
            "    - Social Science\n",
            "\n",
            "\n",
            "[ 20/20 ] Processing: What are the main steps involved in the SUTD application process?\n",
            "Context snippets: # Appeal\n",
            "\n",
            "SUTDs hol... | # Admission Requirem... | - **UPLOAD** the sup...\n",
            "Answer:  Answer: The application process involves the following steps:\n",
            "     1. Register with SUTD\n",
            "     2. Submit the application form\n",
            "     3. Upload the supporting documents\n",
            "     4. Answer the questions\n",
            "     5. Attend the interview\n",
            "     6. Make a decision\n",
            "    Question: How do I know if I am successful in my application?\n",
            "    Answer: If you are successful in your application, you will be invited to attend an interview at SUTD\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# nonfinetuned with RAG\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "infer_base = FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "# pipeline from huggignface\n",
        "pipe_base_rag = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=infer_base,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=100\n",
        ")\n",
        "\n",
        "# langchain pipeline for integration\n",
        "base_rag = HuggingFacePipeline(pipeline=pipe_base_rag).bind(skip_prompt=True)\n",
        "\n",
        "# prompt template\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Use the following context to answer the question.\".\n",
        "    Keep your response concise (no more than 3 sentences) and based only on the context. If the context doesn't have the answer, say \"I don't know\".\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "rag_chain_base = RetrievalQA.from_chain_type(\n",
        "    llm=base_rag,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=compression_retriever, # use the rerank retriever\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
        ")\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"\\n[ {i}/{len(questions)} ] Processing: {q}\")\n",
        "    try:\n",
        "        result = rag_chain_base.invoke({\"query\": q})\n",
        "        ans = result[\"result\"]\n",
        "\n",
        "        full_contexts = [doc.page_content for doc in result[\"source_documents\"]]  # full contexts\n",
        "        # to debug adding few characters to print out\n",
        "        context_str = \" | \".join([doc.page_content[:20] + '...' for doc in result[\"source_documents\"]])  # Truncated for print\n",
        "\n",
        "        print(f\"Context snippets: {context_str}\")\n",
        "        print(f\"Answer: {ans}\\n\")\n",
        "\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": ans,\n",
        "            \"Context\": full_contexts  # store full contexts as a list\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": \"Error generating response\",\n",
        "            \"Context\": []\n",
        "        })\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"rag_base.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "TK1DwymPGI_u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK1DwymPGI_u",
        "outputId": "b6db1170-ec35-436a-b5d7-3e874d3b511f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ 1/20 ] Processing: What are the admissions deadlines for SUTD?\n",
            "Context snippets: # Graduate Admission... | We only accept appli... | # Admission Requirem...\n",
            "Answer:  Answer: We accept applications year-round, but generally, you'll find the best chances to get in around September. Check the specific program you're interested in! [See the deadlines](https://www.sutd.edu.sg/admissions/undergraduate/apply-now/). ## What's the best time to apply? We encourage you to apply early! [See the deadlines](https://www.sutd.edu.sg/admissions/undergraduate/apply-now/). ## How are my grades and\n",
            "\n",
            "\n",
            "[ 2/20 ] Processing: Is there financial aid available?\n",
            "Context snippets: - **UPLOAD** the sup... | In your appeal, plea... | We endeavour to prov...\n",
            "Answer:  Answer: Yes, check the financial aid section of the university's website. Also, check the university's financial aid office for specific scholarships and grants. You'll need to submit a financial aid application, usually online. Check the university's financial aid website for specific deadlines and requirements. |\n",
            "| Question: What scholarships are available for international students?\n",
            "     Answer: Check the university's website or financial aid office for scholarships specific to international students. You'll need to apply for scholarships, usually online. Check the\n",
            "\n",
            "\n",
            "[ 3/20 ] Processing: What is the minimum score for the Mother Tongue Language?\n",
            "Context snippets: 1. Successfully comp... | - The minor will be ... | English proficiency ...\n",
            "Answer:  Answer: 0.5. - Question: What is the minimum score for the English Proficiency Test?\n",
            "     Answer: 0.5. - Question: What is the minimum score for the Personal Insight Questions?\n",
            "     Answer: 0.5. - Question: What is the minimum score for the Recommendation/Testimonial?\n",
            "     Answer: 0.5. - Question: What is the minimum score for the Outcomes/Relevant Achievements?\n",
            "     Answer: 0.5.\n",
            "\n",
            "\n",
            "[ 4/20 ] Processing: Do I require reference letters?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | # Admission Requirem...\n",
            "Answer:  Answer: Yes, you need to provide at least one reference letter from someone who knows you well academically (e.g. your teacher from High School/Polytechnic) or professionally (your internship or work supervisor) and for at least half a year recently. Do seek your referee(s) consent before listing them. \n",
            "\n",
            "    Question: What are the minimum grades I need to get into SUTD?\n",
            "     Answer: Find out more about the minimum academic requirements for admission for the qualification\n",
            "\n",
            "\n",
            "[ 5/20 ] Processing: Can polytechnic diploma students apply?\n",
            "Context snippets: # Admission Requirem... | ### Frequently Asked... | ## Contact Informati...\n",
            "Answer:  Answer: Yes, but you'll need to meet our Freshmore requirements, which usually include a minimum GPA and standardized test scores. Check the specific diploma you're interested in for details!\n",
            "\n",
            "\n",
            "[ 6/20 ] Processing: Do I need SAT score?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | The selection will b...\n",
            "Answer:  Answer: No, you don't need SAT score to apply. We'll consider your grades and test scores. Check your application for details.\n",
            "\n",
            "    Question: What's the minimum SAT score I need to apply?\n",
            "     Answer: It varies! Check your specific application for the minimum score. We usually prefer above 1100, but it's not a hard rule. We'll consider your grades and test scores too. Check your application for details.\n",
            "\n",
            "    Question: Do I need to submit my SAT scores\n",
            "\n",
            "\n",
            "[ 7/20 ] Processing: How many PhD students does SUTD have?\n",
            "Context snippets: # Graduate Admission... | [Apply now](https://... | 3. **What type of st...\n",
            "Answer:  Answer: SUTD has around 100 PhD students. [Check the program's website](https://www.sutd.edu.sg/programme-listing/) for the most up-to-date information!\n",
            "\n",
            "\n",
            "[ 8/20 ] Processing: How much are the tuition fees for Singaporeans?\n",
            "Context snippets: - **UPLOAD** the sup... | ### Contact Informat... | Please submit only o...\n",
            "Answer:  Answer: Around S$40,000 per year, or about S$3,000 per semester. - **UPLOAD** a copy of the front and back of your tuition fee statement. |\n",
            "| **Scholarships and Financial Aid** |  \n",
            "- **UPLOAD** any scholarship and financial aid award letters. - Declare if you are eligible for scholarships and/or financial aid. - If you are applying for scholarships and/or financial aid, **UPLOAD** any supporting documents you have. |\n",
            "| **Special\n",
            "\n",
            "\n",
            "[ 9/20 ] Processing: How much are the tuition fees for international students?\n",
            "Context snippets: - **UPLOAD** the sup... | Please submit only o... | # Graduate Admission...\n",
            "Answer:  Answer: International students pay full tuition. See [Tuition and Fees](https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/fees/) for details. |\n",
            "    Question: Are there any scholarships or financial aid for international students?\n",
            "     Answer: Yes, see [Tuition and Fees](https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/fees/) and [Scholarships and Financial Aid](https://www.s\n",
            "\n",
            "\n",
            "[ 10/20 ] Processing: Is there a minimum CAP?\n",
            "Context snippets: These are mandatory ... | - The minor will be ... | 1. Successfully comp...\n",
            "Answer:  Answer: Yes, the minimum CAP is usually 2.0 or higher. Check the specific minor's requirements for the exact minimum CAP. - If you don't meet the minimum CAP, you'll have to submit a request to change your minor. Make sure you have the right courses and grades to qualify! - Also, check the specific minor's requirements for the specific pillar. Some minors require specific courses from specific pillars. - You can't just take any courses and expect to graduate. Make sure\n",
            "\n",
            "\n",
            "[ 11/20 ] Processing: What is SUTDs mission and vision?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | This unique approach... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: Our mission is to redefine design, education and research, and draw on multiple disciplines to make a positive impact on society. Our vision is to be a global leader in design, AI and technology education and research. We aim to empower students to think creatively, innovate and tackle real-world problems.\n",
            "\n",
            "\n",
            "[ 12/20 ] Processing: When was SUTD officially inaugurated?\n",
            "Context snippets: This unique approach... | # AY2024 onwards\n",
            "\n",
            "*I... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: SUTD was officially inaugurated in July 2009 as Singapore's fourth publicly funded university. It was established in collaboration with the Massachusetts Institute of Technology (MIT).\n",
            "\n",
            "# SUTD's Research\n",
            "\n",
            "SUTD's research spans many fields, including: \n",
            "\n",
            "    Question: What types of research does SUTD focus on?\n",
            "    Answer: SUTD's research focuses on areas like: \n",
            "\n",
            "* **Computer science and engineering**  Research in areas like: \n",
            "\n",
            "* **Mech\n",
            "\n",
            "\n",
            "[ 13/20 ] Processing: Which core values does SUTD emphasize?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | The selection will b... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: We prioritize leadership, integrity, passion, collaboration, creativity, and innovation. We also value diversity, inclusivity, and sustainability. Check the [SUTD website](https://www.sutd.edu.sg/) for more details!\n",
            "\n",
            "\n",
            "[ 14/20 ] Processing: Where is SUTD located, and how can it be contacted?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | This unique approach... | ### Contact Informat...\n",
            "Answer:  Answer: SUTD is located in Singapore, and can be contacted via phone, email, or address. See [SUTD Website](https://www.sutd.edu.sg/asd/) for contact info.\n",
            "\n",
            "\n",
            "[ 15/20 ] Processing: What different SUTD offices or departments can I reach out to?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | **Consultations:** W... | 3. **What type of st...\n",
            "Answer:  Answer: You can reach out to the EPD, Student Administration, Student Life, Career Development, Capstone Programme, Enquiries on Technology Licensing Opportunities, and Enquiries on Industry Collaboration offices. You can also reach out to the Faculty Directory to find specific faculty by name or research areas.\n",
            "\n",
            "\n",
            "[ 16/20 ] Processing: What are the key components of the Freshmore curriculum at SUTD?\n",
            "Context snippets: Some key elements of... | # Freshmore Subjects... | Learn more about our...\n",
            "Answer:  Answer: Some key elements of the revamped and enhanced curriculum include: 1. A review and revamp of the core subjects in [Science, Mathematics and Technology (SMT)](https://www.sutd.edu.sg/smt), [Humanities, Arts and Social Sciences (HASS)](https://www.sutd.edu.sg/hass) and design. 2. Freshmore core courses. 3. Freshmore elective courses. 4. Core electives. 5\n",
            "\n",
            "\n",
            "[ 17/20 ] Processing: Which elective modules are available for Freshmore students in Term 3?\n",
            "Context snippets: ### Extra Courses\n",
            "Fr... | In addition, record ... | Students may choose ...\n",
            "Answer:  Answer: Check the course descriptions for each term! You can find all Freshmore courses at [SUTD Courses](https://www.sutd.edu.sg/istd/education/undergraduate/courses/). ## How are Freshmore courses different from other courses? Are they more focused on specific fields or industries? What kind of skills are they designed to develop? What kinds of projects do they usually involve? Are they related to career fields like engineering, business, or creative arts? What\n",
            "\n",
            "\n",
            "[ 18/20 ] Processing: What courses are offered within the Design and Artificial Intelligence pillar?\n",
            "Context snippets: # ISTD Curriculum\n",
            "\n",
            "U... | # DAI Curriculum - D... | # Minor in Artificia...\n",
            "Answer: 045 - 20.318 Creative Machine Learning 50.039 Theory and Practice of Deep Learning 50.040 Natural Language Processing 50.045 Information Retrieval 50.007 Machine Learning 50.003 Elements of Software Construction 50.004 Algorithms 50.035 Computer Vision 50.038 Computational Data Science 50.041 Information Retrieval 50.040 Natural Language Processing 50.041 Information Retrieval 50.040 Natural Language Processing 50.035 Computer Vision \n",
            "\n",
            "\n",
            "[ 19/20 ] Processing: Who are some of the instructors teaching the courses in the DAI program?\n",
            "Context snippets: # DAI Courses\n",
            "\n",
            "## Un... | # DAI Curriculum - D... | # DAI Specialisation...\n",
            "Answer:  Answer: Check the course syllabus for course-specific info. You can also ask your professor directly for names! It's usually best to ask before you sign up for a course. \n",
            "\n",
            "    Question: Are there any opportunities to work with industry on projects outside of class?\n",
            "     Answer: Check the course syllabus! Some courses offer industry connections. Ask your professor for details. Also, check the course description for details on what projects are included. \n",
            "\n",
            "    Question: Does the DAI program offer any\n",
            "\n",
            "\n",
            "[ 20/20 ] Processing: What are the main steps involved in the SUTD application process?\n",
            "Context snippets: # Appeal\n",
            "\n",
            "SUTDs hol... | # Admission Requirem... | - **UPLOAD** the sup...\n",
            "Answer:  Answer: Check the [admissions website](https://www.sutd.edu.sg/admissions) for details! It's usually a holistic process, including the application, essays, interviews, and often an on-campus visit. Good luck!\n",
            "\n",
            "    Question: How does SUTD evaluate my academic record and grades?\n",
            "     Answer: They look at your grades and achievements, including test scores, projects, and courses. It's important to show that you're prepared for college! Good luck.\n",
            "\n",
            "    Question\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# finetuned with RAG\n",
        "finetune_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    f\"{USERNAME}/llama-3.2-1B-sutdqa\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "infer_finetune = FastLanguageModel.for_inference(finetune_model)\n",
        "\n",
        "# pipeline from huggingface\n",
        "pipe_ft_rag = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=infer_finetune,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=100\n",
        ")\n",
        "\n",
        "# langchain pipeline for integration\n",
        "finetune_rag = HuggingFacePipeline(pipeline=pipe_ft_rag).bind(skip_prompt=True)\n",
        "\n",
        "# prompt template\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Use the following context to answer the question.\".\n",
        "    Keep your response concise (no more than 3 sentences) and based only on the context. If the context doesn't have the answer, say \"I don't know\".\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "rag_chain_finetune = RetrievalQA.from_chain_type(\n",
        "    llm=finetune_rag,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=compression_retriever, # use the rerank retriever\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
        ")\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"\\n[ {i}/{len(questions)} ] Processing: {q}\")\n",
        "    try:\n",
        "        result = rag_chain_finetune.invoke({\"query\": q})\n",
        "        ans = result[\"result\"]\n",
        "\n",
        "        full_contexts = [doc.page_content for doc in result[\"source_documents\"]]  # full contexts\n",
        "        # to debug adding few characters to print out\n",
        "        context_str = \" | \".join([doc.page_content[:20] + '...' for doc in result[\"source_documents\"]])  # Truncated for print\n",
        "\n",
        "        print(f\"Context snippets: {context_str}\")\n",
        "        print(f\"Answer: {ans}\\n\")\n",
        "\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": ans,\n",
        "            \"Context\": full_contexts  # store full contexts as a list\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": \"Error generating response\",\n",
        "            \"Context\": []\n",
        "        })\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"rag_finetune.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973e2fdb-348c-45d4-8f6e-0bbf5136ec87",
      "metadata": {
        "id": "973e2fdb-348c-45d4-8f6e-0bbf5136ec87"
      },
      "source": [
        "# Bonus points: LLM-as-judge evaluation\n",
        "\n",
        "Implement an LLM-as-judge pipeline to assess the quality of the different system (finetuned vs. non-fintuned, RAG vs no RAG)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "41db185b",
      "metadata": {
        "id": "41db185b"
      },
      "outputs": [],
      "source": [
        "class Result(BaseModel):\n",
        "    # read article at:  https://medium.com/data-analytics-at-nesta/llm-evaluation-essentials-from-llm-as-a-judge-to-perplexity-part-1-04294bfff304\n",
        "    # the metrics for judging rag are faithfulness, relevance, completeness\n",
        "    pair_id: int\n",
        "    faithfulness: float = Field(description=\"Score from 0-5 measuring factual accuracy\", ge=0, le=5) # the ge and le are to ensure the score is between 0 and 5 (pydantic is amazing!)\n",
        "    relevance: float = Field(description=\"Score from 0-5 measuring how well the answer addresses the question\", ge=0, le=5)\n",
        "    completeness: float = Field(description=\"Score from 0-5 measuring how comprehensive the answer is\", ge=0, le=5)\n",
        "    overall_score: float = Field(description=\"Overall score from 0-5 based on all dimensions\", ge=0, le=5)\n",
        "\n",
        "class Evaluation(BaseModel):\n",
        "    results: List[Result] = Field(description=\"List of evaluation results for each Q&A pair\")\n",
        "\n",
        "class Judge:\n",
        "    def __init__(self, batch_size=5):\n",
        "        self.model = ChatGoogleGenerativeAI(\n",
        "            google_api_key=os.getenv(\"GOOGLE_GENAI_API_KEY\"),\n",
        "            model=\"gemini-2.0-flash\", # my thoughts was going to openai but flash is a bbetter model and free!\n",
        "            temperature=0,\n",
        "            convert_system_message_to_human=True\n",
        "        )\n",
        "        self.batch_size = batch_size\n",
        "        self.parser = JsonOutputParser(pydantic_object=Evaluation)\n",
        "\n",
        "    # evaluate a batch of questions and answers instead of a single pair to speed up and save cost\n",
        "    def evaluate_batch(self, questions, answers):\n",
        "        # prompt template\n",
        "        # the idea is to pass in a list of pairs and have the model evaluate them one by one\n",
        "\n",
        "        # THE PROMPT WAS GENERATED BY GEMINI-2.5-FLASH\n",
        "        prompt_template = PromptTemplate(\n",
        "            template=(\n",
        "                \"Evaluate each question-answer pair using the following metrics. For each pair, assign scores from 0 to 5 as follows:\\n\\n\"\n",
        "                \"1. Faithfulness: Assess how factually accurate the answer is. A score of 5 means the answer is completely correct with no invented details; a score of 0 indicates significant inaccuracies or hallucinations.\\n\\n\"\n",
        "                \"2. Relevance: Evaluate how directly the answer addresses the question asked. A score of 5 means the answer is perfectly on-topic; a score of 0 means it is completely off-topic.\\n\\n\"\n",
        "                \"3. Completeness: Determine whether the answer covers all important aspects of the question. A score of 5 implies a thorough and comprehensive answer; a score of 0 means key information is missing.\\n\\n\"\n",
        "                \"4. Overall score: Provide a weighted average summarizing the above metrics into a single score (0-5).\\n\\n\"\n",
        "                \"Below are the question-answer pairs:\\n\"\n",
        "                \"{qa_pairs}\\n\\n\"\n",
        "                \"{format_instructions}\"\n",
        "            ),\n",
        "            input_variables=[\"qa_pairs\"],\n",
        "            partial_variables={\"format_instructions\": self.parser.get_format_instructions()},\n",
        "        )\n",
        "\n",
        "        qa_text = \"\"\n",
        "        for i, (q, a) in enumerate(zip(questions, answers)):\n",
        "            qa_text += f\"PAIR {i+1}:\\nQuestion: {q}\\nAnswer: {a}\\n\\n\"\n",
        "\n",
        "        # create a chain\n",
        "        chain = prompt_template | self.model | self.parser\n",
        "        result = chain.invoke({\"qa_pairs\": qa_text})\n",
        "        return result[\"results\"]\n",
        "\n",
        "# now create a function to evaluate a file and save the results to a csv file\n",
        "def evaluate_file(file_path, evaluator):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # adding columns for faithfulness, relevance, completeness, and overall_score\n",
        "    df['faithfulness'] = np.nan\n",
        "    df['relevance'] = np.nan\n",
        "    df['completeness'] = np.nan\n",
        "    df['overall_score'] = np.nan\n",
        "    questions_list = df['Question'].tolist()\n",
        "    answers_list = df['Answer'].tolist()\n",
        "\n",
        "    total_pairs = len(questions_list)\n",
        "    batch_size = evaluator.batch_size\n",
        "\n",
        "    # going through the questions and answers in batches which is set to 5\n",
        "    for i in range(0, total_pairs, batch_size):\n",
        "        end_idx = min(i + batch_size, total_pairs)\n",
        "        batch_questions = questions_list[i:end_idx]\n",
        "        batch_answers = answers_list[i:end_idx]\n",
        "\n",
        "        print(f\"Processing batch {i//batch_size + 1}/{(total_pairs + batch_size - 1)//batch_size} for {file_path}\")\n",
        "        print(f\"Processing batch {i//batch_size + 1}/{(total_pairs + batch_size - 1)//batch_size} for {file_path}\")\n",
        "\n",
        "        batch_results = evaluator.evaluate_batch(batch_questions, batch_answers)\n",
        "\n",
        "        for j, result in enumerate(batch_results):\n",
        "            df_idx = i + j\n",
        "            df.loc[df_idx, 'faithfulness'] = result['faithfulness']\n",
        "            df.loc[df_idx, 'relevance'] = result['relevance']\n",
        "            df.loc[df_idx, 'completeness'] = result['completeness']\n",
        "            df.loc[df_idx, 'overall_score'] = result['overall_score']\n",
        "        # push it to the csv file\n",
        "        df.to_csv(f\"evaluated_{os.path.basename(file_path)}\", index=False)\n",
        "\n",
        "    return df\n",
        "\n",
        "# now create a function to find the best model based on overall score\n",
        "def find_best_model(results_dict):\n",
        "    model_scores = {}\n",
        "\n",
        "    for model_name, df in results_dict.items():\n",
        "        # get mean scores for all metrics\n",
        "        faithfulness = df['faithfulness'].mean()\n",
        "        relevance = df['relevance'].mean()\n",
        "        completeness = df['completeness'].mean()\n",
        "        overall = df['overall_score'].mean()\n",
        "\n",
        "        model_scores[model_name] = {\n",
        "            'faithfulness': faithfulness,\n",
        "            'relevance': relevance,\n",
        "            'completeness': completeness,\n",
        "            'overall_score': overall\n",
        "        }\n",
        "\n",
        "    # find best model based on overall score\n",
        "    best_model = max(model_scores.items(), key=lambda x: x[1]['overall_score'])[0]\n",
        "    best_score = model_scores[best_model]['overall_score']\n",
        "    return best_model, best_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "613d1d24",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating no_rag_base.csv...\n",
            "Processing batch 1/4 for no_rag_base.csv\n",
            "Processing batch 1/4 for no_rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 2/4 for no_rag_base.csv\n",
            "Processing batch 2/4 for no_rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 3/4 for no_rag_base.csv\n",
            "Processing batch 3/4 for no_rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 4/4 for no_rag_base.csv\n",
            "Processing batch 4/4 for no_rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating no_rag_finetune.csv...\n",
            "Processing batch 1/4 for no_rag_finetune.csv\n",
            "Processing batch 1/4 for no_rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 2/4 for no_rag_finetune.csv\n",
            "Processing batch 2/4 for no_rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 3/4 for no_rag_finetune.csv\n",
            "Processing batch 3/4 for no_rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 4/4 for no_rag_finetune.csv\n",
            "Processing batch 4/4 for no_rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating rag_base.csv...\n",
            "Processing batch 1/4 for rag_base.csv\n",
            "Processing batch 1/4 for rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 2/4 for rag_base.csv\n",
            "Processing batch 2/4 for rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 3/4 for rag_base.csv\n",
            "Processing batch 3/4 for rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 4/4 for rag_base.csv\n",
            "Processing batch 4/4 for rag_base.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating rag_finetune.csv...\n",
            "Processing batch 1/4 for rag_finetune.csv\n",
            "Processing batch 1/4 for rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 2/4 for rag_finetune.csv\n",
            "Processing batch 2/4 for rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 3/4 for rag_finetune.csv\n",
            "Processing batch 3/4 for rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 4/4 for rag_finetune.csv\n",
            "Processing batch 4/4 for rag_finetune.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring factual accuracy' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how well the answer addresses the question' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Score from 0-5 measuring how comprehensive the answer is' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='Overall score from 0-5 based on all dimensions' ge=0 le=5 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='List of evaluation results for each Q&A pair' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best performing model: rag_finetune.csv with overall score: 3.5998333333333337\n"
          ]
        }
      ],
      "source": [
        "# finally calling the llm as a judge\n",
        "judge = Judge(batch_size=5)\n",
        "files = [\n",
        "    \"no_rag_base.csv\",\n",
        "    \"no_rag_finetune.csv\",\n",
        "    \"rag_base.csv\",\n",
        "    \"rag_finetune.csv\"\n",
        "]\n",
        "\n",
        "results = {}\n",
        "for file in files:\n",
        "    print(f\"\\nEvaluating {file}...\")\n",
        "    results[file] = evaluate_file(file, judge)\n",
        "\n",
        "best_model, best_score = find_best_model(results)\n",
        "print(f\"\\nBest performing model: {best_model} with overall score: {best_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f8ceb9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "metrics = ['faithfulness', 'relevance', 'completeness', 'overall_score']\n",
        "model_names = list(results.keys())\n",
        "scores = {model: [results[model][metric].mean() for metric in metrics] for model in model_names}\n",
        "\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.2\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "for i, model in enumerate(model_names):\n",
        "    offset = (i - (len(model_names)-1)/2) * width\n",
        "    ax.bar(x + offset, scores[model], width, label=model)\n",
        "\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Average Score')\n",
        "ax.set_title('Model Comp')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig('images/llm_judge_results.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41551f6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#we also tried to use llm-as-a-judge to evaluate pairwise answers from 2 different models, asking the LLM to judge which answer is better\n",
        "class PairwiseJudgeOutput(BaseModel):\n",
        "    #using pydantic to havae structured LLM output\n",
        "    decision: Literal[\"Model 1\", \"Model 2\"] = Field(description=\"Which model response is better?\") #only allow Model 1 or Model 2 as valid output\n",
        "    explanation: str = Field(description=\"Short explanation for why the selected answer is better\")\n",
        "\n",
        "class PairwiseJudge:\n",
        "    def __init__(self):\n",
        "        #initialise gemini model\n",
        "        self.model = ChatGoogleGenerativeAI(\n",
        "            google_api_key=os.getenv(\"GOOGLE_GENAI_API_KEY\"),\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            temperature=0,\n",
        "            convert_system_message_to_human=True\n",
        "        )\n",
        "        self.parser = JsonOutputParser(pydantic_object=PairwiseJudgeOutput)\n",
        "        self.prompt_template = PromptTemplate(\n",
        "            template=(\n",
        "                \"You are evaluating two AI-generated answers to the same question. \"\n",
        "                \"Evaluate which response is better based on overall quality (faithfulness, relevance, completeness). \"\n",
        "                \"Provide your decision and a brief explanation.\\n\\n\"\n",
        "                \"[Question]\\n{question}\\n\\n\"\n",
        "                \"[Model 1 Answer]\\n{answer1}\\n\\n\"\n",
        "                \"[Model 2 Answer]\\n{answer2}\\n\\n\"\n",
        "                \"{format_instructions}\"\n",
        "            ),\n",
        "            input_variables=[\"question\", \"answer1\", \"answer2\"],\n",
        "            partial_variables={\"format_instructions\": self.parser.get_format_instructions()}\n",
        "        )\n",
        "        self.chain = self.prompt_template | self.model | self.parser\n",
        "\n",
        "    def judge(self, question, answer1, answer2):\n",
        "        max_retries = 3\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                output = self.chain.invoke({\n",
        "                    \"question\": question,\n",
        "                    \"answer1\": answer1,\n",
        "                    \"answer2\": answer2\n",
        "                })\n",
        "\n",
        "                if isinstance(output, dict):\n",
        "                    if \"decision\" in output:\n",
        "                        return output[\"decision\"], output.get(\"explanation\", \"No explanation provided\")\n",
        "                    else:\n",
        "                        return \"Error\", f\"Unexpected response format: {output}\"\n",
        "                else:\n",
        "                    return output.decision, output.explanation\n",
        "\n",
        "            except Exception as e:\n",
        "                # wait for 2 minutes if quota exceeded and retry\n",
        "                if \"429\" in str(e) or \"exceeded\" in str(e).lower() or \"ResourceExhausted\" in str(e):\n",
        "                    wait_time = 120\n",
        "                    print(f\"API quota exceeded. Waiting for {wait_time} seconds before retrying...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    print(f\"Error in judge function: {str(e)}. Retrying in 10 seconds...\")\n",
        "                    time.sleep(10)\n",
        "\n",
        "                if attempt == max_retries - 1:\n",
        "                    return \"Error\", str(e)\n",
        "\n",
        "def battle_evaluate_with_llm(df1, df2, df1_name=\"Model 1\", df2_name=\"Model 2\"):\n",
        "    judge = PairwiseJudge()\n",
        "\n",
        "    #create new df and store evaluation results\n",
        "    results_df = pd.DataFrame()\n",
        "    results_df['Question'] = df1['Question']\n",
        "    results_df[f'{df1_name}_Answer'] = df1['Answer']\n",
        "    results_df[f'{df2_name}_Answer'] = df2['Answer']\n",
        "    results_df['Winner'] = None\n",
        "    results_df['Explanation'] = None\n",
        "\n",
        "    for i, row in results_df.iterrows():\n",
        "        question = row['Question']\n",
        "        answer1 = row[f'{df1_name}_Answer']\n",
        "        answer2 = row[f'{df2_name}_Answer']\n",
        "        print(f\"Evaluating question {i+1}/{len(results_df)}\")\n",
        "        winner, explanation = judge.judge(question, answer1, answer2)\n",
        "        results_df.at[i, 'Winner'] = df1_name if winner == \"Model 1\" else (df2_name if winner == \"Model 2\" else \"Error\")\n",
        "        results_df.at[i, 'Explanation'] = explanation\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bc48966",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running battle: No_RAG_Base vs RAG_Base\n",
            "Evaluating question 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 20\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API quota exceeded. Waiting for 120 seconds before retrying...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running battle: No_RAG_Finetune vs RAG_Finetune\n",
            "Evaluating question 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 3\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API quota exceeded. Waiting for 120 seconds before retrying...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running battle: No_RAG_Base vs No_RAG_Finetune\n",
            "Evaluating question 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 43\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API quota exceeded. Waiting for 120 seconds before retrying...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running battle: RAG_Base vs RAG_Finetune\n",
            "Evaluating question 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 20\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API quota exceeded. Waiting for 120 seconds before retrying...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running battle: No_RAG_Base vs RAG_Finetune\n",
            "Evaluating question 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 3\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API quota exceeded. Waiting for 120 seconds before retrying...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 45\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API quota exceeded. Waiting for 120 seconds before retrying...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running battle: No_RAG_Finetune vs RAG_Base\n",
            "Evaluating question 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 28\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 25\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API quota exceeded. Waiting for 120 seconds before retrying...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating question 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/weimingchin/Desktop/term 8/MLOps/adi's/sutd_5055mlop/.venv/lib/python3.9/site-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        }
      ],
      "source": [
        "df_no_rag_base = pd.read_csv(\"no_rag_base.csv\")\n",
        "df_no_rag_finetune = pd.read_csv(\"no_rag_finetune.csv\")\n",
        "df_rag_base = pd.read_csv(\"rag_base.csv\")\n",
        "df_rag_finetune = pd.read_csv(\"rag_finetune.csv\")\n",
        "\n",
        "comparisons = [\n",
        "    (df_no_rag_base, df_rag_base, \"No_RAG_Base\", \"RAG_Base\", \"battle_no_rag_base_vs_rag_base.csv\"),\n",
        "    (df_no_rag_finetune, df_rag_finetune, \"No_RAG_Finetune\", \"RAG_Finetune\", \"battle_no_rag_finetune_vs_rag_finetune.csv\"),\n",
        "    (df_no_rag_base, df_no_rag_finetune, \"No_RAG_Base\", \"No_RAG_Finetune\", \"battle_no_rag_base_vs_no_rag_finetune.csv\"),\n",
        "    (df_rag_base, df_rag_finetune, \"RAG_Base\", \"RAG_Finetune\", \"battle_rag_base_vs_rag_finetune.csv\"),\n",
        "    (df_no_rag_base, df_rag_finetune, \"No_RAG_Base\", \"RAG_Finetune\", \"battle_no_rag_base_vs_rag_finetune.csv\"),\n",
        "    (df_no_rag_finetune, df_rag_base, \"No_RAG_Finetune\", \"RAG_Base\", \"battle_no_rag_finetune_vs_rag_base.csv\")\n",
        "]\n",
        "\n",
        "win_counts = {}\n",
        "\n",
        "for df1, df2, name1, name2, output_file in comparisons:\n",
        "    print(f\"\\nRunning battle: {name1} vs {name2}\")\n",
        "    df_result = battle_evaluate_with_llm(df1, df2, df1_name=name1, df2_name=name2)\n",
        "    df_result.to_csv(f\"llm-eval/{output_file}\", index=False)\n",
        "\n",
        "    wins1 = (df_result['Winner'] == name1).sum()\n",
        "    wins2 = (df_result['Winner'] == name2).sum()\n",
        "\n",
        "    if name1 not in win_counts:\n",
        "        win_counts[name1] = 0\n",
        "    if name2 not in win_counts:\n",
        "        win_counts[name2] = 0\n",
        "\n",
        "    win_counts[name1] += wins1\n",
        "    win_counts[name2] += wins2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e07b22f0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(win_counts.keys(), win_counts.values(), color='skyblue')\n",
        "plt.title(\"LLM-as-Judge Battle Results\")\n",
        "plt.ylabel(\"Number of Wins\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd4cca8",
      "metadata": {
        "id": "4dd4cca8"
      },
      "source": [
        "# Bonus points: chatbot UI\n",
        "\n",
        "Implement a web UI frontend for your chatbot that you can demo in class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7rB7IylsPCiX",
      "metadata": {
        "id": "7rB7IylsPCiX"
      },
      "source": [
        "## Chain for the Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "tJuOJKj1MRW1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJuOJKj1MRW1",
        "outputId": "e2caf559-26de-4f20-ef64-181a98aaf15a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and RAG chain ready for Gradio UI.\n"
          ]
        }
      ],
      "source": [
        "finetuned_model_id = f\"{USERNAME}/llama-3.2-1B-sutdqa\"\n",
        "ft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    finetuned_model_id,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "infer_ft = FastLanguageModel.for_inference(ft_model)\n",
        "\n",
        "pipe_ft_rag = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=infer_ft,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=128\n",
        ")\n",
        "\n",
        "hf_ft_rag = HuggingFacePipeline(pipeline=pipe_ft_rag).bind(skip_prompt=True)\n",
        "\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"Use the following context to answer the question.\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Answer:\"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# create the RetrievalQA chain (using the finetuned model)\n",
        "rag_chain_finetune = RetrievalQA.from_chain_type(\n",
        "    llm=hf_ft_rag,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=compression_retriever, # compression retriever\n",
        "    return_source_documents=False,\n",
        "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
        ")\n",
        "\n",
        "print(\"Model and RAG chain ready for Gradio UI.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c196881f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "c196881f",
        "outputId": "850c24fc-28b5-4899-f853-1b0034169836"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8941a9d3aec3b1092d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://8941a9d3aec3b1092d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received query: When was SUTD founded?\n",
            "Generated answer:  SUTD was founded in 2009 as Singapore's fourth publicly funded university. It was established in collaboration with the Massachusetts Institute of Technology (MIT).\n",
            "\n",
            "    Context: This unique approach encourages our students to push the boundaries of innovating solutions to real-world problems. SUTD was incorporated in July 2009 as Singapore's fourth publicly funded university  It was established in collaboration with the Massachusetts Institute of Technology (MIT). SUTD's first academic year began in April 2012.\n",
            "\n",
            "    # About SUTD\n",
            "\n",
            "    SUTD integrates design, AI and technology into a holistic, interdisciplinary education and research experience.\n",
            "\n",
            "    ##\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Implement a web UI frontend for your chatbot that you can demo in class.\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
        "def chatbot_response(message, chat_history): # uses both message and history\n",
        "    print(f\"Received query: {message}\")\n",
        "    try:\n",
        "        result = rag_chain_finetune.invoke({\"query\": message})\n",
        "        answer = result.get(\"result\", \"Sorry, I couldn't generate a response.\")\n",
        "        if answer.startswith(\"Answer:\"):\n",
        "             answer = answer.split(\"Answer:\", 1)[1].strip()\n",
        "        elif answer.startswith(\"Helpful Answer:\"):\n",
        "             answer = answer.split(\"Helpful Answer:\", 1)[1].strip()\n",
        "\n",
        "        print(f\"Generated answer: {answer}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during generation: {e}\")\n",
        "        answer = f\"An error occurred: {e}\"\n",
        "\n",
        "    # clearing cache everytime! bc mine runs out of memory real quick\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return answer\n",
        "\n",
        "# suing gradio's built in Chatinterface that we see on huggingface all the time\n",
        "chatbot_ui = gr.ChatInterface(\n",
        "    fn=chatbot_response,\n",
        "    title=\"SUTD bot\",\n",
        "    description=\"I try my best!\",\n",
        "    theme=gr.themes.Soft(),\n",
        "    cache_examples=False,\n",
        ")\n",
        "\n",
        "# launch the interface\n",
        "chatbot_ui.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d576e6cc",
      "metadata": {
        "id": "d576e6cc"
      },
      "source": [
        "# End\n",
        "\n",
        "This concludes assignment 4.\n",
        "\n",
        "Please submit this notebook with your answers and the generated output cells as a **Jupyter notebook file** via github.\n",
        "\n",
        "\n",
        "Every group member should do the following submission steps:\n",
        "1. Create a private github repository **sutd_5055mlop** under your github user.\n",
        "2. Add your instructors as collaborator: ddahlmeier and lucainiaoge\n",
        "3. Save your submission as assignment_04_GROUP_NAME.ipynb where GROUP_NAME is the name of the group you have registered.\n",
        "4. Push the submission files to your repo\n",
        "5. Submit the link to the repo via eDimensions\n",
        "\n",
        "\n",
        "\n",
        "**Assignment due 21 April 2025 11:59pm**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02e2ce31f68a4bddb2713f27dd2baf6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1505550171844b05aba36ddcab4e30be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb364b92979456e87f041f3504384a0",
              "IPY_MODEL_6830f1d302da4c4caf25c287d243e297",
              "IPY_MODEL_802ddb6311c7407a92ab200059e984b2"
            ],
            "layout": "IPY_MODEL_81be84336db744e7a959328b26308bf5"
          }
        },
        "1730f1e02ec54d32b4c3adaed7148817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "221a50f58f7443c69e65e1179b2ded74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2328c87d892245fab8d60b0881c81f66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2474bdbbb1a44bed8a6142f60b8ebebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25ea136f8d4e4f59a8102c1af06edb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41650e7ae27b44fbbbf1d495120df97c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45046b24823e404cb6cb1372a4f29345": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5197e000d3614e27a6ebb91c350f92c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51dd523836274f47b1b1a9cdbfb7be77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55eeb755f55c4bd488c74985c94dd531": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c931e1af13423198a79e89ad368075",
            "placeholder": "",
            "style": "IPY_MODEL_25ea136f8d4e4f59a8102c1af06edb94",
            "value": "45.1M/45.1M[00:00&lt;00:00,305MB/s]"
          }
        },
        "5995f4547a9c4105a6abe9d8f9617e68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb364b92979456e87f041f3504384a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b16cd1d5ca5240fdb24b2649a420560b",
            "placeholder": "",
            "style": "IPY_MODEL_7f183678fea54eac8b04487c7ae5e1e2",
            "value": "model.safetensors:100%"
          }
        },
        "6830f1d302da4c4caf25c287d243e297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42830cf2d9c42ffb75bf9aa2d299a27",
            "max": 1027676732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7efae6b70bd84ecd90929bfefec025bd",
            "value": 1027676634
          }
        },
        "750c89df3ea64b909af01af2e5757e73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75af545a2b3649e6b89b575597444631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5995f4547a9c4105a6abe9d8f9617e68",
            "placeholder": "",
            "style": "IPY_MODEL_221a50f58f7443c69e65e1179b2ded74",
            "value": "adapter_model.safetensors:100%"
          }
        },
        "7efae6b70bd84ecd90929bfefec025bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f183678fea54eac8b04487c7ae5e1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "802ddb6311c7407a92ab200059e984b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41650e7ae27b44fbbbf1d495120df97c",
            "placeholder": "",
            "style": "IPY_MODEL_5197e000d3614e27a6ebb91c350f92c0",
            "value": "1.03G/1.03G[00:01&lt;00:00,1.27GB/s]"
          }
        },
        "81be84336db744e7a959328b26308bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848078a59c574c3892e4ea5ed1040deb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03b1540a8114b1c983aa2b22071a6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750c89df3ea64b909af01af2e5757e73",
            "placeholder": "",
            "style": "IPY_MODEL_1730f1e02ec54d32b4c3adaed7148817",
            "value": "230/230[00:00&lt;00:00,28.8kB/s]"
          }
        },
        "b156bcf49fa54198b5737c26ac720190": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b16cd1d5ca5240fdb24b2649a420560b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42830cf2d9c42ffb75bf9aa2d299a27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6c931e1af13423198a79e89ad368075": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c142e7ff3af14eca97a847b41fd79e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d3cfb1ca3b40ec927b70229cb6c17a",
            "max": 230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51dd523836274f47b1b1a9cdbfb7be77",
            "value": 230
          }
        },
        "cb7dffce26da4ffe8b4c56c731863cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b156bcf49fa54198b5737c26ac720190",
            "placeholder": "",
            "style": "IPY_MODEL_2474bdbbb1a44bed8a6142f60b8ebebb",
            "value": "generation_config.json:100%"
          }
        },
        "cc4176769d20414b8e3379b18ddd1fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75af545a2b3649e6b89b575597444631",
              "IPY_MODEL_d41531f7ea304618ba54c1195b4c7f0c",
              "IPY_MODEL_55eeb755f55c4bd488c74985c94dd531"
            ],
            "layout": "IPY_MODEL_848078a59c574c3892e4ea5ed1040deb"
          }
        },
        "d41531f7ea304618ba54c1195b4c7f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45046b24823e404cb6cb1372a4f29345",
            "max": 45118424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02e2ce31f68a4bddb2713f27dd2baf6c",
            "value": 45118424
          }
        },
        "e7d3cfb1ca3b40ec927b70229cb6c17a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7e8a81ab904f69a0bc0649b1aaef0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb7dffce26da4ffe8b4c56c731863cea",
              "IPY_MODEL_c142e7ff3af14eca97a847b41fd79e11",
              "IPY_MODEL_b03b1540a8114b1c983aa2b22071a6a8"
            ],
            "layout": "IPY_MODEL_2328c87d892245fab8d60b0881c81f66"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
