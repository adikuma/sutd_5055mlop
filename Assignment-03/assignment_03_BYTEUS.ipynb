{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d2bc81-e67b-413d-b520-38dfe92b2e23",
   "metadata": {},
   "source": [
    "# Group Project / Assignment 3: Retrieval-Augmented Generation Question Answering\n",
    "**Assignment due 6 April 11:59pm 2025**\n",
    "\n",
    "Welcome to the third assignment for 50.055 Machine Learning Operations. \n",
    "The third and fourth assignment together form the course group project. You will be working in your project groups to build a chatbot which can answer questions about SUTD to prospective students.\n",
    "\n",
    "\n",
    "**This assignment is a group assignment.**\n",
    "\n",
    "- Read the instructions in this notebook carefully\n",
    "- Add your solution code and answers in the appropriate places. The questions are marked as **QUESTION:**, the places where you need to add your code and text answers are marked as **ADD YOUR SOLUTION HERE**\n",
    "- The completed notebook, including your added code and generated output will be your submission for the assignment.\n",
    "- The notebook should execute without errors from start to finish when you select \"Restart Kernel and Run All Cells..\". Please test this before submission.\n",
    "- Use the SUTD Education Cluster to solve and test the assignment. If you work on another environment, minimally test your work on the SUTD Education Cluster.\n",
    "\n",
    "**Rubric for assessment** \n",
    "\n",
    "Your submission will be graded using the following criteria. \n",
    "1. Code executes: your code should execute without errors. The SUTD Education cluster should be used to ensure the same execution environment.\n",
    "2. Correctness: the code should produce the correct result or the text answer should state the factual correct answer.\n",
    "3. Style: your code should be written in a way that is clean and efficient. Your text answers should be relevant, concise and easy to understand.\n",
    "4. Partial marks will be awarded for partially correct solutions.\n",
    "5. Creativity and innovation: in this assignment you have more freedom to design your solution, compared to the first assignments. You can show of your creativity and innovative mindset. \n",
    "6. There is a maximum of 225 points for this assignment.\n",
    "\n",
    "**ChatGPT policy** \n",
    "\n",
    "If you use AI tools, such as ChatGPT, to solve the assignment questions, you need to be transparent about its use and mark AI-generated content as such. In particular, you should include the following in addition to your final answer:\n",
    "- A copy or screenshot of the prompt you used\n",
    "- The name of the AI model\n",
    "- The AI generated output\n",
    "- An explanation why the answer is correct or what you had to change to arrive at the correct answer\n",
    "\n",
    "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission instructions are located at the bottom of the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf8b8a-1385-47bf-9aea-68bac46f7098",
   "metadata": {},
   "source": [
    "### Retrieval-Augmented Generation (RAG) \n",
    "\n",
    "In this assignment, you will be building a Retrieval-Augmented Generation (RAG) question answering system which can answer questions about SUTD.\n",
    "\n",
    "We'll be leveraging `langchain` and `llama 3.2`.\n",
    "\n",
    "Check out the docs:\n",
    "- [LangChain](https://docs.langchain.com/docs/)\n",
    "- [Llama 3.2](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/)\n",
    "\n",
    "\n",
    "The SUTD website used to allow chatting with current students. Unfortunately, this feature does not exist anymore. Let's build a chatbot to fill this gap!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada99010",
   "metadata": {},
   "source": [
    "### Conduct user research\n",
    "\n",
    "What are the questions that prospective and current students have about SUTD? In week 2, you already conducted some user research to understand your users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd4e96",
   "metadata": {},
   "source": [
    "### Value Proposition Canvas\n",
    "\n",
    "\n",
    "### QUESTION: \n",
    "\n",
    "Paste the value proposition canvas which you have created in week 2 into this notebook below. \n",
    "\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "\n",
    "- (replace canvas image below)\n",
    "\n",
    "------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d5ec91",
   "metadata": {},
   "source": [
    "![image.png](images/canvas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b1d0c3",
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "Use pip to install all required dependencies of this assignment in the cell below. Make sure to test this on the SUTD cluster as different environments have different software pre-installed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ed5c8e-f07e-4de2-b2de-0a063001668d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate==1.6.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: aiofiles==24.1.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 2)) (24.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs==2.6.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: aiohttp==3.11.14 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 4)) (3.11.14)\n",
      "Requirement already satisfied: aiosignal==1.3.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 7)) (4.9.3)\n",
      "Requirement already satisfied: anyio==4.9.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 8)) (4.9.0)\n",
      "Requirement already satisfied: asttokens==3.0.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: attrs==25.3.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 10)) (25.3.0)\n",
      "Requirement already satisfied: backoff==2.2.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4==4.13.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 12)) (4.13.3)\n",
      "Requirement already satisfied: bitsandbytes==0.45.4 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 13)) (0.45.4)\n",
      "Requirement already satisfied: cachetools==5.5.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 14)) (5.5.2)\n",
      "Requirement already satisfied: certifi==2025.1.31 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 15)) (2025.1.31)\n",
      "Requirement already satisfied: cffi==1.17.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 16)) (1.17.1)\n",
      "Requirement already satisfied: chardet==5.2.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 17)) (5.2.0)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 18)) (3.4.1)\n",
      "Requirement already satisfied: click==8.1.8 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 19)) (8.1.8)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 20)) (0.4.6)\n",
      "Requirement already satisfied: coloredlogs==15.0.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 21)) (15.0.1)\n",
      "Requirement already satisfied: comm==0.2.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 22)) (0.2.2)\n",
      "Requirement already satisfied: contourpy==1.3.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 23)) (1.3.1)\n",
      "Requirement already satisfied: cryptography==44.0.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 24)) (44.0.2)\n",
      "Requirement already satisfied: cssselect==1.3.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 25)) (1.3.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 26)) (0.12.1)\n",
      "Requirement already satisfied: dataclasses-json==0.6.7 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 27)) (0.6.7)\n",
      "Requirement already satisfied: debugpy==1.8.13 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 28)) (1.8.13)\n",
      "Requirement already satisfied: decorator==5.2.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 29)) (5.2.1)\n",
      "Requirement already satisfied: Deprecated==1.2.18 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 30)) (1.2.18)\n",
      "Requirement already satisfied: distro==1.9.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 31)) (1.9.0)\n",
      "Requirement already satisfied: effdet==0.4.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 32)) (0.4.1)\n",
      "Requirement already satisfied: emoji==2.14.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 33)) (2.14.1)\n",
      "Requirement already satisfied: et_xmlfile==2.0.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 34)) (2.0.0)\n",
      "Requirement already satisfied: eval_type_backport==0.2.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 35)) (0.2.2)\n",
      "Requirement already satisfied: executing==2.2.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 36)) (2.2.0)\n",
      "Requirement already satisfied: faiss-cpu==1.10.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 37)) (1.10.0)\n",
      "Requirement already satisfied: filelock==3.18.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 38)) (3.18.0)\n",
      "Requirement already satisfied: filetype==1.2.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 39)) (1.2.0)\n",
      "Requirement already satisfied: FlashRank==0.2.10 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 40)) (0.2.10)\n",
      "Requirement already satisfied: flatbuffers==25.2.10 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 41)) (25.2.10)\n",
      "Requirement already satisfied: fonttools==4.57.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 42)) (4.57.0)\n",
      "Requirement already satisfied: frozenlist==1.5.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 43)) (1.5.0)\n",
      "Requirement already satisfied: fsspec==2025.3.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 44)) (2025.3.2)\n",
      "Requirement already satisfied: google-api-core==2.24.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 45)) (2.24.2)\n",
      "Requirement already satisfied: google-auth==2.38.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 46)) (2.38.0)\n",
      "Requirement already satisfied: google-cloud-vision==3.10.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 47)) (3.10.1)\n",
      "Requirement already satisfied: googleapis-common-protos==1.69.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 48)) (1.69.2)\n",
      "Requirement already satisfied: graphviz==0.20.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 49)) (0.20.3)\n",
      "Requirement already satisfied: greenlet==3.1.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 50)) (3.1.1)\n",
      "Requirement already satisfied: grpcio==1.71.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 51)) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status==1.71.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 52)) (1.71.0)\n",
      "Requirement already satisfied: h11==0.14.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 53)) (0.14.0)\n",
      "Requirement already satisfied: html5lib==1.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 54)) (1.1)\n",
      "Requirement already satisfied: httpcore==1.0.7 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 55)) (1.0.7)\n",
      "Requirement already satisfied: httpx==0.28.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 56)) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 57)) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub==0.30.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 58)) (0.30.1)\n",
      "Requirement already satisfied: humanfriendly==10.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 59)) (10.0)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 60)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 61)) (6.29.5)\n",
      "Requirement already satisfied: ipython==9.0.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 62)) (9.0.2)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 63)) (1.1.1)\n",
      "Requirement already satisfied: ipywidgets==8.1.5 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 64)) (8.1.5)\n",
      "Requirement already satisfied: jedi==0.19.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 65)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 66)) (3.1.6)\n",
      "Requirement already satisfied: jiter==0.9.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 67)) (0.9.0)\n",
      "Requirement already satisfied: joblib==1.4.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 68)) (1.4.2)\n",
      "Requirement already satisfied: jsonpatch==1.33 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 69)) (1.33)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 70)) (3.0.0)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 71)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 72)) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab_widgets==3.0.13 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 73)) (3.0.13)\n",
      "Requirement already satisfied: kiwisolver==1.4.8 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 74)) (1.4.8)\n",
      "Requirement already satisfied: langchain==0.3.21 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 75)) (0.3.21)\n",
      "Requirement already satisfied: langchain-community==0.3.20 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 76)) (0.3.20)\n",
      "Requirement already satisfied: langchain-core==0.3.49 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 77)) (0.3.49)\n",
      "Requirement already satisfied: langchain-openai==0.3.11 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 78)) (0.3.11)\n",
      "Requirement already satisfied: langchain-text-splitters==0.3.7 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 79)) (0.3.7)\n",
      "Requirement already satisfied: langdetect==1.0.9 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 80)) (1.0.9)\n",
      "Requirement already satisfied: langsmith==0.3.19 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 81)) (0.3.19)\n",
      "Requirement already satisfied: lxml==5.3.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 82)) (5.3.1)\n",
      "Requirement already satisfied: lxml_html_clean==0.4.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 83)) (0.4.1)\n",
      "Requirement already satisfied: Markdown==3.7 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 84)) (3.7)\n",
      "Requirement already satisfied: markdownify==1.1.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 85)) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 86)) (3.0.2)\n",
      "Requirement already satisfied: marshmallow==3.26.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 87)) (3.26.1)\n",
      "Requirement already satisfied: matplotlib==3.10.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 88)) (3.10.1)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 89)) (0.1.7)\n",
      "Requirement already satisfied: mpmath==1.3.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 90)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.2.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 91)) (6.2.0)\n",
      "Requirement already satisfied: mypy-extensions==1.0.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 92)) (1.0.0)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 93)) (1.6.0)\n",
      "Requirement already satisfied: networkx==3.4.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 94)) (3.4.2)\n",
      "Requirement already satisfied: nltk==3.9.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 95)) (3.9.1)\n",
      "Requirement already satisfied: numpy==2.2.4 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 96)) (2.2.4)\n",
      "Requirement already satisfied: olefile==0.47 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 97)) (0.47)\n",
      "Requirement already satisfied: omegaconf==2.3.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 98)) (2.3.0)\n",
      "Requirement already satisfied: onnx==1.17.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 99)) (1.17.0)\n",
      "Requirement already satisfied: onnxruntime==1.21.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 100)) (1.21.0)\n",
      "Requirement already satisfied: openai==1.69.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 101)) (1.69.0)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 102)) (4.11.0.86)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 103)) (3.1.5)\n",
      "Requirement already satisfied: orjson==3.10.16 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 104)) (3.10.16)\n",
      "Requirement already satisfied: packaging==24.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 105)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 106)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 107)) (0.8.4)\n",
      "Requirement already satisfied: pdf2image==1.17.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 108)) (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 109)) (20250327)\n",
      "Requirement already satisfied: pi_heif==0.22.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 110)) (0.22.0)\n",
      "Requirement already satisfied: pikepdf==9.5.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 111)) (9.5.2)\n",
      "Requirement already satisfied: pillow==11.1.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 112)) (11.1.0)\n",
      "Requirement already satisfied: platformdirs==4.3.7 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 113)) (4.3.7)\n",
      "Requirement already satisfied: playwright==1.51.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 114)) (1.51.0)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.50 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 115)) (3.0.50)\n",
      "Requirement already satisfied: propcache==0.3.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 116)) (0.3.1)\n",
      "Requirement already satisfied: proto-plus==1.26.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 117)) (1.26.1)\n",
      "Requirement already satisfied: protobuf==5.29.4 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 118)) (5.29.4)\n",
      "Requirement already satisfied: psutil==7.0.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 119)) (7.0.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 120)) (0.2.3)\n",
      "Requirement already satisfied: pyasn1==0.6.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 121)) (0.6.1)\n",
      "Requirement already satisfied: pyasn1_modules==0.4.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 122)) (0.4.2)\n",
      "Requirement already satisfied: pycocotools==2.0.8 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 123)) (2.0.8)\n",
      "Requirement already satisfied: pycparser==2.22 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 124)) (2.22)\n",
      "Requirement already satisfied: pydantic==2.11.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 125)) (2.11.1)\n",
      "Requirement already satisfied: pydantic-settings==2.8.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 126)) (2.8.1)\n",
      "Requirement already satisfied: pydantic_core==2.33.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 127)) (2.33.0)\n",
      "Requirement already satisfied: pyee==12.1.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 128)) (12.1.1)\n",
      "Requirement already satisfied: Pygments==2.19.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 129)) (2.19.1)\n",
      "Requirement already satisfied: pypandoc==1.15 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 130)) (1.15)\n",
      "Requirement already satisfied: pyparsing==3.2.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 131)) (3.2.3)\n",
      "Requirement already satisfied: pypdf==5.4.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 132)) (5.4.0)\n",
      "Requirement already satisfied: pypdfium2==4.30.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 133)) (4.30.1)\n",
      "Requirement already satisfied: pyreadline3==3.5.4 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 134)) (3.5.4)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 135)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-docx==1.1.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 136)) (1.1.2)\n",
      "Requirement already satisfied: python-dotenv==1.1.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 137)) (1.1.0)\n",
      "Requirement already satisfied: python-iso639==2025.2.18 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 138)) (2025.2.18)\n",
      "Requirement already satisfied: python-magic==0.4.27 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 139)) (0.4.27)\n",
      "Requirement already satisfied: python-multipart==0.0.20 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 140)) (0.0.20)\n",
      "Requirement already satisfied: python-oxmsg==0.0.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 141)) (0.0.2)\n",
      "Requirement already satisfied: python-pptx==1.0.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 142)) (1.0.2)\n",
      "Requirement already satisfied: pytz==2025.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 143)) (2025.2)\n",
      "Requirement already satisfied: pywin32==310 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 144)) (310)\n",
      "Requirement already satisfied: PyYAML==6.0.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 145)) (6.0.2)\n",
      "Requirement already satisfied: pyzmq==26.3.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 146)) (26.3.0)\n",
      "Requirement already satisfied: RapidFuzz==3.13.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 147)) (3.13.0)\n",
      "Requirement already satisfied: readability==0.3.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 148)) (0.3.2)\n",
      "Requirement already satisfied: readability-lxml==0.8.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 149)) (0.8.1)\n",
      "Requirement already satisfied: regex==2024.11.6 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 150)) (2024.11.6)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 151)) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt==1.0.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 152)) (1.0.0)\n",
      "Requirement already satisfied: rsa==4.9 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 153)) (4.9)\n",
      "Requirement already satisfied: safetensors==0.5.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 154)) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn==1.6.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 155)) (1.6.1)\n",
      "Requirement already satisfied: scipy==1.15.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 156)) (1.15.2)\n",
      "Requirement already satisfied: sentence-transformers==4.0.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 157)) (4.0.2)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 158)) (0.2.0)\n",
      "Requirement already satisfied: setuptools==70.2.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 159)) (70.2.0)\n",
      "Requirement already satisfied: six==1.17.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 160)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 161)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.6 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 162)) (2.6)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.40 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 163)) (2.0.40)\n",
      "Requirement already satisfied: stack-data==0.6.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 164)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 165)) (1.13.1)\n",
      "Requirement already satisfied: tenacity==9.0.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 166)) (9.0.0)\n",
      "Requirement already satisfied: threadpoolctl==3.6.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 167)) (3.6.0)\n",
      "Requirement already satisfied: tiktoken==0.9.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 168)) (0.9.0)\n",
      "Requirement already satisfied: timm==1.0.15 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 169)) (1.0.15)\n",
      "Requirement already satisfied: tokenizers==0.21.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 170)) (0.21.1)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 171)) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 172)) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision==0.21.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 173)) (0.21.0+cu118)\n",
      "Requirement already satisfied: tornado==6.4.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 174)) (6.4.2)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 175)) (4.67.1)\n",
      "Requirement already satisfied: traitlets==5.14.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 176)) (5.14.3)\n",
      "Requirement already satisfied: transformers==4.50.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 177)) (4.50.3)\n",
      "Requirement already satisfied: typing-inspect==0.9.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 178)) (0.9.0)\n",
      "Requirement already satisfied: typing-inspection==0.4.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 179)) (0.4.0)\n",
      "Requirement already satisfied: typing_extensions==4.13.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 180)) (4.13.0)\n",
      "Requirement already satisfied: tzdata==2025.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 181)) (2025.2)\n",
      "Requirement already satisfied: unstructured==0.17.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 182)) (0.17.2)\n",
      "Requirement already satisfied: unstructured-client==0.32.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 183)) (0.32.1)\n",
      "Requirement already satisfied: unstructured-inference==0.8.10 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 184)) (0.8.10)\n",
      "Requirement already satisfied: unstructured.pytesseract==0.3.15 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 185)) (0.3.15)\n",
      "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 186)) (2.3.0)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 187)) (0.2.13)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 188)) (0.5.1)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.13 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 189)) (4.0.13)\n",
      "Requirement already satisfied: wrapt==1.17.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 190)) (1.17.2)\n",
      "Requirement already satisfied: xlrd==2.0.1 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 191)) (2.0.1)\n",
      "Requirement already satisfied: XlsxWriter==3.2.2 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 192)) (3.2.2)\n",
      "Requirement already satisfied: yarl==1.18.3 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 193)) (1.18.3)\n",
      "Requirement already satisfied: zstandard==0.23.0 in c:\\users\\chian\\documents\\code\\sutd_5055mlop-adi\\myenv\\lib\\site-packages (from -r requirements.txt (line 194)) (0.23.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Install and import all required packages\n",
    "# The rest of your code should execute without any import or dependency errors.\n",
    "\n",
    "# **--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "! pip install -r requirements.txt\n",
    "\n",
    "# For CUDA purposes, uncomment the following line and run it in your terminal:\n",
    "#! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb2b9c",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b15dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from glob import glob\n",
    "import openai\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from markdown import markdown\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from typing import List, Dict, Any, Tuple, Union\n",
    "from rag_prompt import RAG_PROMPT\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "MARKDOWN_PATH = \"data/markdown/markdown_data.json\"\n",
    "HTML_PATH = \"data/html/html_data.json\"\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "TOP_K = 5\n",
    "OUTPUT_DIR = \"vector_store\"\n",
    "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "MODEL_DIR = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af3447d-b41f-4ac5-95b9-1cae3a42d620",
   "metadata": {},
   "source": [
    "# Download documents\n",
    "The RAG application should be able to answer questions based on ingested documents. For the SUTD chatbot, download PDF and HTML files from the SUTD website. The documents should contain information about the admission process, available courses and the university in general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7c5201b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 30 HTML documents and 30 Markdown documents\n",
      "Found 27 Markdown files on disk\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Has Markdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUTD About page</td>\n",
       "      <td>https://www.sutd.edu.sg/about/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SUTD Contact page</td>\n",
       "      <td>https://www.sutd.edu.sg/contact-us/contact-sutd/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUTD Home page</td>\n",
       "      <td>https://www.sutd.edu.sg/</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUTD Application Guide page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/undergradua...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SUTD Appeal Guide page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/undergradua...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUTD Admission Requirements page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/undergradua...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SUTD Masters information page 1</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/graduate/ma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUTD Masters information page 2</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/graduate/ma...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SUTD PHD information page</td>\n",
       "      <td>https://www.sutd.edu.sg/admissions/graduate/phd/</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUTD Academic Calendar</td>\n",
       "      <td>https://www.sutd.edu.sg/education/undergraduat...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title  \\\n",
       "0                   SUTD About page   \n",
       "1                 SUTD Contact page   \n",
       "2                    SUTD Home page   \n",
       "3       SUTD Application Guide page   \n",
       "4            SUTD Appeal Guide page   \n",
       "5  SUTD Admission Requirements page   \n",
       "6   SUTD Masters information page 1   \n",
       "7   SUTD Masters information page 2   \n",
       "8         SUTD PHD information page   \n",
       "9            SUTD Academic Calendar   \n",
       "\n",
       "                                                 URL  Has Markdown  \n",
       "0                     https://www.sutd.edu.sg/about/          True  \n",
       "1   https://www.sutd.edu.sg/contact-us/contact-sutd/          True  \n",
       "2                           https://www.sutd.edu.sg/         False  \n",
       "3  https://www.sutd.edu.sg/admissions/undergradua...          True  \n",
       "4  https://www.sutd.edu.sg/admissions/undergradua...          True  \n",
       "5  https://www.sutd.edu.sg/admissions/undergradua...          True  \n",
       "6  https://www.sutd.edu.sg/admissions/graduate/ma...         False  \n",
       "7  https://www.sutd.edu.sg/admissions/graduate/ma...          True  \n",
       "8   https://www.sutd.edu.sg/admissions/graduate/phd/          True  \n",
       "9  https://www.sutd.edu.sg/education/undergraduat...          True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... and 20 more documents\n",
      "\n",
      "Document Statistics:\n",
      "Total SUTD documents: 30\n",
      "Documents with extracted markdown content: 27\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Download documents from the SUTD website\n",
    "# You should download at least 10 documents but more documents can increase the knowledge base of your chatbot.\n",
    "\n",
    "# **--- ADD YOUR SOLUTION HERE (20 points) ---**\n",
    "def get_data(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        output_json = json.load(f)\n",
    "    return output_json\n",
    "\n",
    "html_data = get_data(HTML_PATH)\n",
    "markdown_data = get_data(MARKDOWN_PATH)\n",
    "\n",
    "print(\n",
    "    f\"Successfully loaded {len(html_data)} HTML documents and {len(markdown_data)} Markdown documents\"\n",
    ")\n",
    "\n",
    "markdown_files = glob(\"data/markdown/*.md\")\n",
    "print(f\"Found {len(markdown_files)} Markdown files on disk\")\n",
    "\n",
    "docs_info = []\n",
    "for doc in markdown_data:\n",
    "    docs_info.append(\n",
    "        {\n",
    "            \"Title\": doc.get(\"title\", \"No Title\"),\n",
    "            \"URL\": doc.get(\"url\", \"No URL\"),\n",
    "            \"Has Markdown\": bool(doc.get(\"markdown\", \"\").strip()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "docs_df = pd.DataFrame(docs_info)\n",
    "display(docs_df.head(10))\n",
    "\n",
    "if len(docs_df) > 10:\n",
    "    print(f\"... and {len(docs_df) - 10} more documents\")\n",
    "\n",
    "print(\"\\nDocument Statistics:\")\n",
    "print(f\"Total SUTD documents: {len(docs_df)}\")\n",
    "print(f\"Documents with extracted markdown content: {docs_df['Has Markdown'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a646cbd-2a05-4078-995b-4317a94ed109",
   "metadata": {},
   "source": [
    "# Split documents\n",
    "Use LangChain to split the documents into smaller text chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5175131-4a38-4861-96f4-456efea1a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents: 27\n",
      "Total chunks created: 213\n",
      "page_content='# About SUTD\n",
      "\n",
      "\n",
      "<p>SUTD integrates design, AI and technology into a holistic, interdisciplinary education and research experience. This unique approach encourages our students to push the boundaries of innovating solutions to real-world problems.</p>' metadata={'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'pillar': 'General', 'section_title': 'About SUTD', 'parent_sections': [], 'section_level': 1, 'internal_links': []}\n",
      "Total refined chunks: 270\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Use langchain to split the documents into chunks\n",
    "\n",
    "# --- ADD YOUR SOLUTION HERE (20 points)---\n",
    "def process_documents(data):\n",
    "    processed_docs = []\n",
    "\n",
    "    # take in json data (dictionary) and create a list of documents\n",
    "    for item in data:\n",
    "        # get the markdown content\n",
    "        if not item.get(\"markdown\"):\n",
    "            continue\n",
    "\n",
    "        # extract the metadata from the json\n",
    "        metadata = {\n",
    "            \"title\": item.get(\"title\", \"\"),\n",
    "            \"url\": item.get(\"url\", \"\"),\n",
    "            \"description\": item.get(\"description\", \"\"),\n",
    "            \"pillar\": extract_pillar(item.get(\"title\", \"\"), item.get(\"url\", \"\")),\n",
    "        }\n",
    "\n",
    "        # normalize headers\n",
    "        content = normalize_headers(item.get(\"markdown\", \"\"))\n",
    "\n",
    "        # create langchain document object\n",
    "        doc = Document(page_content=content, metadata=metadata)\n",
    "\n",
    "        processed_docs.append(doc)\n",
    "    return processed_docs\n",
    "\n",
    "\n",
    "def extract_pillar(title, url):\n",
    "    # extract each pillar to add to metadata to make it easier to provide context to LLM\n",
    "    pillars = [\"ISTD\", \"ESD\", \"EPD\", \"ASD\", \"DAI\", \"HASS\", \"SMT\"]\n",
    "\n",
    "    for pillar in pillars:\n",
    "        if pillar in title or pillar.lower() in url.lower():\n",
    "            return pillar\n",
    "    # if no pillar is found, return 'General'\n",
    "    return \"General\"\n",
    "\n",
    "\n",
    "def normalize_headers(markdown_text):\n",
    "    # add a space after # characters for proper header parsing\n",
    "    markdown_text = re.sub(r\"(#{1,6})([^#\\s])\", r\"\\1 \\2\", markdown_text)\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def extract_markdown_hierarchy(markdown_text):\n",
    "    # convert the markdown text to html\n",
    "    html = markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    sections = []\n",
    "    current_section = {\"title\": \"Root\", \"level\": 0, \"content\": \"\", \"parents\": []}\n",
    "    # list of header tags to look for\n",
    "    heading_tags = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]\n",
    "\n",
    "    # first pass: identify all headings and their levels\n",
    "    headings = []\n",
    "    for tag in soup.find_all(heading_tags):\n",
    "        level = int(tag.name[1])\n",
    "        headings.append(\n",
    "            {\n",
    "                \"tag\": tag,\n",
    "                \"title\": tag.get_text().strip(),\n",
    "                \"level\": level,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # if there were no headings found, treat the entire document as one section\n",
    "    if not headings:\n",
    "        current_section[\"content\"] = markdown_text\n",
    "        return [current_section]\n",
    "\n",
    "    # second pass: extract section content and build hierarchy\n",
    "    for i, heading in enumerate(headings):\n",
    "        # find content up to the next heading or end of document\n",
    "        content_elements = []\n",
    "        element = heading[\"tag\"].next_sibling\n",
    "\n",
    "        while element and (i == len(headings) - 1 or element != headings[i + 1][\"tag\"]):\n",
    "            if element.name not in heading_tags:\n",
    "                if hasattr(element, \"get_text\"):\n",
    "                    content_elements.append(str(element))\n",
    "            element = element.next_sibling\n",
    "\n",
    "        # get the parent headings\n",
    "        parent_titles = []\n",
    "        for prev_heading in reversed(headings[:i]):\n",
    "            if prev_heading[\"level\"] < heading[\"level\"]:\n",
    "                parent_titles.insert(0, prev_heading[\"title\"])\n",
    "\n",
    "        # build section\n",
    "        section = {\n",
    "            \"title\": heading[\"title\"],\n",
    "            \"level\": heading[\"level\"],\n",
    "            \"content\": \"\".join(content_elements),\n",
    "            \"parents\": parent_titles,\n",
    "        }\n",
    "        sections.append(section)\n",
    "    return sections\n",
    "\n",
    "# the markdowns kept in some internal URLs which are useful\n",
    "def extract_internal_urls(content):\n",
    "    # since the markdown has a few links to internal pages, we need to extract them\n",
    "    # pattern to match markdown links\n",
    "    pattern = r\"\\[.*?\\]\\((https?://www\\.sutd\\.edu\\.sg/[^)]+)\\)\"\n",
    "    urls = re.findall(pattern, content)\n",
    "\n",
    "    # also check for HTML links if any HTML is embedded in the markdown\n",
    "    if '<a href=\"' in content:\n",
    "        html_pattern = r'<a href=\"(https?://www\\.sutd\\.edu\\.sg/[^\"]+)\"'\n",
    "        html_urls = re.findall(html_pattern, content)\n",
    "        urls.extend(html_urls)\n",
    "\n",
    "    return list(set(urls))\n",
    "\n",
    "\n",
    "def process_document(doc):\n",
    "    # extract the metadata from the document\n",
    "    metadata = doc.metadata\n",
    "    content = doc.page_content\n",
    "\n",
    "    # extract markdown structure\n",
    "    sections = extract_markdown_hierarchy(content)\n",
    "\n",
    "    # process each section into a chunk\n",
    "    chunks = []\n",
    "    for section in sections:\n",
    "        # skip very short sections\n",
    "        if len(section[\"content\"]) < 10 and section[\"level\"] > 0:\n",
    "            continue\n",
    "\n",
    "        # get the full text for this section\n",
    "        section_title = f\"# {section['title']}\" if section[\"level\"] > 0 else \"\"\n",
    "        section_text = f\"{section_title}\\n\\n{section['content']}\"\n",
    "\n",
    "        # extract all urls internal to the section\n",
    "        internal_urls = extract_internal_urls(section_text)\n",
    "\n",
    "        # create the metadata\n",
    "        enhanced_metadata = {\n",
    "            **metadata,\n",
    "            \"section_title\": section[\"title\"],\n",
    "            \"parent_sections\": section[\"parents\"],\n",
    "            \"section_level\": section[\"level\"],\n",
    "            \"internal_links\": internal_urls,\n",
    "        }\n",
    "\n",
    "        chunks.append({\"text\": section_text.strip(), \"metadata\": enhanced_metadata})\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def refine_chunks(chunks, min_size=100, max_size=1000):\n",
    "    refined_chunks = []\n",
    "    current_text = \"\"\n",
    "    current_metadata = None\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if (\n",
    "            len(chunk[\"text\"]) < min_size\n",
    "            and current_metadata\n",
    "            and chunk[\"metadata\"][\"parent_sections\"]\n",
    "            == current_metadata[\"parent_sections\"]\n",
    "        ):\n",
    "            current_text += \"\\n\\n\" + chunk[\"text\"]\n",
    "        else:\n",
    "            if current_text:\n",
    "                refined_chunks.append(\n",
    "                    Document(page_content=current_text, metadata=current_metadata)\n",
    "                )\n",
    "\n",
    "            current_text = chunk[\"text\"]\n",
    "            current_metadata = chunk[\"metadata\"]\n",
    "\n",
    "    if current_text:\n",
    "        refined_chunks.append(Document(page_content=current_text, metadata=current_metadata))\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_size, chunk_overlap=100, separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    print(refined_chunks[0])\n",
    "\n",
    "    final_chunks = text_splitter.split_documents(refined_chunks)\n",
    "    return final_chunks\n",
    "\n",
    "\n",
    "processed_docs = process_documents(markdown_data)\n",
    "print(f\"Processed documents: {len(processed_docs)}\")\n",
    "\n",
    "all_chunks = []\n",
    "for doc in processed_docs:\n",
    "    doc_chunks = process_document(doc)\n",
    "    all_chunks.extend(doc_chunks)\n",
    "\n",
    "print(f\"Total chunks created: {len(all_chunks)}\")\n",
    "\n",
    "refined_chunks = refine_chunks(all_chunks)\n",
    "print(f\"Total refined chunks: {len(refined_chunks)}\")\n",
    "print(type(refined_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67518904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents: 27\n",
      "Total chunks created: 213\n",
      "page_content='# About SUTD\n",
      "\n",
      "\n",
      "<p>SUTD integrates design, AI and technology into a holistic, interdisciplinary education and research experience. This unique approach encourages our students to push the boundaries of innovating solutions to real-world problems.</p>' metadata={'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'pillar': 'General', 'section_title': 'About SUTD', 'parent_sections': [], 'section_level': 1, 'internal_links': []}\n",
      "Total refined chunks: 270\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Use langchain to split the documents into chunks\n",
    "\n",
    "# --- ADD YOUR SOLUTION HERE (20 points)---\n",
    "def process_documents(data):\n",
    "    processed_docs = []\n",
    "\n",
    "    # take in json data (dictionary) and create a list of documents\n",
    "    for item in data:\n",
    "        # get the markdown content\n",
    "        if not item.get(\"markdown\"):\n",
    "            continue\n",
    "\n",
    "        # extract the metadata from the json\n",
    "        metadata = {\n",
    "            \"title\": item.get(\"title\", \"\"),\n",
    "            \"url\": item.get(\"url\", \"\"),\n",
    "            \"description\": item.get(\"description\", \"\"),\n",
    "            \"pillar\": extract_pillar(item.get(\"title\", \"\"), item.get(\"url\", \"\")),\n",
    "        }\n",
    "\n",
    "        # normalize headers\n",
    "        content = normalize_headers(item.get(\"markdown\", \"\"))\n",
    "\n",
    "        # create langchain document object\n",
    "        doc = Document(page_content=content, metadata=metadata)\n",
    "\n",
    "        processed_docs.append(doc)\n",
    "    return processed_docs\n",
    "\n",
    "\n",
    "def extract_pillar(title, url):\n",
    "    # extract each pillar to add to metadata to make it easier to provide context to LLM\n",
    "    pillars = [\"ISTD\", \"ESD\", \"EPD\", \"ASD\", \"DAI\", \"HASS\", \"SMT\"]\n",
    "\n",
    "    for pillar in pillars:\n",
    "        if pillar in title or pillar.lower() in url.lower():\n",
    "            return pillar\n",
    "    # if no pillar is found, return 'General'\n",
    "    return \"General\"\n",
    "\n",
    "\n",
    "def normalize_headers(markdown_text):\n",
    "    # add a space after # characters for proper header parsing\n",
    "    markdown_text = re.sub(r\"(#{1,6})([^#\\s])\", r\"\\1 \\2\", markdown_text)\n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "def extract_markdown_hierarchy(markdown_text):\n",
    "    # convert the markdown text to html\n",
    "    html = markdown(markdown_text)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    sections = []\n",
    "    current_section = {\"title\": \"Root\", \"level\": 0, \"content\": \"\", \"parents\": []}\n",
    "    # list of header tags to look for\n",
    "    heading_tags = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\", \"h6\"]\n",
    "\n",
    "    # first pass: identify all headings and their levels\n",
    "    headings = []\n",
    "    for tag in soup.find_all(heading_tags):\n",
    "        level = int(tag.name[1])\n",
    "        headings.append(\n",
    "            {\n",
    "                \"tag\": tag,\n",
    "                \"title\": tag.get_text().strip(),\n",
    "                \"level\": level,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # if there were no headings found, treat the entire document as one section\n",
    "    if not headings:\n",
    "        current_section[\"content\"] = markdown_text\n",
    "        return [current_section]\n",
    "\n",
    "    # second pass: extract section content and build hierarchy\n",
    "    for i, heading in enumerate(headings):\n",
    "        # find content up to the next heading or end of document\n",
    "        content_elements = []\n",
    "        element = heading[\"tag\"].next_sibling\n",
    "\n",
    "        while element and (i == len(headings) - 1 or element != headings[i + 1][\"tag\"]):\n",
    "            if element.name not in heading_tags:\n",
    "                if hasattr(element, \"get_text\"):\n",
    "                    content_elements.append(str(element))\n",
    "            element = element.next_sibling\n",
    "\n",
    "        # get the parent headings\n",
    "        parent_titles = []\n",
    "        for prev_heading in reversed(headings[:i]):\n",
    "            if prev_heading[\"level\"] < heading[\"level\"]:\n",
    "                parent_titles.insert(0, prev_heading[\"title\"])\n",
    "\n",
    "        # build section\n",
    "        section = {\n",
    "            \"title\": heading[\"title\"],\n",
    "            \"level\": heading[\"level\"],\n",
    "            \"content\": \"\".join(content_elements),\n",
    "            \"parents\": parent_titles,\n",
    "        }\n",
    "        sections.append(section)\n",
    "    return sections\n",
    "\n",
    "# the markdowns kept in some internal URLs which are useful\n",
    "def extract_internal_urls(content):\n",
    "    # since the markdown has a few links to internal pages, we need to extract them\n",
    "    # pattern to match markdown links\n",
    "    pattern = r\"\\[.*?\\]\\((https?://www\\.sutd\\.edu\\.sg/[^)]+)\\)\"\n",
    "    urls = re.findall(pattern, content)\n",
    "\n",
    "    # also check for HTML links if any HTML is embedded in the markdown\n",
    "    if '<a href=\"' in content:\n",
    "        html_pattern = r'<a href=\"(https?://www\\.sutd\\.edu\\.sg/[^\"]+)\"'\n",
    "        html_urls = re.findall(html_pattern, content)\n",
    "        urls.extend(html_urls)\n",
    "\n",
    "    return list(set(urls))\n",
    "\n",
    "\n",
    "def process_document(doc):\n",
    "    # extract the metadata from the document\n",
    "    metadata = doc.metadata\n",
    "    content = doc.page_content\n",
    "\n",
    "    # extract markdown structure\n",
    "    sections = extract_markdown_hierarchy(content)\n",
    "\n",
    "    # process each section into a chunk\n",
    "    chunks = []\n",
    "    for section in sections:\n",
    "        # skip very short sections\n",
    "        if len(section[\"content\"]) < 10 and section[\"level\"] > 0:\n",
    "            continue\n",
    "\n",
    "        # get the full text for this section\n",
    "        section_title = f\"# {section['title']}\" if section[\"level\"] > 0 else \"\"\n",
    "        section_text = f\"{section_title}\\n\\n{section['content']}\"\n",
    "\n",
    "        # extract all urls internal to the section\n",
    "        internal_urls = extract_internal_urls(section_text)\n",
    "\n",
    "        # create the metadata\n",
    "        enhanced_metadata = {\n",
    "            **metadata,\n",
    "            \"section_title\": section[\"title\"],\n",
    "            \"parent_sections\": section[\"parents\"],\n",
    "            \"section_level\": section[\"level\"],\n",
    "            \"internal_links\": internal_urls,\n",
    "        }\n",
    "\n",
    "        chunks.append({\"text\": section_text.strip(), \"metadata\": enhanced_metadata})\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def refine_chunks(chunks, min_size=100, max_size=1000):\n",
    "    refined_chunks = []\n",
    "    current_text = \"\"\n",
    "    current_metadata = None\n",
    "\n",
    "    for chunk in chunks:\n",
    "        if (\n",
    "            len(chunk[\"text\"]) < min_size\n",
    "            and current_metadata\n",
    "            and chunk[\"metadata\"][\"parent_sections\"]\n",
    "            == current_metadata[\"parent_sections\"]\n",
    "        ):\n",
    "            current_text += \"\\n\\n\" + chunk[\"text\"]\n",
    "        else:\n",
    "            if current_text:\n",
    "                refined_chunks.append(\n",
    "                    Document(page_content=current_text, metadata=current_metadata)\n",
    "                )\n",
    "\n",
    "            current_text = chunk[\"text\"]\n",
    "            current_metadata = chunk[\"metadata\"]\n",
    "\n",
    "    if current_text:\n",
    "        refined_chunks.append(Document(page_content=current_text, metadata=current_metadata))\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=max_size, chunk_overlap=100, separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "    print(refined_chunks[0])\n",
    "\n",
    "    final_chunks = text_splitter.split_documents(refined_chunks)\n",
    "    return final_chunks\n",
    "\n",
    "\n",
    "processed_docs = process_documents(markdown_data)\n",
    "print(f\"Processed documents: {len(processed_docs)}\")\n",
    "\n",
    "all_chunks = []\n",
    "for doc in processed_docs:\n",
    "    doc_chunks = process_document(doc)\n",
    "    all_chunks.extend(doc_chunks)\n",
    "\n",
    "print(f\"Total chunks created: {len(all_chunks)}\")\n",
    "\n",
    "refined_chunks = refine_chunks(all_chunks)\n",
    "print(f\"Total refined chunks: {len(refined_chunks)}\")\n",
    "print(type(refined_chunks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85abee2",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "\n",
    "What chunking method or strategy did you use? Why did you use this method. Explain your design decision in less than 10 sentences.\n",
    "\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "\n",
    "We designed a hierarchical chunking strategy that respects the natural flow of a document. First, we extract logical sections using markdown headers (h1-h6), turning each section into its own chunk with its heading, content, and useful metadata like title, URL, parent sections, and pillar/department information. To avoid fragmentation, we combine very short chunks (under 100 characters) with nearby related content, and for long chunks (over 1000 characters), we split them using a recursive approach that breaks at natural separators such as paragraphs or sentences. We also keep a 100-character overlap between chunks to maintain context. This way, each chunk remains a complete, meaningful unit, perfectly sized for embedding and retrieval.\n",
    "\n",
    "------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 8,
   "id": "a133cf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is the implementation for using LangChain to create a vector store\n",
    "# But it didn't allow us to switch between different embeddings easily with various models\n",
    "\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embedding = OpenAIEmbeddings(model=EMBEDDING_MODEL, openai_api_key=OPENAI_API_KEY)\n",
    "# retriever = FAISS.from_documents(refined_chunks, embedding).as_retriever(search_kwargs={\"k\": 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "891962a0-65ac-48c5-8a36-6424f0e14734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example chunk: page_content='# About SUTD\n",
      "\n",
      "\n",
      "<p>SUTD integrates design, AI and technology into a holistic, interdisciplinary education and research experience. This unique approach encourages our students to push the boundaries of innovating solutions to real-world problems.</p>' metadata={'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'pillar': 'General', 'section_title': 'About SUTD', 'parent_sections': [], 'section_level': 1, 'internal_links': []}\n",
      "\n",
      "embedding 270 items with model: text-embedding-ada-002\n",
      "saved vector store with 270 documents\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: create embeddings of document chunks and store them in a local vector store for fast lookup\n",
    "# Decide an appropriate embedding model. Use Huggingface to run the embedding model locally.\n",
    "# You do not have to use cloud-based APIs.\n",
    "\n",
    "# --- ADD YOUR SOLUTION HERE (20 points)---\n",
    "# QUESTION: create embeddings of document chunks and store them in a local vector store for fast lookup\n",
    "# Decide an appropriate embedding model. Use Huggingface to run the embedding model locally.\n",
    "# You do not have to use cloud-based APIs.\n",
    "# --- ADD YOUR SOLUTION HERE (20 points)---\n",
    "\n",
    "\n",
    "\n",
    "# creating a retriever class to make it compatible with langchain and allow for huggingface embeddings and openai embeddings\n",
    "# this class that can handle both local Hugging Face models AND OpenAI models in one implementation (we made this to make it easy for us to switch between models)\n",
    "# the best part is storing the embeddings in a local vector store (i think langchain has this as well but we made our own)\n",
    "# we just added this layer on top of the simple langchain implementation\n",
    "class CustomEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        if model_name.startswith(\"text-embedding-\"):\n",
    "            self.model = None\n",
    "        else:\n",
    "            self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        print(f\"\\nembedding {len(texts)} items with model: {self.model_name}\")\n",
    "        if self.model_name.startswith(\"text-embedding-\"):\n",
    "            response = openai.embeddings.create(model=self.model_name, input=texts)\n",
    "            return [r.embedding for r in response.data]\n",
    "        else:\n",
    "            embeddings = self.model.encode(\n",
    "                texts, convert_to_numpy=True, normalize_embeddings=True\n",
    "            ).astype(\"float32\")\n",
    "            return embeddings.tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "# using FAISS to create a vector store from the documents and using it's as_retriever method to create a retriever\n",
    "# setting default k to 7\n",
    "# embedding model chosen is text-embedding-ada-002\n",
    "def create_retriever(refined_chunks, embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\", k=7):\n",
    "    embeddings = CustomEmbeddings(model_name=embedding_model)\n",
    "\n",
    "    if len(refined_chunks) > 0:\n",
    "        print(f\"example chunk: {refined_chunks[0]}\")\n",
    "\n",
    "    vectorstore = FAISS.from_documents(refined_chunks, embeddings)\n",
    "    vector_store_dir = OUTPUT_DIR\n",
    "    os.makedirs(vector_store_dir, exist_ok=True)\n",
    "    vectorstore.save_local(vector_store_dir)\n",
    "\n",
    "    print(f\"saved vector store with {len(refined_chunks)} documents\")\n",
    "    return vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "embedding_model = EMBEDDING_MODEL\n",
    "retriever = create_retriever(refined_chunks, embedding_model=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6bb601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import FlashrankRerank\n",
    "\n",
    "# the idea here is to rerank those candidates with a more powerful model (slower but more accurate)\n",
    "# we think that the retriever may not be able to pick the best documents hence use a reranker to pick the best documents\n",
    "# this is done by using the FlashrankRerank class\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [\n",
    "                f\"Document {i+1}:\\n\\n{d.page_content}\\nMetadata: {d.metadata}\"\n",
    "                for i, d in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "compressor = FlashrankRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f20674",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "\n",
    "What embeddings and vector store did you use and why? Explain your design decision in less than 10 sentences.\n",
    "\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
    "\n",
    "We used OpenAI's \"text-embedding-ada-002\" for embeddings and FAISS (Facebook AI Similarity Search) as our vector store. The \"text-embedding-ada-002\" model provides embeddings with high quality semantic understanding of academic and technical content, which is important for accurately representing SUTD's educational information. We have compared the performance of this model against the following other models namely: all-MiniLM-L6-v2, all-mpnet-base-v2, and text-embedding-3-small. Among the 4, text-embedding-ada-002 was able to perform the best (based on human judgement) and it also integrates smoothly alongside the vector store chosen.\n",
    "\n",
    "FAISS was our go-to choice because it efficiently handles nearest-neighbor searches in high-dimensional spaces, retrieves results quickly even from large collections, and keeps memory usage low through quantization. We have done research on other strategies such as Pinecone and Weaviate, but the ease of integration with FAISS utlimately helped us make our decision. Moreover, we have come across a lot of research in which FAISS was used, which proves its reliability.\n",
    "\n",
    "We built a custom embeddings class that works with both OpenAI and local HuggingFace models, so switching between them is seamless while using the same interface. This setup delivers fast, accurate semantic search results while reliably keeping the vector store locally.\n",
    "\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff0a3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: When was SUTD founded?\n",
      "\n",
      "embedding 1 items with model: text-embedding-ada-002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "# About SUTD\n",
      "\n",
      "\n",
      "<p>SUTD integrates design, AI and technology into a holistic, interdisciplinary education and research experience. This unique approach encourages our students to push the boundaries of innovating solutions to real-world problems.</p>\n",
      "Metadata: {'id': 0, 'relevance_score': np.float32(0.99885666), 'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'pillar': 'General', 'section_title': 'About SUTD', 'parent_sections': [], 'section_level': 1, 'internal_links': []}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "# Quick Links\n",
      "\n",
      "\n",
      "<ul>\n",
      "<li><a href=\"https://www.sutd.edu.sg/about/partnering-with-sutd/giving/\">Donate to SUTD</a></li>\n",
      "<li><a href=\"https://www.sutd.edu.sg/enterprise/research-collaborations/\">Research collaboration</a></li>\n",
      "<li><a href=\"https://www.sutd.edu.sg/enterprise/technology-licensing/\">Technology licensing</a></li>\n",
      "<li><a href=\"https://www.sutd.edu.sg/enterprise/design-innovation/\">Design innovation consultancy</a></li>\n",
      "<li><a href=\"https://www.sutd.edu.sg/education/undergraduate/capstone/\">Student Capstone projects</a></li>\n",
      "</ul>\n",
      "Metadata: {'id': 5, 'relevance_score': np.float32(0.991826), 'title': 'SUTD About page', 'url': 'https://www.sutd.edu.sg/about/', 'description': 'Provides an overview of SUTD, its mission, and its unique educational approach.', 'pillar': 'General', 'section_title': 'Quick Links', 'parent_sections': ['About SUTD', 'Our Vision', 'Our Mission', 'Core Values', 'Latest Happenings'], 'section_level': 3, 'internal_links': ['https://www.sutd.edu.sg/enterprise/design-innovation/', 'https://www.sutd.edu.sg/education/undergraduate/capstone/', 'https://www.sutd.edu.sg/enterprise/research-collaborations/', 'https://www.sutd.edu.sg/about/partnering-with-sutd/giving/', 'https://www.sutd.edu.sg/enterprise/technology-licensing/']}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "# Contact SUTD\n",
      "\n",
      "\n",
      "<p>Thank you for your interest in SUTD. We are located at:</p>\n",
      "<p><strong>Address:</strong> 8 Somapah Road Singapore 487372<br/>\n",
      "<strong>Tel:</strong> +65 6303 6600 / +65 6303 6655<br/>\n",
      "<strong>Email:</strong> <a href=\"mailto:enquiry@sutd.edu.sg\">enquiry@sutd.edu.sg</a> / <a href=\"mailto:admissions@sutd.edu.sg\">admissions@sutd.edu.sg</a></p>\n",
      "Metadata: {'id': 1, 'relevance_score': np.float32(0.9899743), 'title': 'SUTD Contact page', 'url': 'https://www.sutd.edu.sg/contact-us/contact-sutd/', 'description': 'Offers various methods to contact SUTD, including phone numbers, email addresses, and physical addresses.', 'pillar': 'General', 'section_title': 'Contact SUTD', 'parent_sections': [], 'section_level': 1, 'internal_links': []}\n"
     ]
    }
   ],
   "source": [
    "# Execute a query against the vector store\n",
    "\n",
    "query = \"When was SUTD founded?\"\n",
    "\n",
    "# QUESTION: run the query against the vector store, print the top 5 search results\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points)---\n",
    "# TODO: manually add in when SUTD was founded to the dataset\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# use the query_index function to get the top k results\n",
    "response = compression_retriever.invoke(query)\n",
    "pretty_print_docs(response)\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ce000",
   "metadata": {},
   "source": [
    "## Huggingface Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0492e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "003e2cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f8d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3e5be828ef463fadc53dc81ce70870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response:\n",
      "What courses are available in SUTD??\n",
      "Singapore University of Technology and Design (SUTD) offers a wide range of undergraduate and graduate courses across various disciplines. Here are some of the courses available in SUTD:\n",
      "\n",
      "**Undergraduate Courses**\n",
      "\n",
      "1. Bachelor of Science in Information Technology (BSIT)\n",
      "2. Bachelor of Science in Information Systems (BSIS)\n",
      "3. Bachelor of Science in Information Technology and Systems (BSITS)\n",
      "4. Bachelor of Science in Data Science (BSDS)\n",
      "5. Bachelor of Science in Artificial Intelligence and Data Science (BSAIDS)\n",
      "6. Bachelor of Science in Human-Computer Interaction (BSHCI)\n",
      "7. Bachelor of Science in Information Technology and Systems (BSITS)\n",
      "8. Bachelor of Science in Computer Science (BSCS)\n",
      "9. Bachelor of Science in Engineering (BSE)\n",
      "10. Bachelor of Science in Design (BSD)\n",
      "11. Bachelor of Science in Architecture (BSA)\n",
      "12. Bachelor of Science in Biomedical Engineering (BSBME)\n",
      "13. Bachelor of Science in Electrical Engineering (BSEE)\n",
      "14. Bachelor of Science in Mechanical Engineering (BSME)\n",
      "15. Bachelor of Science in Civil Engineering (BSCE)\n",
      "\n",
      "**Graduate Courses**\n",
      "\n",
      "1. Master of Science in Information Technology (MSIT)\n",
      "2. Master of Science in Information Systems\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Use the Huggingface transformers library to load the Llama 3.2-3B instruct model\n",
    "# https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct\n",
    "# Run the model locally. You do not have to use cloud-based APIs.\n",
    "\n",
    "# Execute the below query against the model and let it it answer from it's internal memory\n",
    "\n",
    "query = \"What courses are available in SUTD?\"\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\", model=model_id, max_new_tokens=256, device = device # setting max_new_tokens to 512 to be able to run on my GPU\n",
    ")\n",
    "\n",
    "# TODO: fix \n",
    "output = pipeline(query)\n",
    "print(\"Model Response:\")\n",
    "print(output[0][\"generated_text\"])\n",
    "\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36af8f0a-45d0-404e-a1e9-8e16af4a158a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "models is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 404 Client Error: Not Found for url: https://huggingface.co/models/resolve/main/tokenizer_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\utils\\hub.py:424\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:961\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1068\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1596\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1593\u001b[39m ):\n\u001b[32m   1594\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1595\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1484\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1401\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1401\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:285\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m response = get_session().request(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 404 Client Error. (Request ID: Root=1-67f0f2e3-1a8097af63d7f8cf190c4664;072f8c5f-99ec-43ce-adf5-9f7187c2f25b)\n\nRepository Not Found for url: https://huggingface.co/models/resolve/main/tokenizer_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RetrievalQA\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m model = AutoModelForCausalLM.from_pretrained(\n\u001b[32m     17\u001b[39m     MODEL_DIR,\n\u001b[32m     18\u001b[39m     torch_dtype=torch.float16,  \u001b[38;5;66;03m# using float16 for faster inference\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     low_cpu_mem_usage=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m pipeline = pipeline(\n\u001b[32m     25\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer, max_new_tokens=\u001b[32m256\u001b[39m \u001b[38;5;66;03m# setting max_new_tokens to 512 to be able to run on my GPU\u001b[39;00m\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:910\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n\u001b[32m    909\u001b[39m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m910\u001b[39m tokenizer_config = \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[32m    912\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m] = tokenizer_config[\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:742\u001b[39m, in \u001b[36mget_tokenizer_config\u001b[39m\u001b[34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[39m\n\u001b[32m    739\u001b[39m     token = use_auth_token\n\u001b[32m    741\u001b[39m commit_hash = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33m_commit_hash\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m resolved_config_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    759\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\utils\\hub.py:266\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    209\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    210\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    211\u001b[39m     **kwargs,\n\u001b[32m    212\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    213\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\chian\\Documents\\Code\\sutd_5055mlop-adi\\myenv\\Lib\\site-packages\\transformers\\utils\\hub.py:456\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# We cannot recover from them\u001b[39;00m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RepositoryNotFoundError) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, GatedRepoError):\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    457\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a local folder and is not a valid model identifier \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlisted on \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/models\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    459\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    460\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`token=<your_token>`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, RevisionNotFoundError):\n\u001b[32m    463\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[32m    464\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    465\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfor this model name. Check the model page at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    466\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for available revisions.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    467\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mOSError\u001b[39m: models is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "# QUESTION: Now put everything together. Use langchain to integrate your vector store and Llama model into a RAG system\n",
    "# Run the below example question against your RAG system.\n",
    "\n",
    "# Example questions\n",
    "# TODO: what does this mean?\n",
    "query = \"How can I increase my chances of admission into SUTD?\"\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_DIR,\n",
    "    torch_dtype=torch.float16,  # using float16 for faster inference\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,          # adding a 4-bit quantization\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256 # setting max_new_tokens to 512 to be able to run on my GPU\n",
    ")\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipeline)\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result = rag_chain.run(query)\n",
    "print(\"RAG Chain Response:\")\n",
    "print(result)\n",
    "#------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f30ce26-8a19-4492-91e3-1cea5f750d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: Below is set of test questions. Add another 10 test questions based on your user interviews and your value proposition canvas.\n",
    "# Run the complete set of test questions against the RAG question answering system.\n",
    "\n",
    "questions = [\"What are the admissions deadlines for SUTD?\",\n",
    "             \"Is there financial aid available?\",\n",
    "             \"What is the minimum score for the Mother Tongue Language?\",\n",
    "             \"Do I require reference letters?\",\n",
    "             \"Can polytechnic diploma students apply?\",\n",
    "             \"Do I need SAT score?\",\n",
    "             \"How many PhD students does SUTD have?\",\n",
    "             \"How much are the tuition fees for Singaporeans?\",\n",
    "             \"How much are the tuition fees for international students?\",\n",
    "             \"Is there a minimum CAP?\"\n",
    "             ]\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
    "additional_questions = [\n",
    "    \"What is SUTDs mission and vision?\",\n",
    "    \"When was SUTD officially inaugurated?\",\n",
    "    \"Which core values does SUTD emphasize?\",\n",
    "    \"Where is SUTD located, and how can it be contacted?\",\n",
    "    \"What different SUTD offices or departments can I reach out to?\",\n",
    "    \"What are the key components of the Freshmore curriculum at SUTD?\",\n",
    "    \"Which elective modules are available for Freshmore students in Term 3?\",\n",
    "    \"What courses are offered within the Design and Artificial Intelligence pillar?\",\n",
    "    \"Who are some of the instructors teaching the courses in the DAI program?\",\n",
    "    \"What are the main steps involved in the SUTD application process?\"\n",
    "]\n",
    "\n",
    "all_questions = questions + additional_questions\n",
    "for q in all_questions:\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Question: \" + q)\n",
    "    #run the RAG chain\n",
    "    result = rag_chain.run(q)\n",
    "    print(\"Response:\")\n",
    "    print(result)\n",
    "    print(\"----------------------------------------------------------------\\n\")#---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fd068",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "\n",
    "\n",
    "Manually inspect each answer, fact check whether the answer is correct (use Google or any other method) and check the retrieved documents\n",
    "\n",
    "For each question, answer and context triple, record the following\n",
    "\n",
    "- How accurate is the answer (1-5, 5 best)?\n",
    "- How relevant is the retrieved context (1-5, 5 best)?\n",
    "- How grounded is the answer in the retrieved context (instead of relying on the LLM's internal knowledge) (1-5, 5 best)?\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (20 points) ---**\n",
    "\n",
    "\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67543217",
   "metadata": {},
   "source": [
    "You can try improve the chatbot by going back to previous steps in the notebook and change things until the submission deadline. For example, you can add more data sources, change the embedding models, change the data pre-processing, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3789e17-3fea-495d-a843-85f4b752812b",
   "metadata": {},
   "source": [
    "# End\n",
    "\n",
    "This concludes assignment 3.\n",
    "\n",
    "Please submit this notebook with your answers and the generated output cells as a **Jupyter notebook file** via github.\n",
    "\n",
    "\n",
    "Every group member should do the following submission steps:\n",
    "1. Create a private github repository **sutd_5055mlop** under your github user.\n",
    "2. Add your instructors as collaborator: ddahlmeier and lucainiaoge\n",
    "3. Save your submission as assignment_03_GROUP_NAME.ipynb where GROUP_NAME is the name of the group you have registered. \n",
    "4. Push the submission files to your repo \n",
    "5. Submit the link to the repo via eDimensions\n",
    "\n",
    "\n",
    "\n",
    "**Assignment due 6 April 2025 11:59pm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ad52c-8a4a-49be-bb75-17eaa4830706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
