{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b1cfb22-4b03-4682-9a21-bca5cb05c682",
   "metadata": {},
   "source": [
    "# Assignment 1: detecting offensive content on twitter\n",
    "**Assignment due 1 March 2025 11:59pm**\n",
    "\n",
    "Welcome to the first assignment for 50.055 Machine Learning Operations. These assignments give you a chance to practice the methods and tools you have learned. \n",
    "\n",
    "**This assignment is an individual assignment.**\n",
    "\n",
    "- Read the instructions in this notebook carefully\n",
    "- Add your solution code and answers in the appropriate places. The questions are marked as **QUESTION:**, the places where you need to add your code and text answers are marked as **ADD YOUR SOLUTION HERE**\n",
    "- The completed notebook, including your added code and generated output, will be your submission for the assignment.\n",
    "- The notebook should execute without errors from start to finish when you select \"Restart Kernel and Run All Cells..\". Please test this before submission.\n",
    "- Use the SUTD Education Cluster or Google Colab to solve and test the assignment.\n",
    "\n",
    "**Rubric for assessment** \n",
    "\n",
    "Your submission will be graded using the following criteria. \n",
    "1. Code executes: your code should execute without errors. The SUTD Education cluster should be used to ensure the same execution environment.\n",
    "2. Correctness: the code should produce the correct result or the text answer should state the factual correct answer.\n",
    "3. Style: your code should be written in a way that is clean and efficient. Your text answers should be relevant, concise and easy to understand.\n",
    "4. Partial marks will be awarded for partially correct solutions.\n",
    "5. There is a maximum of 76 points for this assignment.\n",
    "\n",
    "\n",
    "**ChatGPT policy:** \n",
    "\n",
    "If you use AI tools, such as ChatGPT, to solve the assignment questions, you need to be transparent about its use and mark AI-generated content as such. In particular, you should include the following in addition to your final answer:\n",
    "- A copy or screenshot of the prompt you used\n",
    "- The name of the AI model\n",
    "- The AI generated output\n",
    "- An explanation why the answer is correct or what you had to change to arrive at the correct answer\n",
    "\n",
    "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission Instructions are located at the bottom of the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "980439b6-d91e-467e-a0b8-45a0d6637c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.37.2 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]==4.37.2) (4.37.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers==4.37.2->transformers[torch]==4.37.2) (4.67.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.11 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]==4.37.2) (2.1.1+cu118)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]==4.37.2) (0.28.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.21.0->transformers[torch]==4.37.2) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->transformers[torch]==4.37.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.37.2->transformers[torch]==4.37.2) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]==4.37.2) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]==4.37.2) (3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]==4.37.2) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]==4.37.2) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.37.2->transformers[torch]==4.37.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.37.2->transformers[torch]==4.37.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.37.2->transformers[torch]==4.37.2) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers==4.37.2->transformers[torch]==4.37.2) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]==4.37.2) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]==4.37.2) (1.3.0)\n",
      "Requirement already satisfied: evaluate==0.4.1 in /opt/conda/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (2.17.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (1.26.0)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate==0.4.1) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.11/site-packages (from evaluate==0.4.1) (0.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (3.9.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (3.8.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->evaluate==0.4.1) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate==0.4.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate==0.4.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->evaluate==0.4.1) (2025.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.1) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn==1.4.0 in /opt/conda/lib/python3.11/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.4.0) (3.5.0)\n",
      "Requirement already satisfied: datasets==2.17.1 in /opt/conda/lib/python3.11/site-packages (2.17.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (1.26.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (19.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.17.1) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets==2.17.1) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.17.1) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.17.1) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.17.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.17.1) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.17.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.17.1) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets==2.17.1) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets==2.17.1) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.17.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.17.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.19.0->datasets==2.17.1) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.17.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.17.1) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets==2.17.1) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.17.1) (1.16.0)\n",
      "Requirement already satisfied: wandb==0.16.3 in /opt/conda/lib/python3.11/site-packages (0.16.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (8.1.8)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (3.1.44)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (2.32.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (2.22.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (68.2.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.11/site-packages (from wandb==0.16.3) (4.25.6)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb==0.16.3) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.11/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.3) (4.0.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb==0.16.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb==0.16.3) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb==0.16.3) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.0.0->wandb==0.16.3) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.3) (5.0.2)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /opt/conda/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.11/site-packages (from seaborn==0.13.2) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn==0.13.2) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.11/site-packages (from seaborn==0.13.2) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn==0.13.2) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn==0.13.2) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.2) (1.16.0)\n",
      "Requirement already satisfied: peft==0.10.0 in /opt/conda/lib/python3.11/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (2.1.1+cu118)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (4.37.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (0.28.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (0.5.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.11/site-packages (from peft==0.10.0) (0.29.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.17.0->peft==0.10.0) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.10.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.10.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.10.0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.13.0->peft==0.10.0) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers->peft==0.10.0) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.11/site-packages (from transformers->peft==0.10.0) (0.15.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.13.0->peft==0.10.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.10.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.13.0->peft==0.10.0) (1.3.0)\n",
      "Requirement already satisfied: accelerate==0.28.0 in /opt/conda/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.28.0) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.28.0) (23.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate==0.28.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate==0.28.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.28.0) (2.1.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.11/site-packages (from accelerate==0.28.0) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from accelerate==0.28.0) (0.5.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.28.0) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.28.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.28.0) (2023.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate==0.28.0) (2.1.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->accelerate==0.28.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub->accelerate==0.28.0) (4.67.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate==0.28.0) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing all required packages\n",
    "# ----------------\n",
    "! pip install transformers[torch]==4.37.2\n",
    "! pip install evaluate==0.4.1\n",
    "! pip install scikit-learn==1.4.0\n",
    "! pip install datasets==2.17.1\n",
    "! pip install wandb==0.16.3\n",
    "! pip install seaborn==0.13.2\n",
    "! pip install peft==0.10.0\n",
    "! pip install accelerate==0.28.0 \n",
    "# ----------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a272f7c4-8dec-4ec8-986c-2ee28ed366f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing all required packages\n",
    "# ----------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adda5aa5-1297-4767-b36e-05fe6df2cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f84068-a112-46a0-b531-494a903eccae",
   "metadata": {},
   "source": [
    "# Offensive language detection\n",
    "\n",
    "Content moderation of offensive or hateful language is an important task on social media platforms. \n",
    "In this assignment, you will train a text classification models for detecting offensive language on twitter. You will run experiments with different models and evaluate their performance and costs.\n",
    "\n",
    "We will use the TweetEval data set from Barbiert et al (2020): https://aclanthology.org/2020.findings-emnlp.148.pdf\n",
    "\n",
    "\n",
    "**Warning**\n",
    "Some of the content contains rude and offensive language. If you know that this causes you distress, let the course instructor know to arrange a different assessment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730b9f1f-5862-40c0-8b10-a1b7c23fac90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 11916\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 860\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1324\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data set \n",
    "dataset = load_dataset(\"tweet_eval\", \"offensive\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e89a6973-1615-4d7d-8751-744e140465ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '@user Bono... who cares. Soon people will understand that they gain nothing from following a phony celebrity. Become a Leader of your people instead or help and support your fellow countrymen.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QUESTION: print the first training set sample \n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (1 point)---\n",
    "dataset[\"train\"][0]\n",
    "#------------------------------\n",
    "# Hint: you should see a tweet about U2 singer Bono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8915fe-1ed9-4b4a-82ed-fa34de18427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label values - {0, 1}\n",
      "0 - non-offensive\n",
      "1 - offensive\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: what are the possible values of the labels? What is their meaning? \n",
    "# Print the set of label values and their label names\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "values = set(dataset[\"train\"][\"label\"])\n",
    "print(\"label values -\", values)\n",
    "\n",
    "names = dataset[\"train\"].features[\"label\"].names\n",
    "for idx, name in enumerate(names):\n",
    "    print(f\"{idx} - {name}\")\n",
    "# -------\n",
    "# Hint: it is a binary task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdbf3671-1066-4458-92fd-dc1932094187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Label Distribution'}, xlabel='Labels', ylabel='Counts'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# QUESTION: plot a bar chart of the label distribution\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "df = dataset['train'].to_pandas()\n",
    "labels = df['label']\n",
    "counts = labels.value_counts()\n",
    "counts.plot(kind='bar', figsize=(10,5), title='Label Distribution', xlabel='Labels', ylabel='Counts')\n",
    "#------------------------------\n",
    "# Hint: it is not evenly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f73f29c-9728-4a19-8d5a-9e7440d56f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: separate data set into training, validation and test according to given dataset split\n",
    "# You should end up with the following variables\n",
    "# train_text = array containing strings in training set\n",
    "# train_labels = array containing numeric labels in training set\n",
    "# validation_text = array containing strings in training set\n",
    "# validation_labels = array containing numeric labels in training set\n",
    "# test_text = array containing strings in training set\n",
    "# test_labels = array containing numeric labels in training set\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (10 points) ---\n",
    "train_text = dataset[\"train\"][\"text\"]\n",
    "train_labels = dataset[\"train\"][\"label\"]\n",
    "\n",
    "validation_text = dataset[\"validation\"][\"text\"]\n",
    "validation_labels = dataset[\"validation\"][\"label\"]\n",
    "\n",
    "test_text = dataset[\"test\"][\"text\"]\n",
    "test_labels = dataset[\"test\"][\"label\"]\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4254bcf4-3926-4989-99a4-6985e3410caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train:  11916\n",
      "#validation:  1324\n",
      "#test:  860\n"
     ]
    }
   ],
   "source": [
    "# check the size of the data splits\n",
    "print(\"#train: \", len(train_text)) \n",
    "print(\"#validation: \", len(validation_text)) \n",
    "print(\"#test: \", len(test_text)) \n",
    "\n",
    "# Hint: you should see\n",
    "#train:  11916\n",
    "#validation:  1324\n",
    "#test:  860"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9562c182-b658-49b3-bcd3-852052dc7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# QUESTION: create a scikit-learn pipeline object that creates unigram features, applies tf-idf weighting and trains a SGDClassifier \n",
    "# tf-idf stands for \"Term Frequency times Inverse Document Frequency\".\n",
    "# tf-idf is a feature weighting methods commonly used in NLP and IR\n",
    "# use default parameters for unigram feature extraction, tf-idf and the SGDClassifier\n",
    "# add additional import statements in this cell as needed\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (10 points) ---\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('classifier', SGDClassifier())\n",
    "])\n",
    "#------------------------------\n",
    "# Hint: use the scikit-learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f27bb73-f483-4364-9b9a-59493031cfcf",
   "metadata": {},
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54deb077-2ede-425c-91f8-32d24381f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# QUESTION: apply your pipeline of feature extraction and model training to the training set\n",
    "# Measure the wall-clock training time needed \n",
    "# Store the training time in a variable 'train_time_sgd\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "import time\n",
    "start = time.time()\n",
    "pipeline.fit(train_text, train_labels)\n",
    "end = time.time()\n",
    "train_time_sgd = end - start\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de2987f-83f1-4948-a390-05ed2517f151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time: 0.3645956516265869s\n"
     ]
    }
   ],
   "source": [
    "print(f\"training time: {train_time_sgd}s\")\n",
    "\n",
    "# Hint: training should take < 1 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637838e-9741-4c6f-a889-e76dfbe25ead",
   "metadata": {},
   "source": [
    "# Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c2a4a7-78ea-4942-afe3-cf20d177eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "majority class: 0\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.65      1.00      0.79       865\n",
      "non offensive       0.00      0.00      0.00       459\n",
      "\n",
      "     accuracy                           0.65      1324\n",
      "    macro avg       0.33      0.50      0.40      1324\n",
      " weighted avg       0.43      0.65      0.52      1324\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    offensive       0.72      1.00      0.84       620\n",
      "non offensive       0.00      0.00      0.00       240\n",
      "\n",
      "     accuracy                           0.72       860\n",
      "    macro avg       0.36      0.50      0.42       860\n",
      " weighted avg       0.52      0.72      0.60       860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# QUESTION: compute the majority class baseline score on the validation set and test set\n",
    "# the majority class baseline is the score you get if you always predict the most frequent label\n",
    "# \n",
    "# Compute the precision, recall and F1 score for the majority baseline for validation and test set for each class\n",
    "#\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "# easiest way to get the metrics is to use the classification_report since I dont need to isolate the metrics for this one\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = ['offensive', 'non offensive']\n",
    "# get the majority  class in the training set\n",
    "majority_class = np.argmax(np.bincount(train_labels))\n",
    "print(f\"majority class: {majority_class}\")\n",
    "\n",
    "val_baseline = [majority_class] * len(validation_labels)\n",
    "test_baseline = [majority_class] * len(test_labels)\n",
    "\n",
    "print(classification_report(validation_labels, val_baseline, target_names=class_names))\n",
    "print(classification_report(test_labels, test_baseline, target_names=class_names))\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1a2cb65-1d21-4df8-b339-adc157eef182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy: 0.7621\n",
      "Val Precision: 0.8050847457627118\n",
      "Val Recall: 0.4139433551198257\n",
      "F1 score for offensive (positive) tweets (validation): 0.5468\n",
      "Test Accuracy: 0.8081\n",
      "Test Precision: 0.8151260504201681\n",
      "Test Recall: 0.4041666666666667\n",
      "F1 score for offensive (positive) tweets (test): 0.5404\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# \n",
    "# QUESTION: now use your pipeline to make predictions on validation and test set\n",
    "# compute and print accuracy, precision, recall, F1 score\n",
    "# \n",
    "# From now on, we are only concerned with the F1 score for the \"positive\" class which are the offensive tweets\n",
    "# Store the test F1 score for the \"positive\" class in a variable 'f1_validation_sgd' and 'f1_test_sgd' for validation and test set, respectively \n",
    "#--- ADD YOUR SOLUTION HERE (10 points) ---\n",
    "from sklearn.metrics import  f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "# validation set\n",
    "val_pred = pipeline.predict(validation_text)\n",
    "val_accuracy = accuracy_score(validation_labels, val_pred)\n",
    "val_precision = precision_score(validation_labels, val_pred)\n",
    "val_recall = recall_score(validation_labels, val_pred)\n",
    "val_f1 = f1_score(validation_labels, val_pred, pos_label=1) # added this pos_label=1 to make sure it's only for positive class\n",
    "\n",
    "f1_val_sgd = val_f1  #  already for positive class\n",
    "print(f\"Val Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Val Precision: {val_precision}\")\n",
    "print(f\"Val Recall: {val_recall}\")\n",
    "print(f\"F1 score for offensive (positive) tweets (validation): {f1_val_sgd:.4f}\")\n",
    "\n",
    "# test set\n",
    "test_pred = pipeline.predict(test_text)\n",
    "test_accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "test_precision = metrics.precision_score(test_labels, test_pred)\n",
    "test_recall = metrics.recall_score(test_labels, test_pred)\n",
    "test_f1 = metrics.f1_score(test_labels, test_pred, pos_label=1)# added this pos_label=1 to make sure it's only for positive class\n",
    "f1_test_sgd = test_f1  # already for positive class\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision}\")\n",
    "print(f\"Test Recall: {test_recall}\")\n",
    "print(f\"F1 score for offensive (positive) tweets (test): {f1_test_sgd:.4f}\")\n",
    "#------------------------------\n",
    "# Hint: F1 scores should be >50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7958c9e-6aab-4066-a0f0-0296e08c0935",
   "metadata": {},
   "source": [
    "# BERT model\n",
    "\n",
    "Now let us try a more powerful model: the DistilBERT uncased model\n",
    "\n",
    "https://huggingface.co/distilbert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4106f683-1c93-414f-b7ba-31a3722367da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load DistilBERT tokenizer and tokenize data set\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset = tokenized_datasets[\"validation\"]\n",
    "test_dataset = tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09087fb6-1cc6-457c-b601-316d7bb3b3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load DistilBERT model for classification\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Available device: ', device)\n",
    "# loading the DistilBERT using AutoModelForSequenceClassification with 2 labels\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "#------------------------------\n",
    "# Hint: make sure your model corresponds to your tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d865dca-a413-4060-ac4e-a49039262f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add custom metrics that computes precision, recall, f1, accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "   # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(labels, preds, average='binary')\n",
    "    recall = recall_score(labels, preds, average='binary')\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edcbf727-1479-4b81-988a-c18eba4de126",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# QUESTION: configure the training parameters using the Huggingface TrainingArguments class\n",
    "# - set the output directory to \"finetuning-tweeteval\"\n",
    "# - do not report training metrics to an external experiment tracking service\n",
    "# - print acc/p/r/f1 scores on the validation set every 200 steps\n",
    "# - learning rate to 2e-5, \n",
    "# - set weight decay to 0.01\n",
    "# - set epochs to 1\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points) ---\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"finetuning-tweeteval\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=200,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    report_to=\"none\",  # this is the do not report to any external service,\n",
    ")\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52ef1bb5-565d-4d9d-ad4a-cfba3f6d47d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30d891ae-4a62-44d1-8cf1-d05a1bc75074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1490' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 04:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>0.497089</td>\n",
       "      <td>0.747734</td>\n",
       "      <td>0.606838</td>\n",
       "      <td>0.773420</td>\n",
       "      <td>0.680077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.456010</td>\n",
       "      <td>0.795317</td>\n",
       "      <td>0.781437</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.658260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.458876</td>\n",
       "      <td>0.810423</td>\n",
       "      <td>0.757426</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.709154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.460969</td>\n",
       "      <td>0.793807</td>\n",
       "      <td>0.751351</td>\n",
       "      <td>0.605664</td>\n",
       "      <td>0.670688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.473000</td>\n",
       "      <td>0.432049</td>\n",
       "      <td>0.796073</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.671024</td>\n",
       "      <td>0.695260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.433367</td>\n",
       "      <td>0.798338</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.670777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>0.429440</td>\n",
       "      <td>0.803625</td>\n",
       "      <td>0.750630</td>\n",
       "      <td>0.649237</td>\n",
       "      <td>0.696262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory finetuning-tweeteval/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory finetuning-tweeteval/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "# i'm using time here because it's consistent with the sgd (instead of extracting it from Trainer)\n",
    "from time import time\n",
    "start = time()\n",
    "train_output = trainer.train()\n",
    "end = time()\n",
    "train_time_bert = end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "003379b3-a5ba-4d80-8998-514d57bf2449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2038' max='1490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1490/1490 01:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.36067232489585876,\n",
       " 'eval_accuracy': 0.8464249748237663,\n",
       " 'eval_precision': 0.7970728961441036,\n",
       " 'eval_recall': 0.7185993402689672,\n",
       " 'eval_f1': 0.755804643714972,\n",
       " 'eval_runtime': 65.2757,\n",
       " 'eval_samples_per_second': 182.549,\n",
       " 'eval_steps_per_second': 22.826,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "trainer.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eeb0514-431e-44b0-8372-c57e354bc330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4275238513946533,\n",
       " 'eval_accuracy': 0.8066465256797583,\n",
       " 'eval_precision': 0.7493857493857494,\n",
       " 'eval_recall': 0.664488017429194,\n",
       " 'eval_f1': 0.7043879907621247,\n",
       " 'eval_runtime': 7.4462,\n",
       " 'eval_samples_per_second': 177.809,\n",
       " 'eval_steps_per_second': 22.293,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "trainer.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c51d1460-504c-4ab3-8eaf-0691f1f5a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3695092797279358, 'eval_accuracy': 0.8465116279069768, 'eval_precision': 0.77, 'eval_recall': 0.6416666666666667, 'eval_f1': 0.7, 'eval_runtime': 4.8413, 'eval_samples_per_second': 177.64, 'eval_steps_per_second': 22.308, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_output = trainer.evaluate(test_dataset)\n",
    "print(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1d39da-72df-410e-adb4-325c6be590d4",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "Do you see any signs of overfitting or underfitting based on the evaluation scores\n",
    "Explain why or why not\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (5 points) ---**\n",
    "\n",
    "The gap between training and validation/test metrics isn't large. That's a good sign that the model generalizes well to unseen data. (This is from my experience as I don't know what a large gap is for this context)\n",
    "\n",
    "The model also doesn't show any form of significant underfitting because if there was underfitting I would expect much lower performance on the F1 score on all datasets.\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c82913fe-0bbc-41de-acae-ad0662926b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.2247452735901\n",
      "SGD ratio: 1.4822\n",
      "BERT ratio: 0.0028\n",
      "\n",
      "Ratio comparison (SGD/BERT): 529.8195902583682\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# QUESTION: What is the ratio f1 score to training time for the SGDClassifier and the DistilBERT model\n",
    "# compute the two ratios and print them\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE ---\n",
    "ratio_sgd = f1_test_sgd / train_time_sgd\n",
    "ratio_bert = test_output['eval_f1'] / train_time_bert\n",
    "print(train_time_bert)\n",
    "\n",
    "print(f\"SGD ratio: {ratio_sgd:.4f}\")\n",
    "print(f\"BERT ratio: {ratio_bert:.4f}\")\n",
    "print(f\"\\nRatio comparison (SGD/BERT): {ratio_sgd/ratio_bert}\")\n",
    "#------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e7d14-f997-4022-ab46-2cb1ac247073",
   "metadata": {},
   "source": [
    "### QUESTION: \n",
    "Given the results what model would you recommend to use? Write a paragraph (max 200 words) to explain your choice\n",
    "\n",
    "**--- ADD YOUR SOLUTION HERE (10 points)---**\n",
    "\n",
    "I would recommend using the SGDClassifier for this offensive tweet detection task. The SGD model trains in less than a second, while still achieving really respectable performance metrics. It's an efficiency thing to consider.\n",
    "\n",
    "For a content moderation system like such that requires frequent retraining as new data becomes available, the SGDClassifier  being able to train quickly and adapt to the new data is pretty neat. Additionally, the SGD model is much less resource-intensive during both training and inference, making it easy on the deployement side.\n",
    "\n",
    "If absolute performance were the only consideration, DistilBERT would be preferable (especially in scenarios which require contextual understanding of the text). But, in practical MLOps scenarios, the trade-off between performance and efficiency strongly favors the SGDClassifier (Based on the ratios shown above. The SGD is about 530 times more EFFICIENT!).\n",
    "\n",
    "\n",
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc57acf-c65a-4ba7-9d9c-9b212251e542",
   "metadata": {},
   "source": [
    "# End\n",
    "\n",
    "This concludes assignment 1.\n",
    "\n",
    "\n",
    "Please submit this notebook with your answers and the generated output cells as a **Jupyter notebook file** via github.\n",
    "\n",
    "\n",
    "1. Create a private github repository **sutd_5055mlop** under your github user.\n",
    "2. Add your instructors as collaborator: ddahlmeier and lucainiaoge\n",
    "3. Save your submission as assignment_01_STUDENT_NAME.ipynb where STUDENT_NAME is your name in your SUTD email address.\n",
    "4. Push the submission file to your repo \n",
    "5. Submit the link to the repo via eDimensions\n",
    "\n",
    "Example:<br/>\n",
    "Email: michael_tan@mymail.sutd.edu.sg<br/>\n",
    "STUDENT_NAME: michael_tan<br/>\n",
    "Submission file name: assignment_01_michael_tan.ipynb\n",
    "\n",
    "\n",
    "\n",
    "**Assignment due 01 March 2025 11:59pm**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc1be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
