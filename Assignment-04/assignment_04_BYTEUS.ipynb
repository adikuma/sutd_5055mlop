{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f99a8a55",
      "metadata": {
        "id": "f99a8a55"
      },
      "source": [
        "# Group Project / Assignment 4: Instruction finetuning a Llama-3.2 model\n",
        "**Assignment due 21 April 11:59pm**\n",
        "\n",
        "Welcome to the fourth and final assignment for 50.055 Machine Learning Operations. The third and fourth assignment together form the course group project. You will continue the work on a chatbot which can answer questions about SUTD to prospective students.\n",
        "\n",
        "\n",
        "**This assignment is a group assignment.**\n",
        "\n",
        "- Read the instructions in this notebook carefully\n",
        "- Add your solution code and answers in the appropriate places. The questions are marked as **QUESTION:**, the places where you need to add your code and text answers are marked as **ADD YOUR SOLUTION HERE**. The assignment is more open-ended than previous assignments, i.e. you have more freedom how to solve the problem and how to structure your code.\n",
        "- The completed notebook, including your added code and generated output will be your submission for the assignment.\n",
        "- The notebook should execute without errors from start to finish when you select \"Restart Kernel and Run All Cells..\". Please test this before submission.\n",
        "- Use the SUTD Education Cluster to solve and test the assignment. If you work on another environment, minimally test your work on the SUTD Education Cluster.\n",
        "\n",
        "**Rubric for assessment**\n",
        "\n",
        "Your submission will be graded using the following criteria.\n",
        "1. Code executes: your code should execute without errors. The SUTD Education cluster should be used to ensure the same execution environment.\n",
        "2. Correctness: the code should produce the correct result or the text answer should state the factual correct answer.\n",
        "3. Style: your code should be written in a way that is clean and efficient. Your text answers should be relevant, concise and easy to understand.\n",
        "4. Partial marks will be awarded for partially correct solutions.\n",
        "5. Creativity and innovation: in this assignment you have more freedom to design your solution, compared to the first assignments. You can show of your creativity and innovative mindset.\n",
        "6. There is a maximum of 310 points for this assignment.\n",
        "\n",
        "**ChatGPT policy**\n",
        "\n",
        "If you use AI tools, such as ChatGPT, to solve the assignment questions, you need to be transparent about its use and mark AI-generated content as such. In particular, you should include the following in addition to your final answer:\n",
        "- A copy or screenshot of the prompt you used\n",
        "- The name of the AI model\n",
        "- The AI generated output\n",
        "- An explanation why the answer is correct or what you had to change to arrive at the correct answer\n",
        "\n",
        "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission Instructions are located at the bottom of the notebook.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae5e449",
      "metadata": {
        "id": "dae5e449"
      },
      "source": [
        "### Finetuning LLMs\n",
        "\n",
        "The goal of the assignment is to build a more advanced chatbot that can talk to prospective students and answer questions about SUTD.\n",
        "\n",
        "We will finetune a smaller 1B LLM on question-answer pairs which we synthetically generate. Then we will compare the finetuned and non-finetuned LLMs with and without RAG to see if we were able to improve the SUTD chatbot answer quality.\n",
        "\n",
        "We'll be leveraging `langchain`, `llama 3.2` and `Google AI STudio with Gemini 2.0`.\n",
        "\n",
        "Check out the docs:\n",
        "- [LangChain](https://docs.langchain.com/docs/)\n",
        "- [Llama 3.2](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/)\n",
        "- [Google AI Studio](https://aistudio.google.com/)\n",
        "\n",
        "Note: Google AI Studio provides a lot of free tokens but has certain rate limits. Write your code in a way that it can handle these limits."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62530070",
      "metadata": {
        "id": "62530070"
      },
      "source": [
        "# Install dependencies\n",
        "Use pip to install all required dependencies of this assignment in the cell below. Make sure to test this on the SUTD cluster as different environments have different software pre-installed.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4ec75011-c8ef-4c31-9766-2e3e9834684f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ec75011-c8ef-4c31-9766-2e3e9834684f",
        "outputId": "36bffa71-6521-404d-a48e-29850a7208d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m690.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.1.31)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.52)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.31)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain_openai) (1.75.0)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: filetype, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, tiktoken, pydantic-settings, dataclasses-json, langchain-core, langchain_openai, google-ai-generativelanguage, langchain-google-genai, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.52\n",
            "    Uninstalling langchain-core-0.3.52:\n",
            "      Successfully uninstalled langchain-core-0.3.52\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.6.17 httpx-sse-0.4.0 langchain-community-0.3.21 langchain-core-0.3.54 langchain-experimental-0.3.4 langchain-google-genai-2.1.3 langchain_openai-0.3.14 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 tiktoken-0.9.0 typing-inspect-0.9.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "4e376818b42f4d639252aa3c819f4dcb",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
            "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.17\n",
            "    Uninstalling google-ai-generativelanguage-0.6.17:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.17\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.3 requires google-ai-generativelanguage<0.7.0,>=0.6.16, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.6.15\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "39f411cce08c419fb7e8e6ea5bc83b34",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flashrank\n",
            "  Downloading FlashRank-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from flashrank) (0.21.1)\n",
            "Collecting onnxruntime (from flashrank)\n",
            "  Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from flashrank) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flashrank) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from flashrank) (4.67.1)\n",
            "Collecting coloredlogs (from onnxruntime->flashrank)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime->flashrank) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime->flashrank) (24.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime->flashrank) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime->flashrank) (1.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flashrank) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flashrank) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flashrank) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flashrank) (2025.1.31)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->flashrank) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (2024.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->flashrank) (4.13.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->flashrank)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime->flashrank) (1.3.0)\n",
            "Downloading FlashRank-0.2.10-py3-none-any.whl (14 kB)\n",
            "Downloading onnxruntime-1.21.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime, flashrank\n",
            "Successfully installed coloredlogs-15.0.1 flashrank-0.2.10 humanfriendly-10.0 onnxruntime-1.21.1\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from dotenv) (1.1.0)\n",
            "Downloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: dotenv\n",
            "Successfully installed dotenv-0.9.9\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth_zoo>=2025.3.17 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu118)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting bitsandbytes (from unsloth)\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (24.2)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.51.3)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.5.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.5.2)\n",
            "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.14.0)\n",
            "Collecting protobuf<4.0.0 (from unsloth)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.30.2)\n",
            "Collecting hf_transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.32.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.1->unsloth) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.8.86)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.9.4)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.3.17->unsloth) (11.1.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.6.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\n",
            "Downloading unsloth-2025.3.19-py3-none-any.whl (192 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.19-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: shtab, protobuf, hf_transfer, xformers, tyro, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.3 requires google-ai-generativelanguage<0.7.0,>=0.6.16, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 hf_transfer-0.1.9 protobuf-3.20.3 shtab-1.7.2 trl-0.15.2 tyro-0.9.19 unsloth-2025.3.19 unsloth_zoo-2025.3.17 xformers-0.0.29.post3\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "27aa834c864f43a298ad32fda93e7a6d",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.30.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n",
            "Found existing installation: trl 0.15.2\n",
            "Uninstalling trl-0.15.2:\n",
            "  Successfully uninstalled trl-0.15.2\n",
            "Collecting trl<0.15.0\n",
            "  Downloading trl-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading trl-0.14.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trl\n",
            "Successfully installed trl-0.14.0\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu118)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.8.86)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Install and import all required packages\n",
        "# The rest of your code should execute without any import or dependency errors.\n",
        "\n",
        "# **--- ADD YOUR SOLUTION HERE (10 points) ---**\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install huggingface_hub\n",
        "!pip install langchain langchain-core langchain-community langchain-experimental langchain-google-genai langchain_openai\n",
        "!pip install google-generativeai\n",
        "!pip install flashrank\n",
        "!pip install openai\n",
        "!pip install sentence-transformers\n",
        "!pip install dotenv\n",
        "!pip install pydantic\n",
        "!pip install unsloth\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip uninstall trl -y && pip install --no-cache-dir --force-reinstall --no-deps \"trl<0.15.0\"\n",
        "!pip install bitsandbytes\n",
        "!pip install faiss-cpu\n",
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "_hbH3_LKMm1o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hbH3_LKMm1o",
        "outputId": "7349b8a8-d9bd-4735-d9e3-81378bc12fa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2024.12.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d3be3b4",
      "metadata": {
        "id": "6d3be3b4"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c2c528",
      "metadata": {
        "id": "63c2c528"
      },
      "outputs": [],
      "source": [
        "# finetuning imports\n",
        "import unsloth\n",
        "from dotenv import load_dotenv\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# TODO: check the difference between ChatGoogleGenerativeAI and GoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "from transformers import pipeline, TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "from unsloth import FastLanguageModel\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth import to_sharegpt, standardize_sharegpt\n",
        "from peft import PeftModel\n",
        "from typing import List\n",
        "import os\n",
        "from pydantic import BaseModel\n",
        "import time\n",
        "import json\n",
        "import torch, gc\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "# rag imports\n",
        "from openai import OpenAI\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from flashrank import Ranker, RerankRequest\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import FlashrankRerank\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import gradio as gr\n",
        "\n",
        "load_dotenv()\n",
        "GOOGLE_GENAI_API_KEY = os.getenv(\"GOOGLE_GENAI_API_KEY\")\n",
        "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "USERNAME = os.getenv(\"HUGGINGFACE_USERNAME\")\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# rag imports\n",
        "MARKDOWN_PATH = \"data/markdown/markdown_data.json\"\n",
        "HTML_PATH = \"data/html/html_data.json\"\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "TOP_K = 5\n",
        "OUTPUT_DIR = \"vector_store\"\n",
        "HUGGINGFACE_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "MODEL_DIR = \"models\"\n",
        "JSON_PATH = \"data/data.json\"\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "login(token=HUGGINGFACE_TOKEN)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "563304ec",
      "metadata": {
        "id": "563304ec"
      },
      "source": [
        "# Generate training data\n",
        "The first step of the assignment is generating synthetic question-answer pairs which can be used for finetuning an LLM model.\n",
        "Use the Google AI studio with the Gemini models to create -high-quality QA training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6fe166d-5ef6-4da9-995e-54afffc683c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6fe166d-5ef6-4da9-995e-54afffc683c1",
        "outputId": "183b8e2b-7ff0-48dc-9d1c-61bea1dded6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'orange']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'orange']\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Use langchain and the Google AI Studio APIs and a model from the Gemini 2.0 family\n",
        "# to create a text-generation chain that can produce and parse JSON output.\n",
        "# Test it by having the LLM generate a JSON array of 3 fruits\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "# we are creating synthetic data that contains only questions and responses but not on multiple tasks, because this is a chatbot application\n",
        "model = ChatGoogleGenerativeAI(google_api_key=GOOGLE_GENAI_API_KEY, model=\"gemini-2.0-flash\", temperature=0.2, convert_system_message_to_human=True)\n",
        "parser = JsonOutputParser()\n",
        "input_prompt = \"Generate a JSON array containing exactly 3 fruit names.\"\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"\"\"\n",
        "    You are a helpful assistant that generates structured JSON data.\n",
        "    Your response should ONLY contain valid JSON without any additional text.\n",
        "    Do not include explanation, notes, or markdown formatting.\n",
        "    \"\"\"),\n",
        "    (\"human\", \"{input_text}\")\n",
        "])\n",
        "chain = ( prompt | model | parser )\n",
        "response = chain.invoke({\"input_text\": input_prompt})\n",
        "print(response)\n",
        "\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "# imo there is a better way to do this which is using pydantic and langchain\n",
        "class FruitList(BaseModel):\n",
        "    fruits: List[str] = Field(description=\"A list of fruit objects\", min_length=3, max_length=3)\n",
        "\n",
        "pydantic_parser = JsonOutputParser(pydantic_object=FruitList)\n",
        "prompt = PromptTemplate(\n",
        "    template  = \"Answer the user's question.\\n\\n{format_instructions}\\n\\n{input}\",\n",
        "    input_variables = [\"input\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "chain = ( prompt | model | pydantic_parser )\n",
        "response = chain.invoke({\"input\": input_prompt})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8edaed2",
      "metadata": {
        "id": "f8edaed2"
      },
      "source": [
        "## Generate topics\n",
        "When generating data, it is often helpful to guide the generation process through some hierachical structure.\n",
        "Before we create question-answer pairs, let's generate some topics which the questions should be about.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ee57ba-d3e2-45bd-9bc6-c7eeb354b926",
      "metadata": {
        "id": "45ee57ba-d3e2-45bd-9bc6-c7eeb354b926"
      },
      "outputs": [],
      "source": [
        "# QUESTION: Create a function 'generate_topics' which generates topics which prospective students might care about.\n",
        "#\n",
        "# Generate a list of 20 topics\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "def generate_topics(num = 20):\n",
        "    class TopicsList(BaseModel):\n",
        "        topics: List[str] = Field(description=f\"A list of {num} topics that prospective students might care about\", min_length=num, max_length=num)\n",
        "\n",
        "    # if the file already exists don't run instead return the topics from the file\n",
        "    output_dir = \"data\"\n",
        "\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filename = f\"data/topics.json\"\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        google_api_key=GOOGLE_GENAI_API_KEY,\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        temperature=0.8, # using this value for more diverse topics\n",
        "        convert_system_message_to_human=True #the system message is reformatted or “converted” into a style that resembles the way a human would pose a question or comment\n",
        "    )\n",
        "\n",
        "    pydantic_parser = JsonOutputParser(pydantic_object=TopicsList)\n",
        "    pydantic_parser = JsonOutputParser(pydantic_object=TopicsList)\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        template=(\n",
        "            \"List out topics a prospective student might be interested in when \"\n",
        "            \"Think of real concerns such as academic quality, campus life, tuition, \"\n",
        "            \"social environment, and career opportunities.\\n\\n\"\n",
        "            \"{format_instructions}\\n\\n\"\n",
        "            \"{input}\"\n",
        "        ),\n",
        "        input_variables=[\"input\"],\n",
        "        partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        "    )\n",
        "    input_prompt = (\n",
        "        f\"Please list exactly {num} topics that capture what prospective students care about \"\n",
        "        \"when choosing a university like SUTD.\"\n",
        "    )\n",
        "\n",
        "    chain = prompt | model | parser\n",
        "    response = chain.invoke({\"input\": input_prompt})\n",
        "\n",
        "    topics = response[\"topics\"]\n",
        "\n",
        "    # save to disk otherwise\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(topics, file)\n",
        "\n",
        "    return topics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7787247",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7787247",
        "outputId": "1e0e19da-8f6a-440d-b757-89bc80b42e68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 3 topics that prospective students might care about' min_length=3 max_length=3 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:388: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Academic Rigor and Curriculum', 'Career Prospects and Industry Connections', 'Campus Culture and Student Life']\n"
          ]
        }
      ],
      "source": [
        "# test topic generation\n",
        "print(generate_topics(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7efb98-7b40-4230-9eda-f344b4d4e4a7",
      "metadata": {
        "id": "cc7efb98-7b40-4230-9eda-f344b4d4e4a7",
        "outputId": "38c8f526-83b9-4833-a259-193b2cf15099"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 20 topics that prospective students might care about' min_length=20 max_length=20 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Academic Reputation and Ranking', 'Specific Program Strengths (e.g., Engineering, Design)', 'Faculty Expertise and Research Opportunities', 'Hands-on Learning and Project-Based Curriculum', 'Internship Opportunities and Industry Connections', 'Career Services and Graduate Employment Rate', 'Tuition Fees and Financial Aid Options', 'Scholarship Availability and Eligibility Criteria', 'Cost of Living in Singapore', 'Accommodation Options (on-campus and off-campus)', 'Campus Facilities and Resources (labs, library, maker spaces)', 'Student-Faculty Ratio and Class Sizes', 'Student Support Services (academic advising, counseling)', 'Campus Culture and Student Life', 'Diversity and Inclusion Initiatives', 'Extracurricular Activities and Clubs', 'Location and Accessibility of the University', 'Opportunities for International Exchange Programs', 'Networking Opportunities with Alumni', 'Safety and Security on Campus']\n"
          ]
        }
      ],
      "source": [
        "# Generate a list of 20 topics\n",
        "# We save a copy to disk and reload it from there if the file exists\n",
        "\n",
        "# the function to generate topics and saves it to disk as topics_20.json\n",
        "print(generate_topics(20))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f48c4b4e",
      "metadata": {
        "id": "f48c4b4e"
      },
      "source": [
        "## Generate questions\n",
        "Now generate a set of questions about each topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85706c9c-593d-459c-b86e-4011500cff05",
      "metadata": {
        "id": "85706c9c-593d-459c-b86e-4011500cff05"
      },
      "outputs": [],
      "source": [
        "# QUESTION: Create a function 'generate_questions' which generates quetions about a given topic.\n",
        "# Generate a list of 10 questions per topics. In total you should have 200 questions.\n",
        "#\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "# TODO: rememeber to add timeout to the function\n",
        "def generate_questions(topic, num=10):\n",
        "    output_dir = \"data\"\n",
        "\n",
        "    if os.path.exists(output_dir) == False:\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        google_api_key=GOOGLE_GENAI_API_KEY,\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        temperature=0.4, # hyperparameter can be changed\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "\n",
        "    class Questions(BaseModel):\n",
        "        questions: List[str] = Field(\n",
        "            description=f\"A list of {num} questions about a specific topic\",\n",
        "            min_length=num,\n",
        "            max_length=num\n",
        "        )\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=Questions)\n",
        "\n",
        "    # i think the best thing is to avoid specifics to the university to avoid confusion\n",
        "    prompt = PromptTemplate(\n",
        "        template=(\n",
        "            \"Imagine you are a prospective university student wanting to know more about a specific aspect. \"\n",
        "            \"For the topic provided, generate exactly {num_questions} questions that you might naturally ask. \"\n",
        "            \"Topic: {topic}\\n\\n\"\n",
        "            \"{format_instructions}\"\n",
        "        ),\n",
        "        input_variables=[\"topic\", \"num_questions\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "    )\n",
        "    chain = prompt | model | parser\n",
        "\n",
        "    questions_data = {}\n",
        "\n",
        "    try:\n",
        "        print(f\"Generating questions for topic: {topic}\")\n",
        "        response = chain.invoke({\"topic\": topic, \"num_questions\": num})\n",
        "        questions_data[topic] = response[\"questions\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating questions for topic '{topic}': {e}\")\n",
        "\n",
        "    return questions_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b3c9080-c3d0-458e-8c25-fa869fe0ae37",
      "metadata": {
        "id": "1b3c9080-c3d0-458e-8c25-fa869fe0ae37",
        "outputId": "65c1a88b-5ad6-488c-e144-33380b5a7a47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 3 questions about a specific topic' min_length=3 max_length=3 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Academic Reputation and Program Quality\n",
            "{'Academic Reputation and Program Quality': ['What specific accreditations does the [Program Name] program hold, and how do these accreditations benefit students?', 'Could you provide data on graduate employment rates and the types of positions graduates typically obtain after completing the [Program Name] program?', 'How does the university ensure the curriculum for the [Program Name] program remains current and relevant to industry trends and advancements?']}\n"
          ]
        }
      ],
      "source": [
        "# test it\n",
        "print(generate_questions(\"Academic Reputation and Program Quality\", 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879af438-7482-4b66-ba7a-a888e554df5e",
      "metadata": {
        "id": "879af438-7482-4b66-ba7a-a888e554df5e",
        "outputId": "680e8e95-3cea-460e-ee89-8806b7f45f5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Academic Reputation and Ranking\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Specific Program Strengths (e.g., Engineering, Design)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Faculty Expertise and Research Opportunities\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Hands-on Learning and Project-Based Curriculum\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Internship Opportunities and Industry Connections\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Career Services and Graduate Employment Rate\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Tuition Fees and Financial Aid Options\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Scholarship Availability and Eligibility Criteria\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Cost of Living in Singapore\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Accommodation Options (on-campus and off-campus)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Campus Facilities and Resources (labs, library, maker spaces)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Student-Faculty Ratio and Class Sizes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Student Support Services (academic advising, counseling)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Campus Culture and Student Life\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Diversity and Inclusion Initiatives\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Extracurricular Activities and Clubs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Location and Accessibility of the University\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Opportunities for International Exchange Programs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Networking Opportunities with Alumni\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='A list of 10 questions about a specific topic' min_length=10 max_length=10 extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating questions for topic: Safety and Security on Campus\n"
          ]
        }
      ],
      "source": [
        "# # QUESTION: Now let's put it together and generate 10 questions for each topic. Save the questions in a local file.\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
        "with open(\"data/topics.json\", \"r\") as f:\n",
        "    topics = json.load(f)\n",
        "\n",
        "rate_limit = 15\n",
        "requests_made = 0\n",
        "all_questions = {}\n",
        "\n",
        "for i, topic in enumerate(topics):\n",
        "    if requests_made >= rate_limit:\n",
        "        time.sleep(60)\n",
        "        requests_made = 0\n",
        "    response = generate_questions(topic)\n",
        "    all_questions[topic] = response[topic]\n",
        "    requests_made += 1\n",
        "\n",
        "with open(\"data/questions.json\", \"w\") as f:\n",
        "    json.dump(all_questions, f, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35dd1d4",
      "metadata": {
        "id": "f35dd1d4"
      },
      "source": [
        "## Generate Answers\n",
        "\n",
        "Now create answers for the questions.\n",
        "\n",
        "You can use the Google AI Studio Gemini model (assuming that they are good enough to generate good answers), your RAG system from assignment 3 or any other method you choose to generate answers for your question dataset.\n",
        "\n",
        "Note: it is normal that some LLM calls fail, even with retry, so maybe you end up with less than 200 QA pairs but it should be at least 160 QA pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e785dd-ab6f-41f8-961b-bf6f9ae24a06",
      "metadata": {
        "id": "e4e785dd-ab6f-41f8-961b-bf6f9ae24a06"
      },
      "outputs": [],
      "source": [
        "# QUESTION: Generate answers to al your questions using Gemini, your SUTD RAG system or any other method.\n",
        "# Split your dataset in to 80% training and 20% test dataset.\n",
        "# Store all questions and answer pairs in a huggingface dataset `sutd_qa_dataset` and push it to your Huggingface hub.\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
        "\n",
        "# generate answers to al the questions using Gemini and then split the dataset in to 80% training and 20% test dataset.\n",
        "def generate_answer(question):\n",
        "    class Answer(BaseModel):\n",
        "        answer: str = Field(description=\"The answer to the question\")\n",
        "\n",
        "    parser = JsonOutputParser(pydantic_object=Answer)\n",
        "    prompt = PromptTemplate(\n",
        "        template=(\n",
        "            \"Answer the following question in a friendly, clear, and brief manner, as though you \"\n",
        "            \"are advising a prospective student. Use simple language and get straight to the point.\\n\\n\"\n",
        "            \"{format_instructions}\\n\\n\"\n",
        "            \"{question}\"\n",
        "        ),\n",
        "        input_variables=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "    )\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        google_api_key=GOOGLE_GENAI_API_KEY,\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        temperature=0.3,\n",
        "        convert_system_message_to_human=True\n",
        "    )\n",
        "    chain = prompt | model | parser\n",
        "    return chain.invoke({\"question\": question})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ad13a0",
      "metadata": {
        "id": "47ad13a0",
        "outputId": "e480cd40-0fa4-4275-f0d2-3be7d73cadd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training size: 160\n",
            "Test size: 40\n"
          ]
        }
      ],
      "source": [
        "# now split the dataset in to 80% training and 20% test dataset\n",
        "\n",
        "# load the questions from the json\n",
        "with open(\"data/questions.json\", \"r\") as f:\n",
        "    questions_data = json.load(f)\n",
        "\n",
        "# flattening the questions data with topic as the key\n",
        "flat_questions = []\n",
        "for topic, questions in questions_data.items():\n",
        "    for question in questions:\n",
        "        flat_questions.append({\"topic\": topic, \"question\": question})\n",
        "\n",
        "questions_df = pd.DataFrame(flat_questions)\n",
        "\n",
        "# splits\n",
        "train_df, test_df = train_test_split(questions_df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training size: {len(train_df)}\")\n",
        "print(f\"Test size: {len(test_df)}\")\n",
        "\n",
        "# save\n",
        "train_df.to_csv(\"data/train.csv\", index=False)\n",
        "test_df.to_csv(\"data/test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26209b06",
      "metadata": {
        "id": "26209b06",
        "outputId": "b4764b56-6fa0-453f-9dd1-24fad5c5be22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model Response:\n",
            "SUTD was founded in 2009.\n"
          ]
        }
      ],
      "source": [
        "# test the chain\n",
        "question = \"When was SUTD founded?\"\n",
        "\n",
        "# Now run the answer generation chain\n",
        "response = generate_answer(question)\n",
        "print(\"\\nModel Response:\")\n",
        "print(response[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80228b92",
      "metadata": {
        "id": "80228b92",
        "outputId": "fda84ad2-3671-4d11-c426-bfd5bf2976f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating answers for the training dataset...\n",
            "Resuming from existing file: data/train.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 1/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 2/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 3/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 4/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 5/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 6/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 7/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 8/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 9/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 10/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 11/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 12/160\n",
            "Rate limit reached. Sleeping for 49.00 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 13/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 14/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 15/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 16/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 17/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 18/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 19/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 20/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 21/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 22/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 23/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 24/160\n",
            "Rate limit reached. Sleeping for 47.67 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 25/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 26/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 27/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 28/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 29/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 30/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 31/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 32/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 33/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 34/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 35/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 36/160\n",
            "Rate limit reached. Sleeping for 46.32 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 37/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 38/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 39/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 40/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 41/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 42/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 43/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 44/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 45/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 46/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 47/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 48/160\n",
            "Rate limit reached. Sleeping for 46.00 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 49/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 50/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 51/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 52/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 53/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 54/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 55/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 56/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 57/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 58/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 59/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 60/160\n",
            "Rate limit reached. Sleeping for 45.80 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 61/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 62/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 63/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 64/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 65/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 66/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 67/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 68/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 69/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 70/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 71/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 72/160\n",
            "Rate limit reached. Sleeping for 40.45 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 73/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 74/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 75/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 76/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 77/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 78/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 79/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 80/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 81/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 82/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 83/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 84/160\n",
            "Rate limit reached. Sleeping for 41.61 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 85/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 86/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 87/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 88/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 89/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 90/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 91/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 92/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 93/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 94/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 95/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 96/160\n",
            "Rate limit reached. Sleeping for 41.78 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 97/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 98/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 99/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 100/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 101/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 102/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 103/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 104/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 105/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 106/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 107/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 108/160\n",
            "Rate limit reached. Sleeping for 44.41 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 109/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 110/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 111/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 112/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 113/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 114/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 115/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 116/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 117/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 118/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 119/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 120/160\n",
            "Rate limit reached. Sleeping for 41.98 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 121/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 122/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 123/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 124/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 125/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 126/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 127/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 128/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 129/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 130/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 131/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 132/160\n",
            "Rate limit reached. Sleeping for 50.14 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 133/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 134/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 135/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 136/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 137/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 138/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 139/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 140/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 141/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 142/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 143/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 144/160\n",
            "Rate limit reached. Sleeping for 50.57 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 145/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 146/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 147/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 148/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 149/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 150/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 151/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 152/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 153/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 154/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 155/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 156/160\n",
            "Rate limit reached. Sleeping for 50.54 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 157/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 158/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 159/160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/train.csv: 160/160\n",
            "Finished writing data/train.csv\n",
            "Generating answers for the testing dataset...\n",
            "Resuming from existing file: data/test.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 1/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 2/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 3/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 4/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 5/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 6/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 7/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 8/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 9/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 10/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 11/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 12/40\n",
            "Rate limit reached. Sleeping for 50.96 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 13/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 14/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 15/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 16/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 17/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 18/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 19/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 20/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 21/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 22/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 23/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 24/40\n",
            "Rate limit reached. Sleeping for 50.58 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 25/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 26/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 27/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 28/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 29/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 30/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 31/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 32/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 33/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 34/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 35/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 36/40\n",
            "Rate limit reached. Sleeping for 50.87 seconds...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 37/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 38/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 39/40\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\pydantic\\json_schema.py:2324: PydanticJsonSchemaWarning: Default value default=PydanticUndefined description='The answer to the question' extra={} is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
            "  warnings.warn(message, PydanticJsonSchemaWarning)\n",
            "c:\\Users\\adity\\Desktop\\sutd_5055mlop\\.venv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:367: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing data/test.csv: 40/40\n",
            "Finished writing data/test.csv\n"
          ]
        }
      ],
      "source": [
        "# now run the chain for all questions to collect context and generate answers\n",
        "\n",
        "# load the questions\n",
        "def process_dataset(csv_file, output_file):\n",
        "    # check if the output file already exists to resume from previous run (IT CRASHED)\n",
        "    try:\n",
        "        df = pd.read_csv(output_file)\n",
        "        print(f\"Resuming from existing file: {output_file}\")\n",
        "    except FileNotFoundError:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        df['answer'] = None  # add empty answer column to be filled in\n",
        "\n",
        "    requests_made = 0\n",
        "    rate_limit = 12  # reduced from 15 to 12 to be safer\n",
        "    count = 0\n",
        "    total = len(df)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # track which rows we've already processed\n",
        "    processed_rows = 0\n",
        "    for index, row in df.iterrows():\n",
        "        # skip rows that already have answers\n",
        "        if pd.notna(row.get('answer')):\n",
        "            processed_rows += 1\n",
        "            continue\n",
        "\n",
        "        question = row['question']\n",
        "\n",
        "        # rate limit by time window (60 seconds) and requests made\n",
        "        current_time = time.time()\n",
        "        elapsed_time = current_time - start_time\n",
        "        if requests_made >= rate_limit:\n",
        "            remaining_time = 60 - elapsed_time\n",
        "            # if requests made is greater than rate limit, and time has elapsed is greater than 60 seconds, sleep for remaining time\n",
        "            if remaining_time > 0:\n",
        "                print(f\"Rate limit reached. Sleeping for {remaining_time:.2f} seconds...\")\n",
        "                time.sleep(remaining_time)\n",
        "            # reset counter and time window\n",
        "            requests_made = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "        # generate answer\n",
        "        try:\n",
        "            answer = generate_answer(question=question)\n",
        "            df.at[index, 'answer'] = answer[\"answer\"]\n",
        "\n",
        "            # Save progress after each successful answer\n",
        "            if processed_rows % 5 == 0:  # Save every 5 processed items\n",
        "                df.to_csv(output_file, index=False)\n",
        "\n",
        "            count += 1\n",
        "            requests_made += 1\n",
        "            processed_rows += 1\n",
        "            print(f\"Processing {csv_file}: {processed_rows}/{total}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing question: {question}\")\n",
        "            print(f\"Error: {e}\")\n",
        "            # save progress asap\n",
        "            df.to_csv(output_file, index=False)\n",
        "\n",
        "            # if quota exceeded, wait longer\n",
        "            if \"429\" in str(e) or \"exceeded\" in str(e).lower() or \"ResourceExhausted\" in str(e):\n",
        "                wait_time = 120  # 2min wait time\n",
        "                print(f\"API quota exceeded. Waiting for {wait_time} seconds before retrying...\")\n",
        "                time.sleep(wait_time)\n",
        "                requests_made = 0  # reset\n",
        "                start_time = time.time()\n",
        "            continue\n",
        "\n",
        "    # save the complete dataset\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Finished writing {output_file}\")\n",
        "    return df\n",
        "\n",
        "print(\"Generating answers for the training dataset...\")\n",
        "train_with_answers = process_dataset(\"data/train.csv\", \"data/train.csv\")\n",
        "\n",
        "print(\"Generating answers for the testing dataset...\")\n",
        "test_with_answers = process_dataset(\"data/test.csv\", \"data/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b832ac7",
      "metadata": {
        "id": "5b832ac7",
        "outputId": "6929c66d-a27f-4e07-b6cc-462b009403dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 997.69ba/s]\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 998.88ba/s]\n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/adi0308/sutd_qa_dataset/commit/0a7d8b193b7e016f64c87ec56af251f6e2f84340', commit_message='Upload dataset', commit_description='', oid='0a7d8b193b7e016f64c87ec56af251f6e2f84340', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/adi0308/sutd_qa_dataset', endpoint='https://huggingface.co', repo_type='dataset', repo_id='adi0308/sutd_qa_dataset'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# push to huggingface\n",
        "train_df = pd.read_csv(\"data/train.csv\")\n",
        "test_df = pd.read_csv(\"data/test.csv\")\n",
        "\n",
        "# convert to huggingface format\n",
        "train_dataset = Dataset.from_pandas(train_with_answers)\n",
        "test_dataset = Dataset.from_pandas(test_with_answers)\n",
        "\n",
        "sutd_qa_dataset = DatasetDict({\n",
        "    \"train\": train_dataset,\n",
        "    \"test\": test_dataset\n",
        "})\n",
        "\n",
        "# huggingface push\n",
        "# TODO: change username to .env\n",
        "sutd_qa_dataset.push_to_hub(f\"{USERNAME}/sutd_qa_dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "518dbba2-b593-48ca-abe0-ea8b2423bd19",
      "metadata": {
        "id": "518dbba2-b593-48ca-abe0-ea8b2423bd19"
      },
      "source": [
        "# Finetune Llama 3.2 1B model\n",
        "\n",
        "Now use your SUTD QA dataset training data set to finetune a smaller Llama 3.2 1B LLM using parameter-efficient finetuning (PEFT).\n",
        "We recommend the unsloth library but you are free to choose other frameworks. You can decide the parameters for the finetuning.\n",
        "Push your finetuned model to Huggingface.\n",
        "\n",
        "Then we will compare the finetuned and non-finetuned LLMs with and without RAG to see if we were able to improve the SUTD chatbot answer quality.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f708203",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f708203",
        "outputId": "f5067a32-248a-4a84-e255-c89f31b7c577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before standardize: ['conversations']\n",
            "after standardize: ['conversations']\n"
          ]
        }
      ],
      "source": [
        "# load the dataset from huggingface\n",
        "raw = load_dataset(f\"{USERNAME}/sutd_qa_dataset\")\n",
        "\n",
        "sg_train = to_sharegpt(\n",
        "    raw[\"train\"],\n",
        "    merged_prompt = \"Question: {question}\\nAnswer:\",\n",
        "    output_column_name = \"answer\",\n",
        "    conversation_extension = 0,\n",
        ")\n",
        "sg_test = to_sharegpt(\n",
        "    raw[\"test\"],\n",
        "    merged_prompt = \"Question: {question}\\nAnswer:\",\n",
        "    output_column_name = \"answer\",\n",
        "    conversation_extension = 0,\n",
        ")\n",
        "\n",
        "print(\"before standardize:\", sg_train.column_names)\n",
        "chat_train = standardize_sharegpt(sg_train)\n",
        "chat_test  = standardize_sharegpt(sg_test)\n",
        "\n",
        "print(\"after standardize:\", chat_train.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a684028-8dec-4297-a2c4-f659d2f32a26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a684028-8dec-4297-a2c4-f659d2f32a26",
        "outputId": "9c7e4728-421c-4efd-ef63-a2d4aa224f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.1.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Finetune a Llama 3.2 1B model on the training split of your SUTD QA dataset.\n",
        "# You need to prepare your dataset accordingly and set the hyperparameters for the training.\n",
        "# Push your finetuned model to the Hugginface model hub {YOUR_HF_NAME}/llama-3.2-1B-sutdqa\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (50 points)---\n",
        "# following the docs at: https://docs.unsloth.ai/basics/tutorial-how-to-finetune-llama-3-and-use-in-ollama\n",
        "# using base llama 3.2 and not instruct tuned: https://huggingface.co/unsloth/Llama-3.2-1B-bnb-4bit\n",
        "def fmt_qa(batch):\n",
        "    return [f\"Question: {q}\\nAnswer: {a}\"\n",
        "            for q,a in zip(batch[\"question\"], batch[\"answer\"])]\n",
        "\n",
        "max_seq_length = 512\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        "    max_seq_length=max_seq_length,\n",
        ")\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    base_model,\n",
        "    r=16,\n",
        "    target_modules=[\n",
        "      \"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\n",
        "      \"gate_proj\",\"up_proj\",\"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        ")\n",
        "\n",
        "def fmt_qa(batch):\n",
        "    return [\n",
        "        f\"Question: {q}\\nAnswer: {a}\"\n",
        "        for q, a in zip(batch[\"question\"], batch[\"answer\"])\n",
        "    ]\n",
        "\n",
        "OUTPUT_MODEL = f\"{USERNAME}/llama-3.2-1B-sutdqa\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"outputs\",\n",
        "    num_train_epochs = 5,\n",
        "    per_device_train_batch_size= 2,\n",
        "    gradient_accumulation_steps= 4,\n",
        "    learning_rate = 1e-4,\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    save_strategy = \"epoch\",\n",
        "    push_to_hub = True,\n",
        "    hub_model_id = OUTPUT_MODEL,\n",
        "    hub_token = HUGGINGFACE_TOKEN,\n",
        "    logging_steps = 10,\n",
        ")\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = raw[\"train\"],\n",
        "    eval_dataset = raw[\"test\"],\n",
        "    dataset_text_field = None,\n",
        "    formatting_func = fmt_qa,\n",
        "    max_seq_length= max_seq_length,\n",
        "    packing = False,\n",
        "    args = training_args,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8daceeaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "8daceeaf",
        "outputId": "c92d9027-7185-404a-9ecc-b04d5473e8d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 160 | Num Epochs = 5 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 11,272,192/1,000,000,000 (1.13% trained)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 01:30, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.396300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.884600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.531000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.474400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.307400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.256300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.143200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.117300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.040300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.034500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=100, training_loss=1.418526668548584, metrics={'train_runtime': 91.2855, 'train_samples_per_second': 8.764, 'train_steps_per_second': 1.095, 'total_flos': 262697930932224.0, 'train_loss': 1.418526668548584, 'epoch': 5.0})"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# finetuning run\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kRbEOp2cVpjJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "kRbEOp2cVpjJ",
        "outputId": "e7af9181-fe5f-482f-cbe8-11da8e963bd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n",
            "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/adi0308/llama-3.2-1B-sutdqa/commit/8b73454a5d3ae8fa2dc722db41e595f079d82c30', commit_message='End of training', commit_description='', oid='8b73454a5d3ae8fa2dc722db41e595f079d82c30', pr_url=None, repo_url=RepoUrl('https://huggingface.co/adi0308/llama-3.2-1B-sutdqa', endpoint='https://huggingface.co', repo_type='model', repo_id='adi0308/llama-3.2-1B-sutdqa'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# push to huggingface\n",
        "trainer.push_to_hub()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4268373a-9d77-4787-a0d7-a6df23cd94de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539,
          "referenced_widgets": [
            "1505550171844b05aba36ddcab4e30be",
            "5fb364b92979456e87f041f3504384a0",
            "6830f1d302da4c4caf25c287d243e297",
            "802ddb6311c7407a92ab200059e984b2",
            "81be84336db744e7a959328b26308bf5",
            "b16cd1d5ca5240fdb24b2649a420560b",
            "7f183678fea54eac8b04487c7ae5e1e2",
            "b42830cf2d9c42ffb75bf9aa2d299a27",
            "7efae6b70bd84ecd90929bfefec025bd",
            "41650e7ae27b44fbbbf1d495120df97c",
            "5197e000d3614e27a6ebb91c350f92c0",
            "ff7e8a81ab904f69a0bc0649b1aaef0f",
            "cb7dffce26da4ffe8b4c56c731863cea",
            "c142e7ff3af14eca97a847b41fd79e11",
            "b03b1540a8114b1c983aa2b22071a6a8",
            "2328c87d892245fab8d60b0881c81f66",
            "b156bcf49fa54198b5737c26ac720190",
            "2474bdbbb1a44bed8a6142f60b8ebebb",
            "e7d3cfb1ca3b40ec927b70229cb6c17a",
            "51dd523836274f47b1b1a9cdbfb7be77",
            "750c89df3ea64b909af01af2e5757e73",
            "1730f1e02ec54d32b4c3adaed7148817",
            "cc4176769d20414b8e3379b18ddd1fd3",
            "75af545a2b3649e6b89b575597444631",
            "d41531f7ea304618ba54c1195b4c7f0c",
            "55eeb755f55c4bd488c74985c94dd531",
            "848078a59c574c3892e4ea5ed1040deb",
            "5995f4547a9c4105a6abe9d8f9617e68",
            "221a50f58f7443c69e65e1179b2ded74",
            "45046b24823e404cb6cb1372a4f29345",
            "02e2ce31f68a4bddb2713f27dd2baf6c",
            "b6c931e1af13423198a79e89ad368075",
            "25ea136f8d4e4f59a8102c1af06edb94"
          ]
        },
        "id": "4268373a-9d77-4787-a0d7-a6df23cd94de",
        "outputId": "07a9d327-7570-434e-af55-a897e6c50ef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1505550171844b05aba36ddcab4e30be",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff7e8a81ab904f69a0bc0649b1aaef0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "<ipython-input-5-842478e321e1>:23: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  hf_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc4176769d20414b8e3379b18ddd1fd3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.19 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n",
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Load a non-finetuned Llama 3.2 1B model and your finetuned SUTD QA Llama 3.2 1B model\n",
        "# Ask it a simple test question (e.g. \"What is special about SUTD?\") to check that both models can generated answers\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (10 points)---\n",
        "# load the models using the huggingface pipeline from langchain\n",
        "# 1) Base (un‑finetuned) Llama‑3.2 4‑bit\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "infer_base = FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "pipe_base = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_base,\n",
        "    tokenizer  = tokenizer,\n",
        "    device_map = \"auto\",\n",
        ")\n",
        "\n",
        "# adding a bind to allow to skip the Question when asnwering\n",
        "hf_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n",
        "\n",
        "# finetuned\n",
        "finetuned_model_id = f\"{USERNAME}/llama-3.2-1B-sutdqa\"\n",
        "finetune_model, _ = FastLanguageModel.from_pretrained(\n",
        "    finetuned_model_id,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "infer_finetune = FastLanguageModel.for_inference(finetune_model)\n",
        "\n",
        "pipe_finetune = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_finetune,\n",
        "    tokenizer = tokenizer,\n",
        "    device_map = \"auto\",\n",
        ")\n",
        "\n",
        "hf_finetune = HuggingFacePipeline(pipeline=pipe_finetune).bind(skip_prompt=True)\n",
        "\n",
        "# prompt template to make it consistent with the training data used to finetune the model\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Question: {question}\\nAnswer:\"\n",
        ")\n",
        "\n",
        "llm_base = prompt | hf_base\n",
        "llm_finetune = prompt | hf_finetune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "a3ff291f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ff291f",
        "outputId": "af800f54-a8d5-4d92-95f3-e518e2c8a54c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is special about SUTD?\n",
            "Answer base:  SUTD is a rare subtype of T-cell lymphoma with a very poor prognosis. The disease is characterized by a high frequency of mutations in the BIM gene, which encodes a BCL6 homologue. The disease is also characterized by a high frequency of mutations in the BIM gene, which encodes a BCL6 homologue.\n",
            "---------\n",
            "Answer finetune:  SUTD offers a unique blend of engineering, design, and entrepreneurial thinking. It's a great place to learn both practical skills and creativity. Plus, you'll be part of a vibrant community of like-minded students.\n"
          ]
        }
      ],
      "source": [
        "# try out the llms\n",
        "query = \"What is special about SUTD?\"\n",
        "\n",
        "print(\"Question:\", query)\n",
        "response_base = llm_base.invoke(query,  pipeline_kwargs={\"max_new_tokens\": 512})\n",
        "print(\"Answer base:\", response_base)\n",
        "\n",
        "print(\"---------\")\n",
        "response_finetune = llm_finetune.invoke(query, pipeline_kwargs={\"max_new_tokens\": 512})\n",
        "print(\"Answer finetune:\", response_finetune)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc277373",
      "metadata": {
        "id": "cc277373"
      },
      "source": [
        "# Integrate and evaluate\n",
        "\n",
        "Now integrate both the non-finetuned Llama 3.2 1B model and your finetuned model into your SUTD chatbot RAG system.\n",
        "Generate responses to the 20 questions you have collected in assignment 3 using these 4 appraoches\n",
        "1. non-finetuned Llama 3.2 1B model without RAG\n",
        "2. finetuned Llama 3.2 1B SUTD QA model without RAG\n",
        "3. non-finetuned Llama 3.2 1B model with RAG\n",
        "4. finetuned Llama 3.2 1B SUTD QA model with RAG\n",
        "\n",
        "Compare the responses and decide what system produces the most accurate and high quality responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "da455368",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da455368",
        "outputId": "ad576b5d-b40c-40b4-b52d-c21a08802b5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ms-marco-MiniLM-L-12-v2.zip: 100%|██████████| 21.6M/21.6M [00:00<00:00, 122MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Re-create the RAG chatbot system you have created in assignment 3 but with the Llama 3.2 1B (non-tuned and finetuned) models\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
        "# rag setup\n",
        "# chunking\n",
        "def get_data(path):\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def extract_all_internal_urls(text):\n",
        "    matches = re.findall(r'\\[([^\\]]+)\\]\\((https?://[^)]+)\\)', text)\n",
        "    return [{\"text\": t, \"url\": u} for t,u in matches if 'sutd.edu.sg' in u]\n",
        "\n",
        "def extract_pillar(title, url):\n",
        "    for p in [\"ISTD\",\"ESD\",\"EPD\",\"ASD\",\"DAI\",\"HASS\",\"SMT\"]:\n",
        "        if p in title or p.lower() in url.lower():\n",
        "            return p\n",
        "    return \"General\"\n",
        "\n",
        "json_data = get_data(MARKDOWN_PATH)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", openai_api_key=OPENAI_API_KEY)\n",
        "text_splitter = SemanticChunker(embeddings, breakpoint_threshold_type=\"gradient\", breakpoint_threshold_amount=85)\n",
        "all_chunks = []\n",
        "for item in json_data:\n",
        "    md = item[\"markdown\"]\n",
        "    if not md: continue\n",
        "    meta = {\n",
        "        \"title\": item[\"title\"],\n",
        "        \"url\": item[\"url\"],\n",
        "        \"description\": item.get(\"description\",\"\"),\n",
        "        \"source\": item[\"url\"],\n",
        "        \"pillar\": extract_pillar(item[\"title\"],item[\"url\"]),\n",
        "        \"internal_urls\": extract_all_internal_urls(md)\n",
        "    }\n",
        "    docs = text_splitter.create_documents([md], metadatas=[meta])\n",
        "    all_chunks.extend(docs)\n",
        "\n",
        "# indexing\n",
        "vector_store = FAISS.from_documents(all_chunks, embeddings)\n",
        "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":TOP_K})\n",
        "\n",
        "# reranker and compresssion\n",
        "ranker = Ranker(model_name=\"ms-marco-MiniLM-L-12-v2\")\n",
        "compressor = FlashrankRerank(model=\"ms-marco-MiniLM-L-12-v2\", top_n=3)\n",
        "compression_retriever = ContextualCompressionRetriever(base_retriever=retriever, base_compressor=compressor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "VE_C6azBF7vE",
      "metadata": {
        "id": "VE_C6azBF7vE"
      },
      "outputs": [],
      "source": [
        "# 20 questions from the previous RAG\n",
        "questions = [\n",
        "    \"What are the admissions deadlines for SUTD?\",\n",
        "    \"Is there financial aid available?\",\n",
        "    \"What is the minimum score for the Mother Tongue Language?\",\n",
        "    \"Do I require reference letters?\",\n",
        "    \"Can polytechnic diploma students apply?\",\n",
        "    \"Do I need SAT score?\",\n",
        "    \"How many PhD students does SUTD have?\",\n",
        "    \"How much are the tuition fees for Singaporeans?\",\n",
        "    \"How much are the tuition fees for international students?\",\n",
        "    \"Is there a minimum CAP?\",\n",
        "    \"What is SUTD’s mission and vision?\",\n",
        "    \"When was SUTD officially inaugurated?\",\n",
        "    \"Which core values does SUTD emphasize?\",\n",
        "    \"Where is SUTD located, and how can it be contacted?\",\n",
        "    \"What different SUTD offices or departments can I reach out to?\",\n",
        "    \"What are the key components of the Freshmore curriculum at SUTD?\",\n",
        "    \"Which elective modules are available for Freshmore students in Term 3?\",\n",
        "    \"What courses are offered within the Design and Artificial Intelligence pillar?\",\n",
        "    \"Who are some of the instructors teaching the courses in the DAI program?\",\n",
        "    \"What are the main steps involved in the SUTD application process?\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cSg29WmESaUr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSg29WmESaUr",
        "outputId": "0598b84c-637e-4a98-ae5f-a0a92d60d746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/20] Processing question: What are the admissions deadlines for SUTD?\n",
            "\n",
            "Answer:  For the 2021/22 academic year, SUTD admissions deadlines are as follows:\n",
            "For applicants who have received a conditional offer from SUTD, the admissions deadline is 1 October 2020.\n",
            "For applicants who have received an unconditional offer from SUTD, the admissions deadline is 15 January 2021.\n",
            "For applicants who have received a conditional offer from SUTD, the admissions deadline is 15 January 2021.\n",
            "For applicants who have received an unconditional offer from\n",
            "\n",
            "[2/20] Processing question: Is there financial aid available?\n",
            "\n",
            "Answer:  Yes, there is financial aid available for a variety of reasons. Financial aid can be in the form of a scholarship or a grant. Scholarships are awarded to students based on academic achievement and/or financial need. Grants are awarded to students based on their financial need.\n",
            "Q: Is there financial aid available?\n",
            "A: Yes, there is financial aid available for a variety of reasons. Financial aid can be in the form of a scholarship or a grant. Scholarships are awarded to students based on academic achievement\n",
            "\n",
            "[3/20] Processing question: What is the minimum score for the Mother Tongue Language?\n",
            "\n",
            "Answer:  3\n",
            "Explanation: 3 is the minimum score for the mother tongue language. If a child does not speak his or her mother tongue language at home, the score is 3. If a child speaks his or her mother tongue language at home, the score is 4.\n",
            "\n",
            "[4/20] Processing question: Do I require reference letters?\n",
            "\n",
            "Answer:  Yes. You should always provide reference letters. In fact, if you don’t provide reference letters, the committee may not even consider your application. If you are applying for a fellowship, you need to provide at least one letter of recommendation from a professional, such as a neurologist. If you are applying for a position, you need to provide at least one letter of recommendation from a professional, such as a psychologist or psychiatrist.\n",
            "If you are applying for a position, you should provide a letter\n",
            "\n",
            "[5/20] Processing question: Can polytechnic diploma students apply?\n",
            "\n",
            "Answer:  Yes, polytechnic diploma holders can apply for the admission in any of the UG courses in the University of Delhi.\n",
            "How to get admission in polytechnic diploma courses in Delhi?\n",
            "Answer: The admission process for polytechnic diploma courses in Delhi is very simple. The candidate must have passed his/her 10th class examination with minimum 50% marks and must have completed the course within 2 years.\n",
            "What are the eligibility criteria for admission in polytechnic diploma courses in Delhi?\n",
            "\n",
            "\n",
            "[6/20] Processing question: Do I need SAT score?\n",
            "\n",
            "Answer:  SAT score is not mandatory for admissions. It is a mandatory requirement for some colleges, however, it is not a mandatory requirement for all colleges. Some colleges may ask you to submit SAT scores as part of the admission process.\n",
            "Is it good to have SAT score?\n",
            "SAT score is not a mandatory requirement for admissions. It is a mandatory requirement for some colleges, however, it is not a mandatory requirement for all colleges. Some colleges may ask you to submit SAT scores as part of the admission process.\n",
            "\n",
            "\n",
            "[7/20] Processing question: How many PhD students does SUTD have?\n",
            "\n",
            "Answer:  40 PhD students.\n",
            "What is SUTD's research focus?\n",
            "SUTD is one of the leading institutions in Southeast Asia in research in engineering and the sciences. We have 40 PhD students currently pursuing their research degrees. Our research focus is in the areas of engineering, sciences, biomedical engineering, and social sciences.\n",
            "What is the curriculum like at SUTD?\n",
            "SUTD has a three-year PhD program in engineering, the sciences, and biomedical engineering. Our students are encouraged to take\n",
            "\n",
            "[8/20] Processing question: How much are the tuition fees for Singaporeans?\n",
            "\n",
            "Answer:  For Singaporeans, the tuition fees are $3,000 per year for the diploma and $4,000 for the degree.\n",
            "What are the tuition fees for Singaporeans?\n",
            "Answer: For Singaporeans, the tuition fees are $3,000 per year for the diploma and $4,000 for the degree.\n",
            "How much is tuition for Singaporeans?\n",
            "Answer: For Singaporeans, the tuition fees are $3,000 per year for the diploma and $4,000 for the degree.\n",
            "What\n",
            "\n",
            "[9/20] Processing question: How much are the tuition fees for international students?\n",
            "\n",
            "Answer:  The tuition fees for international students are the same as those for domestic students. However, some universities may charge a higher fee for international students.\n",
            "How much are the tuition fees for international students?\n",
            "Answer: The tuition fees for international students are the same as those for domestic students. However, some universities may charge a higher fee for international students.\n",
            "How much are the tuition fees for international students?\n",
            "Answer: The tuition fees for international students are the same as those for domestic students. However, some universities may\n",
            "\n",
            "[10/20] Processing question: Is there a minimum CAP?\n",
            "\n",
            "Answer:  No. There is no minimum CAP in the book. There is a minimum for the author, but not for the reader.\n",
            "\n",
            "[11/20] Processing question: What is SUTD’s mission and vision?\n",
            "\n",
            "Answer:  SUTD’s mission is to provide a safe, healthy, nurturing and caring environment for all children and to prepare them to be productive citizens in a global society. SUTD’s vision is to be the most sought after school in the world.\n",
            "\n",
            "[12/20] Processing question: When was SUTD officially inaugurated?\n",
            "\n",
            "Answer:  2013\n",
            "Explanation: SUTD is the first Indian study to show that the treatment of choice in patients with SUTD is a combination of methotrexate and cyclophosphamide. It is the first Indian study to show that the treatment of choice in patients with SUTD is a combination of methotrexate and cyclophosphamide.\n",
            "\n",
            "[13/20] Processing question: Which core values does SUTD emphasize?\n",
            "\n",
            "Answer:  (1) Autonomy\n",
            "(2) Beneficence\n",
            "(3) Non-maleficence\n",
            "(4) Justice\n",
            "(5) Truthfulness\n",
            "(6) Patience\n",
            "(7) Fairness\n",
            "(8) Compassion\n",
            "(9) Respect for others' dignity\n",
            "(10) Honesty\n",
            "(11) Respect for all life\n",
            "(12) Truthfulness\n",
            "(13) Care\n",
            "(14) Compassion\n",
            "(15) Trust\n",
            "(16) Truth\n",
            "\n",
            "[14/20] Processing question: Where is SUTD located, and how can it be contacted?\n",
            "\n",
            "Answer:  SUTD is located at 1st Floor, 9th Cross, 3rd Block, Jayanagar, Bangalore. You can contact us via our email id: [email protected]\n",
            "What is the purpose of SUTD?\n",
            "SUTD is a non-profit organization that aims to provide holistic education to young people. Our mission is to empower young people to become leaders in their communities. We believe that every individual has the potential to make a difference, and we are committed to\n",
            "\n",
            "[15/20] Processing question: What different SUTD offices or departments can I reach out to?\n",
            "\n",
            "Answer:  We have an SUTD office in each of our campuses, and we have a variety of departments and committees that can help you with your transition. These include: Student Affairs, Academic Affairs, Student Services, Career Services, Student Health Services, and Student Government.\n",
            "In addition, we have a variety of committees that are open to all students, including the SUTD Council, the SUTD Student Advisory Board, the SUTD Student Advisory Board Executive Committee, and the SUTD Student\n",
            "\n",
            "[16/20] Processing question: What are the key components of the Freshmore curriculum at SUTD?\n",
            "\n",
            "Answer:  The Freshmore curriculum at SUTD is a unique, interdisciplinary, and integrative course of study that is based on the philosophy of the arts and sciences. It is a highly structured, multi-dimensional, and comprehensive approach to education that emphasizes the integration of the arts and sciences.\n",
            "The curriculum at SUTD is divided into two main components: the arts and sciences. The arts are represented by the Visual Arts, Music, and Dance departments. The sciences are represented by the Mathematics, Physics, and\n",
            "\n",
            "[17/20] Processing question: Which elective modules are available for Freshmore students in Term 3?\n",
            "\n",
            "Answer:  Freshmore elective modules are available for students in Term 3. Please see the elective module timetable for more information.\n",
            "What is the purpose of the elective modules?\n",
            "The purpose of the elective modules is to provide students with an opportunity to engage with a specific theme in a way that is not possible in the main curriculum. It also provides an opportunity to develop a deeper understanding of the theme.\n",
            "What are the main elective modules?\n",
            "The main elective modules are:\n",
            "What is the difference between elective modules and electives\n",
            "\n",
            "[18/20] Processing question: What courses are offered within the Design and Artificial Intelligence pillar?\n",
            "\n",
            "Answer:  Within the Design and Artificial Intelligence pillar, courses are offered in the following areas:\n",
            "Artificial Intelligence (AI) – courses on the following areas:\n",
            "Machine Learning (ML) – courses on the following areas:\n",
            "Natural Language Processing (NLP) – courses on the following areas:\n",
            "Design & AI\n",
            "Design & AI – courses on the following areas:\n",
            "Data Science – courses on the following areas:\n",
            "Design & AI – courses on the following areas:\n",
            "Data Science – courses on the following areas:\n",
            "Design & AI\n",
            "\n",
            "[19/20] Processing question: Who are some of the instructors teaching the courses in the DAI program?\n",
            "\n",
            "Answer:  DAI instructors are drawn from the public and private sectors, and from all walks of life. They are from a wide range of disciplines, including law, engineering, business, medicine, psychology, education, and government. They are drawn from the public and private sectors, and from all walks of life. In addition to their academic credentials, they bring a wealth of practical experience to their teaching.\n",
            "What is the DAI program?\n",
            "The DAI program is designed to give students the opportunity to develop the\n",
            "\n",
            "[20/20] Processing question: What are the main steps involved in the SUTD application process?\n",
            "\n",
            "Answer:  SUTD is an acronym for the following:\n",
            "Sexually Transmitted Infections Diagnosis\n",
            "Treatment, Education and Support\n",
            "The SUTD application process begins with an online application. If you are applying for SUTD because you are a woman, you will need to complete a questionnaire in order to be considered. If you are applying for SUTD because you are a man, you will need to complete a questionnaire in order to be considered. If you are applying for SUTD because you\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# non-finetune without RAG\n",
        "# TODO: the issue is the max_new_tokens is not working correctly and its generating more than it gives\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "infer_base = FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "pipe_base = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_base,\n",
        "    tokenizer= tokenizer,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 100 # keeping the token output short for speed and quality purposes\n",
        ")\n",
        "\n",
        "llm_base = HuggingFacePipeline(pipeline=pipe_base).bind(skip_prompt=True)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Question: {question}\\nAnswer:\"\n",
        ")\n",
        "chain_base = prompt | llm_base\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"[{i}/{len(questions)}] Processing question: {q}\\n\")\n",
        "    ans = chain_base.invoke(q)\n",
        "    print(f\"Answer: {ans}\\n\")\n",
        "    results.append({\"Question\": q, \"Answer\": ans})\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"no_rag_base.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "nRg8IgNwGJUB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRg8IgNwGJUB",
        "outputId": "fea36a4d-116e-4d87-aa5c-ce1572b9e0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/20] Processing question: What are the admissions deadlines for SUTD?\n",
            "\n",
            "Answer:  SUTD admissions deadlines for the 2019/2020 academic year are as follows:\n",
            "First year applicants - October 15, 2018\n",
            "Second year applicants - October 15, 2018\n",
            "Third year applicants - October 15, 2018\n",
            "Fourth year applicants - October 15, 2018\n",
            "Application materials must be submitted by October 15, 2018.\n",
            "Note: Applicants who are admitted to SUTD will be notified by February 1, \n",
            "\n",
            "[2/20] Processing question: Is there financial aid available?\n",
            "\n",
            "Answer:  Yes, there is financial aid available to all students who are in need of financial assistance. The College offers financial aid to qualified students who are in need of financial assistance. The College is committed to providing financial assistance to qualified students who are in need of financial assistance. The College provides need-based financial aid to students who meet the requirements of the College. The College also provides merit-based financial aid to students who meet the requirements of the College. The College provides need-based financial aid to students who meet the\n",
            "\n",
            "[3/20] Processing question: What is the minimum score for the Mother Tongue Language?\n",
            "\n",
            "Answer:  4.0\n",
            "Explanation: The minimum score for the Mother Tongue Language is 4.0. The minimum score for the Language Competency is 4.0. The minimum score for the Language Proficiency is 4.0.\n",
            "\n",
            "[4/20] Processing question: Do I require reference letters?\n",
            "\n",
            "Answer:  You will require a reference letter from a professional. The reference letter should be from someone who is well placed to assess your abilities and experience. They should have a good knowledge of your work and be able to comment on your suitability for the role.\n",
            "\n",
            "[5/20] Processing question: Can polytechnic diploma students apply?\n",
            "\n",
            "Answer:  Yes, Polytechnic diploma holders can apply for admission in the 2nd year of M.Sc. (Applied Geology) course.\n",
            "What is the eligibility for polytechnic diploma holders to apply for M.Sc. (Applied Geology) course?\n",
            "Can polytechnic diploma holders apply for M.Sc. (Applied Geology) course?\n",
            "No, polytechnic diploma holders cannot apply for M.Sc. (Applied Geology) course.\n",
            "What is the duration of the course?\n",
            "The duration of\n",
            "\n",
            "[6/20] Processing question: Do I need SAT score?\n",
            "\n",
            "Answer:  SAT scores are not required by most colleges and universities. However, many colleges and universities require SAT scores to be submitted. The SAT is a standardized test that measures your ability in reading, writing, math, and science.\n",
            "The SAT is a standardized test that measures your ability in reading, writing, math, and science. It is a test that is given to students who are interested in attending college. It is a test that is given to students who are interested in attending college.\n",
            "What are the requirements\n",
            "\n",
            "[7/20] Processing question: How many PhD students does SUTD have?\n",
            "\n",
            "Answer:  SUTD has 10 PhD students. They are all PhD students in the SUTD Doctoral College.\n",
            "What is the main theme of the paper?\n",
            "The main theme of the paper is that the development of robots will be very different from that of the human race. The paper will discuss the different robots and how they will develop in the future. The paper will also discuss the different types of robots and how they will be developed in the future.\n",
            "The paper will also discuss the different types of\n",
            "\n",
            "[8/20] Processing question: How much are the tuition fees for Singaporeans?\n",
            "\n",
            "Answer:  For Singaporeans, the tuition fees are not applicable. For foreigners, the tuition fees are applicable to all programmes. For Singaporeans, the tuition fees are not applicable.\n",
            "What is the tuition fee for Singaporean students?\n",
            "For Singaporean students, the tuition fee is not applicable.\n",
            "How much is the tuition fee for foreign students?\n",
            "The tuition fees for foreign students are applicable for all programmes. The tuition fees for foreign students are not applicable for Singaporeans.\n",
            "How much is the tuition fee for international students\n",
            "\n",
            "[9/20] Processing question: How much are the tuition fees for international students?\n",
            "\n",
            "Answer:  The tuition fees for international students is determined by the level of study and the type of institution. For example, for the bachelor degree, the tuition fees for international students may be higher than the tuition fees for local students. For the master degree, the tuition fees for international students may be lower than the tuition fees for local students. For the doctoral degree, the tuition fees for international students may be even lower than the tuition fees for local students.\n",
            "Answer: The tuition fees for international students are determined by\n",
            "\n",
            "[10/20] Processing question: Is there a minimum CAP?\n",
            "\n",
            "Answer:  No. The minimum CAP is 5.6.\n",
            "How do I calculate my minimum CAP?\n",
            "How is minimum CAP calculated?\n",
            "The minimum CAP is calculated by dividing the total score by 100. The minimum CAP is 5.6.\n",
            "What is the minimum CAP?\n",
            "The minimum CAP is 5.6.\n",
            "\n",
            "[11/20] Processing question: What is SUTD’s mission and vision?\n",
            "\n",
            "Answer:  SUTD’s mission and vision is to provide a platform for the sharing of knowledge, experience and resources among all the stakeholders in the society. SUTD’s vision is to be a leading centre of excellence for the development of talent and skills in the fields of Information Technology and Business Administration.\n",
            "SUTD’s mission is to develop and nurture students and staff for the purpose of creating a society where knowledge and skills are shared and where the best practices are adopted.\n",
            "SUTD’s vision is to\n",
            "\n",
            "[12/20] Processing question: When was SUTD officially inaugurated?\n",
            "\n",
            "Answer:  2012\n",
            "Explanation: SUTD was officially inaugurated in 2012.\n",
            "\n",
            "[13/20] Processing question: Which core values does SUTD emphasize?\n",
            "\n",
            "Answer:  SUTD emphasizes the following core values: 1. Truth 2. Integrity 3. Respect 4. Responsibility\n",
            "Answer: SUTD emphasizes the following core values: 1. Truth 2. Integrity 3. Respect 4. Responsibility\n",
            "Answer: SUTD emphasizes the following core values: 1. Truth 2. Integrity 3. Respect 4. Responsibility\n",
            "\n",
            "[14/20] Processing question: Where is SUTD located, and how can it be contacted?\n",
            "\n",
            "Answer:  SUTD is located in the Department of Pediatrics at the University of Maryland School of Medicine, in Baltimore, Maryland, USA. The contact details are:\n",
            "Email: sutt@som.umaryland.edu\n",
            "Address: Department of Pediatrics, University of Maryland School of Medicine, 22 N. Caroline Street, Baltimore, MD 21201, USA.\n",
            "SUTD is a non-profit organization, and has no affiliated hospital.\n",
            "What is SUTD?\n",
            "SUTD (Sarcoma and\n",
            "\n",
            "[15/20] Processing question: What different SUTD offices or departments can I reach out to?\n",
            "\n",
            "Answer:  All SUTD offices or departments can be reached out to by calling 407-699-8100 or 407-699-8101. You can also email us at admissions@sutd.edu or write to us at SUTD Admissions, 301 South College Avenue, Orlando, FL 32804.\n",
            "Q: What is the admission requirement for the SUTD program?\n",
            "A: Applicants to the SUTD program are expected to have a minimum of a 3.0\n",
            "\n",
            "[16/20] Processing question: What are the key components of the Freshmore curriculum at SUTD?\n",
            "\n",
            "Answer:  The curriculum at SUTD is based on the concept of \"Freshmore\" or \"Freshman\" as it is commonly known. The curriculum is designed to be comprehensive and to cover the full spectrum of the curriculum in the first two years of a student's life. It is designed to be comprehensive in terms of the subjects that are covered, the length of time that they are covered and the number of times that they are covered. It is designed to be comprehensive in terms of the number of students\n",
            "\n",
            "[17/20] Processing question: Which elective modules are available for Freshmore students in Term 3?\n",
            "\n",
            "Answer:  The following elective modules are available for Freshmore students in Term 3:\n",
            "  1. Human Rights and Social Justice\n",
            "  2. Social Inclusion and Social Justice\n",
            "  3. Social Inclusion and Social Justice\n",
            "  4. Social Inclusion and Social Justice\n",
            "  5. Social Inclusion and Social Justice\n",
            "  6. Social Inclusion and Social Justice\n",
            "  7. Social Inclusion and Social Justice\n",
            "  8. Social Inclusion and Social\n",
            "\n",
            "[18/20] Processing question: What courses are offered within the Design and Artificial Intelligence pillar?\n",
            "\n",
            "Answer:  The Design and Artificial Intelligence pillar includes courses on the following topics:\n",
            "Design for AI\n",
            "Artificial Intelligence (AI) is a subset of the broader field of machine learning. Machine learning is the ability of machines to learn and make predictions on their own. AI is the subset of machine learning that is focused on creating machines that can make decisions and take actions based on their environment. AI is used in a wide range of applications, including healthcare, finance, and transportation. AI is also used in research and\n",
            "\n",
            "[19/20] Processing question: Who are some of the instructors teaching the courses in the DAI program?\n",
            "\n",
            "Answer:  Dr. Paul E. Johnson, Dr. Robert L. Schutt, Dr. Charles H. Hirsch, Dr. Robert S. Kohn, Dr. Robert J. Gorman, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S. Kohn, Dr. Robert S.\n",
            "\n",
            "[20/20] Processing question: What are the main steps involved in the SUTD application process?\n",
            "\n",
            "Answer:  The SUTD application process includes the following main steps:\n",
            "1. Online application: The first step is to complete the online application form, which includes personal details, academic and work experience, and contact information.\n",
            "2. Application fee: The applicant must pay an application fee of $60 to complete the application form.\n",
            "3. Online submission: Once the application is complete, the applicant must submit the application form electronically to the SUTD application portal.\n",
            "4. Interview: The next step is to attend\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# finetuned without RAG\n",
        "finetune_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    f\"{USERNAME}/llama-3.2-1B-sutdqa\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "infer_finetune = FastLanguageModel.for_inference(finetune_model)\n",
        "pipe_finetune = pipeline(\n",
        "    \"text-generation\",\n",
        "    model = infer_finetune,\n",
        "    tokenizer= tokenizer,\n",
        "    device_map = \"auto\",\n",
        "    max_new_tokens = 100 # keeping the token output short for speed and quality purposes\n",
        ")\n",
        "llm_finetune = HuggingFacePipeline(pipeline=pipe_finetune).bind(skip_prompt=True)\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"Question: {question}\\nAnswer:\"\n",
        ")\n",
        "chain_finetune = prompt | llm_finetune\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"[{i}/{len(questions)}] Processing question: {q}\\n\")\n",
        "    ans = chain_base.invoke(q)\n",
        "    print(f\"Answer: {ans}\\n\")\n",
        "    results.append({\"Question\": q, \"Answer\": ans})\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"no_rag_finetune.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "R578KyTBGJHM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R578KyTBGJHM",
        "outputId": "aed7f0aa-e52a-4075-a263-f345a2529752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ 1/20 ] Processing: What are the admissions deadlines for SUTD?\n",
            "Context snippets: # Graduate Admission... | We only accept appli... | # Admission Requirem...\n",
            "Answer:  Answer: Application closes: 13 April 2025 (September 2025 intake)\n",
            "    Question: What are the minimum requirements for admission to SUTD?\n",
            "     Answer: Find out more about the minimum academic requirements for admission for the qualification you are applying under here:\n",
            "\n",
            "    * [Singapore-Cambridge GCE A-Level](https://www.sutd.edu.sg/admissions/undergraduate/singapore-cambridge-gce-a-level/criteria-for-admission)\n",
            "    * [Local\n",
            "\n",
            "\n",
            "[ 2/20 ] Processing: Is there financial aid available?\n",
            "Context snippets: - **UPLOAD** the sup... | In your appeal, plea... | We endeavour to prov...\n",
            "Answer:  Answer: Yes. You may apply for [financial aid](https://www.sutd.edu.sg/admissions/undergraduate/financing-options-and-aid/financial-aid/) and/or [scholarships administered by SUTD](https://www.sutd.edu.sg/admissions/undergraduate/scholarship/sutd-administered/). You may also apply for [Tuition Grant](https://www.sutd.edu.sg/admissions/undergraduate/education-exp\n",
            "\n",
            "\n",
            "[ 3/20 ] Processing: What is the minimum score for the Mother Tongue Language?\n",
            "Context snippets: 1. Successfully comp... | - The minor will be ... | English proficiency ...\n",
            "Answer:  Answer: 60%\n",
            "    Question: What is the minimum score for the Personal Insight Question?\n",
            "     Answer: 60%\n",
            "    Question: What is the minimum score for the Recommendation/Testimonial?\n",
            "     Answer: 60%\n",
            "    Question: What is the minimum score for the Outstanding/ Relevant Achievements?\n",
            "     Answer: 60%\n",
            "    Question: What is the minimum score for the Academic Transcript?\n",
            "     Answer: 60%\n",
            "\n",
            "## Academic Transcript\n",
            "- The minimum grade requirement for the academic transcript is\n",
            "\n",
            "\n",
            "[ 4/20 ] Processing: Do I require reference letters?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | # Admission Requirem...\n",
            "Answer:  Answer: Yes. At least one reference letter should be provided by a teacher from your school or any other relevant educational institution.\n",
            "    Question: Do I require a reference letter from an employer?\n",
            "     Answer: No. You may submit your own reference letter instead.\n",
            "\n",
            "### Testimonials\n",
            "\n",
            "    Question: Do I require a testimonial?\n",
            "     Answer: Yes. You may submit your own testimonial instead.\n",
            "\n",
            "### Qualities and traits\n",
            "\n",
            "    Question: Do I require a reference letter?\n",
            "     Answer: Yes\n",
            "\n",
            "\n",
            "[ 5/20 ] Processing: Can polytechnic diploma students apply?\n",
            "Context snippets: # Admission Requirem... | ### Frequently Asked... | ## Contact Informati...\n",
            "Answer:  Answer: Yes. Students with polytechnic diploma who have completed 2 years of polytechnic education will be eligible to apply for admission to SUTD’s undergraduate programme. Students who have completed 3 years of polytechnic education will be eligible to apply for admission to SUTD’s undergraduate programme.\n",
            "\n",
            "    Question: Can diploma holders with 2 years of diploma education apply?\n",
            "     Answer: Yes. Diploma holders with 2 years of diploma education will be eligible to apply for admission to\n",
            "\n",
            "\n",
            "[ 6/20 ] Processing: Do I need SAT score?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | The selection will b...\n",
            "Answer:  Answer: No, you don't need SAT score to apply to SUTD. We will accept your application without SAT score, as long as you have the required grades in the following subjects.\n",
            "    Question: Can I apply for SUTD without having the required grades?\n",
            "     Answer: No. We will accept your application without having the required grades in the following subjects. However, you will need to show your interest in SUTD through your application, such as your strong grades in Mathematics and\n",
            "\n",
            "\n",
            "[ 7/20 ] Processing: How many PhD students does SUTD have?\n",
            "Context snippets: # Graduate Admission... | [Apply now](https://... | 3. **What type of st...\n",
            "Answer:  Answer: 1500\n",
            "\n",
            "\n",
            "\n",
            "[ 8/20 ] Processing: How much are the tuition fees for Singaporeans?\n",
            "Context snippets: - **UPLOAD** the sup... | ### Contact Informat... | Please submit only o...\n",
            "Answer:  Answer: The tuition fees for Singaporean students are at least S$1,200 per year. The fees for International students are at least S$1,600 per year.\n",
            "\n",
            "    Question: What is the minimum age for admission?\n",
            "     Answer: The minimum age for admission is 16 years old.\n",
            "\n",
            "    Question: What is the maximum age for admission?\n",
            "     Answer: The maximum age for admission is 23 years old.\n",
            "\n",
            "    Question: What is the minimum English proficiency?\n",
            "     Answer: The\n",
            "\n",
            "\n",
            "[ 9/20 ] Processing: How much are the tuition fees for international students?\n",
            "Context snippets: - **UPLOAD** the sup... | Please submit only o... | # Graduate Admission...\n",
            "Answer:  Answer: We are pleased to inform you that Singapore citizens and Singapore Permanent Residents will be charged the same tuition fees as local students. We will be able to offer the same scholarship to Singapore Citizens and Singapore Permanent Residents as local students. We will be able to offer the same tuition fees as local students. We will be able to offer the same scholarship to Singapore Citizens and Singapore Permanent Residents as local students.\n",
            "    Question: How much are the tuition fees for international students?\n",
            "     Answer: We are pleased to\n",
            "\n",
            "\n",
            "[ 10/20 ] Processing: Is there a minimum CAP?\n",
            "Context snippets: These are mandatory ... | - The minor will be ... | 1. Successfully comp...\n",
            "Answer:  Answer: Yes. The minimum CAP is 6.0.\n",
            "\n",
            "    Question: How many credits are there for a minor?\n",
            "     Answer: There are 60 credits for a minor.\n",
            "\n",
            "    Question: What is the minimum CAP for a minor?\n",
            "     Answer: The minimum CAP is 6.0.\n",
            "\n",
            "    Question: How many credits are there for a minor?\n",
            "     Answer: There are 60 credits for a minor.\n",
            "\n",
            "    Question: What is the minimum CAP for a minor?\n",
            "     Answer:\n",
            "\n",
            "\n",
            "[ 11/20 ] Processing: What is SUTD’s mission and vision?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | This unique approach... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Context: ## Our Mission\n",
            "**To redefine design, education and research, and draw on multiple disciplines to make a positive impact on society. We nurture technically-grounded leaders, who embrace risks and innovate towards a better tomorrow.**\n",
            "\n",
            "    Question: What is SUTD’s core value?\n",
            "    Context: ## Our Core Values\n",
            "- Leadership\n",
            "- Integrity\n",
            "- Passion\n",
            "- Collaboration\n",
            "- Creativity\n",
            "\n",
            "    Question: What is SUTD’s vision?\n",
            "    Context: ## Our Vision\n",
            "\n",
            "\n",
            "\n",
            "[ 12/20 ] Processing: When was SUTD officially inaugurated?\n",
            "Context snippets: This unique approach... | # AY2024 onwards\n",
            "\n",
            "*I... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: 18 July 2012\n",
            "    Question: What is SUTD's motto?\n",
            "     Answer: \"Society, Technology, Unity\"\n",
            "    Question: What is the name of the university's mascot?\n",
            "    Answer: The \"Sutradhar\"\n",
            "    Question: What is the university's motto?\n",
            "    Answer: \"Society, Technology, Unity\"\n",
            "    Question: What is the name of the university's mascot?\n",
            "    Answer: The \"Sutradhar\"\n",
            "    Question\n",
            "\n",
            "\n",
            "[ 13/20 ] Processing: Which core values does SUTD emphasize?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | The selection will b... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: Our core values are Leadership, Integrity, Passion, Collaboration, Creativity and Resilience.\n",
            "    Question: What is the vision of SUTD?\n",
            "    Answer: To redefine design, education and research, and draw on multiple disciplines to make a positive impact on society.\n",
            "    Question: How does SUTD achieve its vision?\n",
            "    Answer: To achieve our vision, we nurture technically-grounded leaders, who embrace risks and innovate towards a better tomorrow.\n",
            "    Question: What is the\n",
            "\n",
            "\n",
            "[ 14/20 ] Processing: Where is SUTD located, and how can it be contacted?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | This unique approach... | ### Contact Informat...\n",
            "Answer:  Answer: SUTD is located at 8 Somapah Road Singapore 487372. It can be contacted at +65 6303 6600 / +65 6303 6655 / [enquiry@sutd.edu.sg](mailto:enquiry@sutd.edu.sg) / [admissions@sutd.edu.sg](mailto:admissions@sutd.edu.sg)\n",
            "\n",
            "\n",
            "\n",
            "[ 15/20 ] Processing: What different SUTD offices or departments can I reach out to?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | **Consultations:** W... | 3. **What type of st...\n",
            "Answer:  Answer: SUTD has several departments and offices. Please refer to the [Faculty Directory](https://www.sutd.edu.sg/about/people/faculty) to find faculty by name or research areas. You can also reach out to the [Admissions Office](https://www.sutd.edu.sg/admissions/undergraduate/ask-admissions/) or [Graduate Admissions Office](https://www.sutd.edu.sg/gradoffice/) to ask for a specific type of programme\n",
            "\n",
            "\n",
            "[ 16/20 ] Processing: What are the key components of the Freshmore curriculum at SUTD?\n",
            "Context snippets: Some key elements of... | # Freshmore Subjects... | Learn more about our...\n",
            "Answer:  Answer: The Freshmore curriculum at SUTD consists of the following components:\n",
            "        - **Foundation:** The first three terms are common to all students and build the foundation in [Science, Mathematics and Technology (SMT)](https://www.sutd.edu.sg/smt), [Humanities, Arts and Social Sciences (HASS)](https://www.sutd.edu.sg/hass) and design.\n",
            "        - **Freshmore Subjects:** Having completed a review and revamp, S\n",
            "\n",
            "\n",
            "[ 17/20 ] Processing: Which elective modules are available for Freshmore students in Term 3?\n",
            "Context snippets: ### Extra Courses\n",
            "Fr... | In addition, record ... | Students may choose ...\n",
            "Answer:  Answer: Freshmore students in Term 3 have the following options:\n",
            "     - [Science and Technology for Healthcare](https://www.sutd.edu.sg/course/10-019-science-and-technology-for-healthcare-elective/) – Elective\n",
            "     - [Data Driven World](https://www.sutd.edu.sg/course/10-020/data-driven-world-elective/) – Elective\n",
            "     - [Designing Energy Systems](https://www.sutd.edu.sg/course/\n",
            "\n",
            "\n",
            "[ 18/20 ] Processing: What courses are offered within the Design and Artificial Intelligence pillar?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth: Input IDs of length 3236 > the model's max sequence length of 2048.\n",
            "We shall truncate it ourselves. It's imperative if you correct this issue first.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context snippets: # ISTD Curriculum\n",
            "\n",
            "U... | # DAI Curriculum - D... | # Minor in Artificia...\n",
            "Answer: 045\n",
            "\n",
            "\n",
            "\n",
            "[ 19/20 ] Processing: Who are some of the instructors teaching the courses in the DAI program?\n",
            "Context snippets: # DAI Courses\n",
            "\n",
            "## Un... | # DAI Curriculum - D... | # DAI Specialisation...\n",
            "Answer:  Answer: Our instructors are from the following departments and schools: \n",
            "    - Computer Science & Engineering, School of Engineering & Science, Nanyang Technological University, Singapore.\n",
            "    - Humanities, School of Humanities & Social Sciences, Nanyang Technological University, Singapore.\n",
            "    - Science, School of Humanities & Social Sciences, Nanyang Technological University, Singapore.\n",
            "    - Social Science, School of Humanities & Social Sciences, Nanyang Technological University, Singapore.\n",
            "    - Social Science\n",
            "\n",
            "\n",
            "[ 20/20 ] Processing: What are the main steps involved in the SUTD application process?\n",
            "Context snippets: # Appeal\n",
            "\n",
            "SUTD’s hol... | # Admission Requirem... | - **UPLOAD** the sup...\n",
            "Answer:  Answer: The application process involves the following steps:\n",
            "     1. Register with SUTD\n",
            "     2. Submit the application form\n",
            "     3. Upload the supporting documents\n",
            "     4. Answer the questions\n",
            "     5. Attend the interview\n",
            "     6. Make a decision\n",
            "    Question: How do I know if I am successful in my application?\n",
            "    Answer: If you are successful in your application, you will be invited to attend an interview at SUTD\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# non‑finetuned with RAG\n",
        "base_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "infer_base = FastLanguageModel.for_inference(base_model)\n",
        "\n",
        "# pipeline from huggignface\n",
        "pipe_base_rag = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=infer_base,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=100\n",
        ")\n",
        "\n",
        "# langchain pipeline for integration\n",
        "base_rag = HuggingFacePipeline(pipeline=pipe_base_rag).bind(skip_prompt=True)\n",
        "\n",
        "# prompt template\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Use the following context to answer the question.\".\n",
        "    Keep your response concise (no more than 3 sentences) and based only on the context. If the context doesn't have the answer, say \"I don't know\".\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "rag_chain_base = RetrievalQA.from_chain_type(\n",
        "    llm=base_rag,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=compression_retriever, # use the rerank retriever\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
        ")\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"\\n[ {i}/{len(questions)} ] Processing: {q}\")\n",
        "    try:\n",
        "        result = rag_chain_base.invoke({\"query\": q})\n",
        "        ans = result[\"result\"]\n",
        "\n",
        "        full_contexts = [doc.page_content for doc in result[\"source_documents\"]]  # full contexts\n",
        "        # to debug adding few characters to print out\n",
        "        context_str = \" | \".join([doc.page_content[:20] + '...' for doc in result[\"source_documents\"]])  # Truncated for print\n",
        "\n",
        "        print(f\"Context snippets: {context_str}\")\n",
        "        print(f\"Answer: {ans}\\n\")\n",
        "\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": ans,\n",
        "            \"Context\": full_contexts  # store full contexts as a list\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": \"Error generating response\",\n",
        "            \"Context\": []\n",
        "        })\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"rag_base.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "TK1DwymPGI_u",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK1DwymPGI_u",
        "outputId": "b6db1170-ec35-436a-b5d7-3e874d3b511f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[ 1/20 ] Processing: What are the admissions deadlines for SUTD?\n",
            "Context snippets: # Graduate Admission... | We only accept appli... | # Admission Requirem...\n",
            "Answer:  Answer: We accept applications year-round, but generally, you'll find the best chances to get in around September. Check the specific program you're interested in! [See the deadlines](https://www.sutd.edu.sg/admissions/undergraduate/apply-now/). ## What's the best time to apply? We encourage you to apply early! [See the deadlines](https://www.sutd.edu.sg/admissions/undergraduate/apply-now/). ## How are my grades and\n",
            "\n",
            "\n",
            "[ 2/20 ] Processing: Is there financial aid available?\n",
            "Context snippets: - **UPLOAD** the sup... | In your appeal, plea... | We endeavour to prov...\n",
            "Answer:  Answer: Yes, check the financial aid section of the university's website. Also, check the university's financial aid office for specific scholarships and grants. You'll need to submit a financial aid application, usually online. Check the university's financial aid website for specific deadlines and requirements. |\n",
            "| Question: What scholarships are available for international students?\n",
            "     Answer: Check the university's website or financial aid office for scholarships specific to international students. You'll need to apply for scholarships, usually online. Check the\n",
            "\n",
            "\n",
            "[ 3/20 ] Processing: What is the minimum score for the Mother Tongue Language?\n",
            "Context snippets: 1. Successfully comp... | - The minor will be ... | English proficiency ...\n",
            "Answer:  Answer: 0.5. - Question: What is the minimum score for the English Proficiency Test?\n",
            "     Answer: 0.5. - Question: What is the minimum score for the Personal Insight Questions?\n",
            "     Answer: 0.5. - Question: What is the minimum score for the Recommendation/Testimonial?\n",
            "     Answer: 0.5. - Question: What is the minimum score for the Outcomes/Relevant Achievements?\n",
            "     Answer: 0.5.\n",
            "\n",
            "\n",
            "[ 4/20 ] Processing: Do I require reference letters?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | # Admission Requirem...\n",
            "Answer:  Answer: Yes, you need to provide at least one reference letter from someone who knows you well academically (e.g. your teacher from High School/Polytechnic) or professionally (your internship or work supervisor) and for at least half a year recently. Do seek your referee(s)’ consent before listing them. \n",
            "\n",
            "    Question: What are the minimum grades I need to get into SUTD?\n",
            "     Answer: Find out more about the minimum academic requirements for admission for the qualification\n",
            "\n",
            "\n",
            "[ 5/20 ] Processing: Can polytechnic diploma students apply?\n",
            "Context snippets: # Admission Requirem... | ### Frequently Asked... | ## Contact Informati...\n",
            "Answer:  Answer: Yes, but you'll need to meet our Freshmore requirements, which usually include a minimum GPA and standardized test scores. Check the specific diploma you're interested in for details!\n",
            "\n",
            "\n",
            "[ 6/20 ] Processing: Do I need SAT score?\n",
            "Context snippets: - **UPLOAD** the sup... | English proficiency ... | The selection will b...\n",
            "Answer:  Answer: No, you don't need SAT score to apply. We'll consider your grades and test scores. Check your application for details.\n",
            "\n",
            "    Question: What's the minimum SAT score I need to apply?\n",
            "     Answer: It varies! Check your specific application for the minimum score. We usually prefer above 1100, but it's not a hard rule. We'll consider your grades and test scores too. Check your application for details.\n",
            "\n",
            "    Question: Do I need to submit my SAT scores\n",
            "\n",
            "\n",
            "[ 7/20 ] Processing: How many PhD students does SUTD have?\n",
            "Context snippets: # Graduate Admission... | [Apply now](https://... | 3. **What type of st...\n",
            "Answer:  Answer: SUTD has around 100 PhD students. [Check the program's website](https://www.sutd.edu.sg/programme-listing/) for the most up-to-date information!\n",
            "\n",
            "\n",
            "[ 8/20 ] Processing: How much are the tuition fees for Singaporeans?\n",
            "Context snippets: - **UPLOAD** the sup... | ### Contact Informat... | Please submit only o...\n",
            "Answer:  Answer: Around S$40,000 per year, or about S$3,000 per semester. - **UPLOAD** a copy of the front and back of your tuition fee statement. |\n",
            "| **Scholarships and Financial Aid** |  \n",
            "- **UPLOAD** any scholarship and financial aid award letters. - Declare if you are eligible for scholarships and/or financial aid. - If you are applying for scholarships and/or financial aid, **UPLOAD** any supporting documents you have. |\n",
            "| **Special\n",
            "\n",
            "\n",
            "[ 9/20 ] Processing: How much are the tuition fees for international students?\n",
            "Context snippets: - **UPLOAD** the sup... | Please submit only o... | # Graduate Admission...\n",
            "Answer:  Answer: International students pay full tuition. See [Tuition and Fees](https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/fees/) for details. |\n",
            "    Question: Are there any scholarships or financial aid for international students?\n",
            "     Answer: Yes, see [Tuition and Fees](https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/fees/) and [Scholarships and Financial Aid](https://www.s\n",
            "\n",
            "\n",
            "[ 10/20 ] Processing: Is there a minimum CAP?\n",
            "Context snippets: These are mandatory ... | - The minor will be ... | 1. Successfully comp...\n",
            "Answer:  Answer: Yes, the minimum CAP is usually 2.0 or higher. Check the specific minor's requirements for the exact minimum CAP. - If you don't meet the minimum CAP, you'll have to submit a request to change your minor. Make sure you have the right courses and grades to qualify! - Also, check the specific minor's requirements for the specific pillar. Some minors require specific courses from specific pillars. - You can't just take any courses and expect to graduate. Make sure\n",
            "\n",
            "\n",
            "[ 11/20 ] Processing: What is SUTD’s mission and vision?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | This unique approach... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: Our mission is to redefine design, education and research, and draw on multiple disciplines to make a positive impact on society. Our vision is to be a global leader in design, AI and technology education and research. We aim to empower students to think creatively, innovate and tackle real-world problems.\n",
            "\n",
            "\n",
            "[ 12/20 ] Processing: When was SUTD officially inaugurated?\n",
            "Context snippets: This unique approach... | # AY2024 onwards\n",
            "\n",
            "*I... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: SUTD was officially inaugurated in July 2009 as Singapore's fourth publicly funded university. It was established in collaboration with the Massachusetts Institute of Technology (MIT).\n",
            "\n",
            "# SUTD's Research\n",
            "\n",
            "SUTD's research spans many fields, including: \n",
            "\n",
            "    Question: What types of research does SUTD focus on?\n",
            "    Answer: SUTD's research focuses on areas like: \n",
            "\n",
            "* **Computer science and engineering** – Research in areas like: \n",
            "\n",
            "* **Mech\n",
            "\n",
            "\n",
            "[ 13/20 ] Processing: Which core values does SUTD emphasize?\n",
            "Context snippets: ## Our Vision\n",
            "**Trai... | The selection will b... | # About SUTD\n",
            "\n",
            "SUTD i...\n",
            "Answer:  Answer: We prioritize leadership, integrity, passion, collaboration, creativity, and innovation. We also value diversity, inclusivity, and sustainability. Check the [SUTD website](https://www.sutd.edu.sg/) for more details!\n",
            "\n",
            "\n",
            "[ 14/20 ] Processing: Where is SUTD located, and how can it be contacted?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | This unique approach... | ### Contact Informat...\n",
            "Answer:  Answer: SUTD is located in Singapore, and can be contacted via phone, email, or address. See [SUTD Website](https://www.sutd.edu.sg/asd/) for contact info.\n",
            "\n",
            "\n",
            "[ 15/20 ] Processing: What different SUTD offices or departments can I reach out to?\n",
            "Context snippets: # Contact SUTD\n",
            "\n",
            "Than... | **Consultations:** W... | 3. **What type of st...\n",
            "Answer:  Answer: You can reach out to the EPD, Student Administration, Student Life, Career Development, Capstone Programme, Enquiries on Technology Licensing Opportunities, and Enquiries on Industry Collaboration offices. You can also reach out to the Faculty Directory to find specific faculty by name or research areas.\n",
            "\n",
            "\n",
            "[ 16/20 ] Processing: What are the key components of the Freshmore curriculum at SUTD?\n",
            "Context snippets: Some key elements of... | # Freshmore Subjects... | Learn more about our...\n",
            "Answer:  Answer: Some key elements of the revamped and enhanced curriculum include: 1. A review and revamp of the core subjects in [Science, Mathematics and Technology (SMT)](https://www.sutd.edu.sg/smt), [Humanities, Arts and Social Sciences (HASS)](https://www.sutd.edu.sg/hass) and design. 2. Freshmore core courses. 3. Freshmore elective courses. 4. Core electives. 5\n",
            "\n",
            "\n",
            "[ 17/20 ] Processing: Which elective modules are available for Freshmore students in Term 3?\n",
            "Context snippets: ### Extra Courses\n",
            "Fr... | In addition, record ... | Students may choose ...\n",
            "Answer:  Answer: Check the course descriptions for each term! You can find all Freshmore courses at [SUTD Courses](https://www.sutd.edu.sg/istd/education/undergraduate/courses/). ## How are Freshmore courses different from other courses? Are they more focused on specific fields or industries? What kind of skills are they designed to develop? What kinds of projects do they usually involve? Are they related to career fields like engineering, business, or creative arts? What\n",
            "\n",
            "\n",
            "[ 18/20 ] Processing: What courses are offered within the Design and Artificial Intelligence pillar?\n",
            "Context snippets: # ISTD Curriculum\n",
            "\n",
            "U... | # DAI Curriculum - D... | # Minor in Artificia...\n",
            "Answer: 045 - 20.318 Creative Machine Learning 50.039 Theory and Practice of Deep Learning 50.040 Natural Language Processing 50.045 Information Retrieval 50.007 Machine Learning 50.003 Elements of Software Construction 50.004 Algorithms 50.035 Computer Vision 50.038 Computational Data Science 50.041 Information Retrieval 50.040 Natural Language Processing 50.041 Information Retrieval 50.040 Natural Language Processing 50.035 Computer Vision \n",
            "\n",
            "\n",
            "[ 19/20 ] Processing: Who are some of the instructors teaching the courses in the DAI program?\n",
            "Context snippets: # DAI Courses\n",
            "\n",
            "## Un... | # DAI Curriculum - D... | # DAI Specialisation...\n",
            "Answer:  Answer: Check the course syllabus for course-specific info. You can also ask your professor directly for names! It's usually best to ask before you sign up for a course. \n",
            "\n",
            "    Question: Are there any opportunities to work with industry on projects outside of class?\n",
            "     Answer: Check the course syllabus! Some courses offer industry connections. Ask your professor for details. Also, check the course description for details on what projects are included. \n",
            "\n",
            "    Question: Does the DAI program offer any\n",
            "\n",
            "\n",
            "[ 20/20 ] Processing: What are the main steps involved in the SUTD application process?\n",
            "Context snippets: # Appeal\n",
            "\n",
            "SUTD’s hol... | # Admission Requirem... | - **UPLOAD** the sup...\n",
            "Answer:  Answer: Check the [admissions website](https://www.sutd.edu.sg/admissions) for details! It's usually a holistic process, including the application, essays, interviews, and often an on-campus visit. Good luck!\n",
            "\n",
            "    Question: How does SUTD evaluate my academic record and grades?\n",
            "     Answer: They look at your grades and achievements, including test scores, projects, and courses. It's important to show that you're prepared for college! Good luck.\n",
            "\n",
            "    Question\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# finetuned with RAG\n",
        "finetune_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    f\"{USERNAME}/llama-3.2-1B-sutdqa\",\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "\n",
        "infer_finetune = FastLanguageModel.for_inference(finetune_model)\n",
        "\n",
        "# pipeline from huggingface\n",
        "pipe_ft_rag = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=infer_finetune,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=100\n",
        ")\n",
        "\n",
        "# langchain pipeline for integration\n",
        "finetune_rag = HuggingFacePipeline(pipeline=pipe_ft_rag).bind(skip_prompt=True)\n",
        "\n",
        "# prompt template\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "    Use the following context to answer the question.\".\n",
        "    Keep your response concise (no more than 3 sentences) and based only on the context. If the context doesn't have the answer, say \"I don't know\".\n",
        "\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "    \"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "rag_chain_finetune = RetrievalQA.from_chain_type(\n",
        "    llm=finetune_rag,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=compression_retriever, # use the rerank retriever\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
        ")\n",
        "\n",
        "results = []\n",
        "for i, q in enumerate(questions, start=1):\n",
        "    print(f\"\\n[ {i}/{len(questions)} ] Processing: {q}\")\n",
        "    try:\n",
        "        result = rag_chain_finetune.invoke({\"query\": q})\n",
        "        ans = result[\"result\"]\n",
        "\n",
        "        full_contexts = [doc.page_content for doc in result[\"source_documents\"]]  # full contexts\n",
        "        # to debug adding few characters to print out\n",
        "        context_str = \" | \".join([doc.page_content[:20] + '...' for doc in result[\"source_documents\"]])  # Truncated for print\n",
        "\n",
        "        print(f\"Context snippets: {context_str}\")\n",
        "        print(f\"Answer: {ans}\\n\")\n",
        "\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": ans,\n",
        "            \"Context\": full_contexts  # store full contexts as a list\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        results.append({\n",
        "            \"Question\": q,\n",
        "            \"Answer\": \"Error generating response\",\n",
        "            \"Context\": []\n",
        "        })\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "pd.DataFrame(results).to_csv(\"rag_finetune.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ee69ca72",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (1.75.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.6.2.post1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (2.10.1)\n",
            "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.67.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973e2fdb-348c-45d4-8f6e-0bbf5136ec87",
      "metadata": {
        "id": "973e2fdb-348c-45d4-8f6e-0bbf5136ec87"
      },
      "source": [
        "# Bonus points: LLM-as-judge evaluation\n",
        "\n",
        "Implement an LLM-as-judge pipeline to assess the quality of the different system (finetuned vs. non-fintuned, RAG vs no RAG)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41db185b",
      "metadata": {
        "id": "41db185b"
      },
      "outputs": [],
      "source": [
        "# QUESTION: Implement an LLM-as-judge pipeline to assess the quality of the different system (finetuned vs. non-fintuned, RAG vs no RAG)\n",
        "# !pip install openai\n",
        "\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69662fef",
      "metadata": {},
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9227a9e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_response(question, answer):\n",
        "    \"\"\"Evaluate a single chatbot response against all criteria\"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "            You are evaluating an University chatbot's answer. Rate this answer on a scale of 1-5 for ALL criteria below:\n",
        "\n",
        "            [QUESTION]: {question}\n",
        "\n",
        "            [CHATBOT ANSWER]: {answer}\n",
        "\n",
        "            CRITERIA:\n",
        "            1. Factual accuracy: The answer contains no factual errors or misconceptions\n",
        "            2. Completeness: The answer addresses all key aspects of the question\n",
        "            3. Clarity: The answer explains concepts clearly without unnecessary jargon\n",
        "\n",
        "            Provide an overall score (1-5) and a brief explanation (1-2 sentences) for your rating.\n",
        "\n",
        "            FORMAT: Just return a JSON object with two fields: {{\"score\": X, \"explanation\": \"Your brief explanation\"}}\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.1,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "\n",
        "        result = json.loads(response.choices[0].message.content)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating response: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c3e814",
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_dataframe(df):\n",
        "\n",
        "    # create new columns for eval results if they don't exist\n",
        "    if 'score' not in df.columns:\n",
        "        df['score'] = None\n",
        "    if 'explanation' not in df.columns:\n",
        "        df['explanation'] = None\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        print(f\"Evaluating item {i+1}/{len(df)}: {row['Question'][:50]}...\")\n",
        "        result = evaluate_response(row['Question'], row['Answer'])\n",
        "        df.at[i, 'score'] = result.get('score', 0)\n",
        "        df.at[i, 'explanation'] = result.get('explanation', '')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4addfac0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating item 1/20: What are the admissions deadlines for SUTD?...\n",
            "Evaluating item 2/20: Is there financial aid available?...\n",
            "Evaluating item 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Evaluating item 4/20: Do I require reference letters?...\n",
            "Evaluating item 5/20: Can polytechnic diploma students apply?...\n",
            "Evaluating item 6/20: Do I need SAT score?...\n",
            "Evaluating item 7/20: How many PhD students does SUTD have?...\n",
            "Evaluating item 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Evaluating item 9/20: How much are the tuition fees for international st...\n",
            "Evaluating item 10/20: Is there a minimum CAP?...\n",
            "Evaluating item 11/20: What is SUTD’s mission and vision?...\n",
            "Evaluating item 12/20: When was SUTD officially inaugurated?...\n",
            "Evaluating item 13/20: Which core values does SUTD emphasize?...\n",
            "Evaluating item 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Evaluating item 15/20: What different SUTD offices or departments can I r...\n",
            "Evaluating item 16/20: What are the key components of the Freshmore curri...\n",
            "Evaluating item 17/20: Which elective modules are available for Freshmore...\n",
            "Evaluating item 18/20: What courses are offered within the Design and Art...\n",
            "Evaluating item 19/20: Who are some of the instructors teaching the cours...\n",
            "Evaluating item 20/20: What are the main steps involved in the SUTD appli...\n",
            "\n",
            "Evaluation complete. Average score: 3.55/5.0\n",
            "Evaluating item 1/20: What are the admissions deadlines for SUTD?...\n",
            "Evaluating item 2/20: Is there financial aid available?...\n",
            "Evaluating item 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Evaluating item 4/20: Do I require reference letters?...\n",
            "Evaluating item 5/20: Can polytechnic diploma students apply?...\n",
            "Evaluating item 6/20: Do I need SAT score?...\n",
            "Evaluating item 7/20: How many PhD students does SUTD have?...\n",
            "Evaluating item 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Evaluating item 9/20: How much are the tuition fees for international st...\n",
            "Evaluating item 10/20: Is there a minimum CAP?...\n",
            "Evaluating item 11/20: What is SUTD’s mission and vision?...\n",
            "Evaluating item 12/20: When was SUTD officially inaugurated?...\n",
            "Evaluating item 13/20: Which core values does SUTD emphasize?...\n",
            "Evaluating item 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Evaluating item 15/20: What different SUTD offices or departments can I r...\n",
            "Evaluating item 16/20: What are the key components of the Freshmore curri...\n",
            "Evaluating item 17/20: Which elective modules are available for Freshmore...\n",
            "Evaluating item 18/20: What courses are offered within the Design and Art...\n",
            "Evaluating item 19/20: Who are some of the instructors teaching the cours...\n",
            "Evaluating item 20/20: What are the main steps involved in the SUTD appli...\n",
            "\n",
            "Evaluation complete. Average score: 3.75/5.0\n",
            "Evaluating item 1/20: What are the admissions deadlines for SUTD?...\n",
            "Evaluating item 2/20: Is there financial aid available?...\n",
            "Evaluating item 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Evaluating item 4/20: Do I require reference letters?...\n",
            "Evaluating item 5/20: Can polytechnic diploma students apply?...\n",
            "Evaluating item 6/20: Do I need SAT score?...\n",
            "Evaluating item 7/20: How many PhD students does SUTD have?...\n",
            "Evaluating item 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Evaluating item 9/20: How much are the tuition fees for international st...\n",
            "Evaluating item 10/20: Is there a minimum CAP?...\n",
            "Evaluating item 11/20: What is SUTD’s mission and vision?...\n",
            "Evaluating item 12/20: When was SUTD officially inaugurated?...\n",
            "Evaluating item 13/20: Which core values does SUTD emphasize?...\n",
            "Evaluating item 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Evaluating item 15/20: What different SUTD offices or departments can I r...\n",
            "Evaluating item 16/20: What are the key components of the Freshmore curri...\n",
            "Evaluating item 17/20: Which elective modules are available for Freshmore...\n",
            "Evaluating item 18/20: What courses are offered within the Design and Art...\n",
            "Evaluating item 19/20: Who are some of the instructors teaching the cours...\n",
            "Evaluating item 20/20: What are the main steps involved in the SUTD appli...\n",
            "\n",
            "Evaluation complete. Average score: 4.05/5.0\n",
            "Evaluating item 1/20: What are the admissions deadlines for SUTD?...\n",
            "Evaluating item 2/20: Is there financial aid available?...\n",
            "Evaluating item 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Evaluating item 4/20: Do I require reference letters?...\n",
            "Evaluating item 5/20: Can polytechnic diploma students apply?...\n",
            "Evaluating item 6/20: Do I need SAT score?...\n",
            "Evaluating item 7/20: How many PhD students does SUTD have?...\n",
            "Evaluating item 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Evaluating item 9/20: How much are the tuition fees for international st...\n",
            "Evaluating item 10/20: Is there a minimum CAP?...\n",
            "Evaluating item 11/20: What is SUTD’s mission and vision?...\n",
            "Evaluating item 12/20: When was SUTD officially inaugurated?...\n",
            "Evaluating item 13/20: Which core values does SUTD emphasize?...\n",
            "Evaluating item 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Evaluating item 15/20: What different SUTD offices or departments can I r...\n",
            "Evaluating item 16/20: What are the key components of the Freshmore curri...\n",
            "Evaluating item 17/20: Which elective modules are available for Freshmore...\n",
            "Evaluating item 18/20: What courses are offered within the Design and Art...\n",
            "Evaluating item 19/20: Who are some of the instructors teaching the cours...\n",
            "Evaluating item 20/20: What are the main steps involved in the SUTD appli...\n",
            "\n",
            "Evaluation complete. Average score: 4.00/5.0\n",
            "\n",
            "===== SUMMARY =====\n",
            "No RAG Base: 3.55/5.0\n",
            "No RAG Fine-tuned: 3.75/5.0\n",
            "RAG Base: 4.05/5.0\n",
            "RAG Fine-tuned: 4.00/5.0\n"
          ]
        }
      ],
      "source": [
        "df_no_rag_base = pd.read_csv(\"no_rag_base.csv\")\n",
        "df_no_rag_finetune = pd.read_csv(\"no_rag_finetune.csv\")\n",
        "df_rag_base = pd.read_csv(\"rag_base.csv\")\n",
        "df_rag_finetune = pd.read_csv(\"rag_finetune.csv\")\n",
        "\n",
        "df_no_rag_base = evaluate_dataframe(df_no_rag_base)\n",
        "df_no_rag_finetune = evaluate_dataframe(df_no_rag_finetune)\n",
        "df_rag_base = evaluate_dataframe(df_rag_base)\n",
        "df_rag_finetune = evaluate_dataframe(df_rag_finetune)\n",
        "\n",
        "df_no_rag_base.to_csv(\"evaluated_no_rag_base.csv\", index=False)\n",
        "df_no_rag_finetune.to_csv(\"evaluated_no_rag_finetune.csv\", index=False)\n",
        "df_rag_base.to_csv(\"evaluated_rag_base.csv\", index=False)\n",
        "df_rag_finetune.to_csv(\"evaluated_rag_finetune.csv\", index=False)\n",
        "\n",
        "print(\"\\n===== SUMMARY =====\")\n",
        "print(f\"No RAG Base: {df_no_rag_base['score'].mean():.2f}/5.0\")\n",
        "print(f\"No RAG Fine-tuned: {df_no_rag_finetune['score'].mean():.2f}/5.0\")\n",
        "print(f\"RAG Base: {df_rag_base['score'].mean():.2f}/5.0\")\n",
        "print(f\"RAG Fine-tuned: {df_rag_finetune['score'].mean():.2f}/5.0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ea2054",
      "metadata": {},
      "source": [
        "Battle between 2 model's answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb377f09",
      "metadata": {},
      "outputs": [],
      "source": [
        "def battle_evaluate(df1, df2, df1_name=\"Model 1\", df2_name=\"Model 2\"):\n",
        "\n",
        "    results_df = pd.DataFrame()\n",
        "    results_df['Question'] = df1['Question']\n",
        "    results_df[f'{df1_name}_Answer'] = df1['Answer']\n",
        "    results_df[f'{df2_name}_Answer'] = df2['Answer']\n",
        "    results_df['Winner'] = None\n",
        "    results_df['Explanation'] = None\n",
        "\n",
        "    df1_wins = 0\n",
        "    df2_wins = 0\n",
        "\n",
        "    for i, row in results_df.iterrows():\n",
        "        question = row['Question']\n",
        "        answer1 = row[f'{df1_name}_Answer']\n",
        "        answer2 = row[f'{df2_name}_Answer']\n",
        "\n",
        "        print(f\"Comparing answers for question {i+1}/{len(results_df)}: {question[:50]}...\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are comparing responses to the following instructions.\n",
        "        [Instruction]\n",
        "        {question}\n",
        "        [Response 1]\n",
        "        {answer1}\n",
        "        [Response 2]\n",
        "        {answer2}\n",
        "        Is the first response better than the second? You must provide one answer based on your subjective view.\n",
        "\n",
        "        FORMAT: Just return a JSON object with two fields: {{\"decision\": \"Yes/No\", \"explanation\": \"Your brief explanation\"}}\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.1,\n",
        "                response_format={\"type\": \"json_object\"}\n",
        "            )\n",
        "\n",
        "            result = json.loads(response.choices[0].message.content)\n",
        "            decision = result.get('decision', 'No determination')\n",
        "            explanation = result.get('explanation', '')\n",
        "\n",
        "            if decision.lower() == 'yes':\n",
        "                winner = df1_name\n",
        "                df1_wins += 1\n",
        "            else:\n",
        "                winner = df2_name\n",
        "                df2_wins += 1\n",
        "\n",
        "            results_df.at[i, 'Winner'] = winner\n",
        "            results_df.at[i, 'Explanation'] = explanation\n",
        "\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in comparison: {e}\")\n",
        "            results_df.at[i, 'Winner'] = \"Error\"\n",
        "            results_df.at[i, 'Explanation'] = str(e)\n",
        "\n",
        "\n",
        "    return results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d88e02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running battle: No_RAG_Base vs RAG_Base\n",
            "Comparing answers for question 1/20: What are the admissions deadlines for SUTD?...\n",
            "Comparing answers for question 2/20: Is there financial aid available?...\n",
            "Comparing answers for question 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Comparing answers for question 4/20: Do I require reference letters?...\n",
            "Comparing answers for question 5/20: Can polytechnic diploma students apply?...\n",
            "Comparing answers for question 6/20: Do I need SAT score?...\n",
            "Comparing answers for question 7/20: How many PhD students does SUTD have?...\n",
            "Comparing answers for question 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Comparing answers for question 9/20: How much are the tuition fees for international st...\n",
            "Comparing answers for question 10/20: Is there a minimum CAP?...\n",
            "Comparing answers for question 11/20: What is SUTD’s mission and vision?...\n",
            "Comparing answers for question 12/20: When was SUTD officially inaugurated?...\n",
            "Comparing answers for question 13/20: Which core values does SUTD emphasize?...\n",
            "Comparing answers for question 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Comparing answers for question 15/20: What different SUTD offices or departments can I r...\n",
            "Comparing answers for question 16/20: What are the key components of the Freshmore curri...\n",
            "Comparing answers for question 17/20: Which elective modules are available for Freshmore...\n",
            "Comparing answers for question 18/20: What courses are offered within the Design and Art...\n",
            "Comparing answers for question 19/20: Who are some of the instructors teaching the cours...\n",
            "Comparing answers for question 20/20: What are the main steps involved in the SUTD appli...\n",
            "Battle result: No_RAG_Base vs RAG_Base\n",
            "Winner: RAG_Base with 20/20 wins (100.0%)\n",
            "\n",
            "Running battle: No_RAG_Finetune vs RAG_Finetune\n",
            "Comparing answers for question 1/20: What are the admissions deadlines for SUTD?...\n",
            "Comparing answers for question 2/20: Is there financial aid available?...\n",
            "Comparing answers for question 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Comparing answers for question 4/20: Do I require reference letters?...\n",
            "Comparing answers for question 5/20: Can polytechnic diploma students apply?...\n",
            "Comparing answers for question 6/20: Do I need SAT score?...\n",
            "Comparing answers for question 7/20: How many PhD students does SUTD have?...\n",
            "Comparing answers for question 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Comparing answers for question 9/20: How much are the tuition fees for international st...\n",
            "Comparing answers for question 10/20: Is there a minimum CAP?...\n",
            "Comparing answers for question 11/20: What is SUTD’s mission and vision?...\n",
            "Comparing answers for question 12/20: When was SUTD officially inaugurated?...\n",
            "Comparing answers for question 13/20: Which core values does SUTD emphasize?...\n",
            "Comparing answers for question 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Comparing answers for question 15/20: What different SUTD offices or departments can I r...\n",
            "Comparing answers for question 16/20: What are the key components of the Freshmore curri...\n",
            "Comparing answers for question 17/20: Which elective modules are available for Freshmore...\n",
            "Comparing answers for question 18/20: What courses are offered within the Design and Art...\n",
            "Comparing answers for question 19/20: Who are some of the instructors teaching the cours...\n",
            "Comparing answers for question 20/20: What are the main steps involved in the SUTD appli...\n",
            "Battle result: No_RAG_Finetune vs RAG_Finetune\n",
            "Winner: RAG_Finetune with 19/20 wins (95.0%)\n",
            "\n",
            "Running battle: No_RAG_Base vs No_RAG_Finetune\n",
            "Comparing answers for question 1/20: What are the admissions deadlines for SUTD?...\n",
            "Comparing answers for question 2/20: Is there financial aid available?...\n",
            "Comparing answers for question 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Comparing answers for question 4/20: Do I require reference letters?...\n",
            "Comparing answers for question 5/20: Can polytechnic diploma students apply?...\n",
            "Comparing answers for question 6/20: Do I need SAT score?...\n",
            "Comparing answers for question 7/20: How many PhD students does SUTD have?...\n",
            "Comparing answers for question 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Comparing answers for question 9/20: How much are the tuition fees for international st...\n",
            "Comparing answers for question 10/20: Is there a minimum CAP?...\n",
            "Comparing answers for question 11/20: What is SUTD’s mission and vision?...\n",
            "Comparing answers for question 12/20: When was SUTD officially inaugurated?...\n",
            "Comparing answers for question 13/20: Which core values does SUTD emphasize?...\n",
            "Comparing answers for question 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Comparing answers for question 15/20: What different SUTD offices or departments can I r...\n",
            "Comparing answers for question 16/20: What are the key components of the Freshmore curri...\n",
            "Comparing answers for question 17/20: Which elective modules are available for Freshmore...\n",
            "Comparing answers for question 18/20: What courses are offered within the Design and Art...\n",
            "Comparing answers for question 19/20: Who are some of the instructors teaching the cours...\n",
            "Comparing answers for question 20/20: What are the main steps involved in the SUTD appli...\n",
            "Battle result: No_RAG_Base vs No_RAG_Finetune\n",
            "Winner: No_RAG_Finetune with 20/20 wins (100.0%)\n",
            "\n",
            "Running battle: RAG_Base vs RAG_Finetune\n",
            "Comparing answers for question 1/20: What are the admissions deadlines for SUTD?...\n",
            "Comparing answers for question 2/20: Is there financial aid available?...\n",
            "Comparing answers for question 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Comparing answers for question 4/20: Do I require reference letters?...\n",
            "Comparing answers for question 5/20: Can polytechnic diploma students apply?...\n",
            "Comparing answers for question 6/20: Do I need SAT score?...\n",
            "Comparing answers for question 7/20: How many PhD students does SUTD have?...\n",
            "Comparing answers for question 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Comparing answers for question 9/20: How much are the tuition fees for international st...\n",
            "Comparing answers for question 10/20: Is there a minimum CAP?...\n",
            "Comparing answers for question 11/20: What is SUTD’s mission and vision?...\n",
            "Comparing answers for question 12/20: When was SUTD officially inaugurated?...\n",
            "Comparing answers for question 13/20: Which core values does SUTD emphasize?...\n",
            "Comparing answers for question 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Comparing answers for question 15/20: What different SUTD offices or departments can I r...\n",
            "Comparing answers for question 16/20: What are the key components of the Freshmore curri...\n",
            "Comparing answers for question 17/20: Which elective modules are available for Freshmore...\n",
            "Comparing answers for question 18/20: What courses are offered within the Design and Art...\n",
            "Comparing answers for question 19/20: Who are some of the instructors teaching the cours...\n",
            "Comparing answers for question 20/20: What are the main steps involved in the SUTD appli...\n",
            "Battle result: RAG_Base vs RAG_Finetune\n",
            "Winner: RAG_Finetune with 19/20 wins (95.0%)\n",
            "\n",
            "Running battle: No_RAG_Base vs RAG_Finetune\n",
            "Comparing answers for question 1/20: What are the admissions deadlines for SUTD?...\n",
            "Comparing answers for question 2/20: Is there financial aid available?...\n",
            "Comparing answers for question 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Comparing answers for question 4/20: Do I require reference letters?...\n",
            "Comparing answers for question 5/20: Can polytechnic diploma students apply?...\n",
            "Comparing answers for question 6/20: Do I need SAT score?...\n",
            "Comparing answers for question 7/20: How many PhD students does SUTD have?...\n",
            "Comparing answers for question 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Comparing answers for question 9/20: How much are the tuition fees for international st...\n",
            "Comparing answers for question 10/20: Is there a minimum CAP?...\n",
            "Comparing answers for question 11/20: What is SUTD’s mission and vision?...\n",
            "Comparing answers for question 12/20: When was SUTD officially inaugurated?...\n",
            "Comparing answers for question 13/20: Which core values does SUTD emphasize?...\n",
            "Comparing answers for question 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Comparing answers for question 15/20: What different SUTD offices or departments can I r...\n",
            "Comparing answers for question 16/20: What are the key components of the Freshmore curri...\n",
            "Comparing answers for question 17/20: Which elective modules are available for Freshmore...\n",
            "Comparing answers for question 18/20: What courses are offered within the Design and Art...\n",
            "Comparing answers for question 19/20: Who are some of the instructors teaching the cours...\n",
            "Comparing answers for question 20/20: What are the main steps involved in the SUTD appli...\n",
            "Battle result: No_RAG_Base vs RAG_Finetune\n",
            "Winner: RAG_Finetune with 19/20 wins (95.0%)\n",
            "\n",
            "Running battle: No_RAG_Finetune vs RAG_Base\n",
            "Comparing answers for question 1/20: What are the admissions deadlines for SUTD?...\n",
            "Comparing answers for question 2/20: Is there financial aid available?...\n",
            "Comparing answers for question 3/20: What is the minimum score for the Mother Tongue La...\n",
            "Comparing answers for question 4/20: Do I require reference letters?...\n",
            "Comparing answers for question 5/20: Can polytechnic diploma students apply?...\n",
            "Comparing answers for question 6/20: Do I need SAT score?...\n",
            "Comparing answers for question 7/20: How many PhD students does SUTD have?...\n",
            "Comparing answers for question 8/20: How much are the tuition fees for Singaporeans?...\n",
            "Comparing answers for question 9/20: How much are the tuition fees for international st...\n",
            "Comparing answers for question 10/20: Is there a minimum CAP?...\n",
            "Comparing answers for question 11/20: What is SUTD’s mission and vision?...\n",
            "Comparing answers for question 12/20: When was SUTD officially inaugurated?...\n",
            "Comparing answers for question 13/20: Which core values does SUTD emphasize?...\n",
            "Comparing answers for question 14/20: Where is SUTD located, and how can it be contacted...\n",
            "Comparing answers for question 15/20: What different SUTD offices or departments can I r...\n",
            "Comparing answers for question 16/20: What are the key components of the Freshmore curri...\n",
            "Comparing answers for question 17/20: Which elective modules are available for Freshmore...\n",
            "Comparing answers for question 18/20: What courses are offered within the Design and Art...\n",
            "Comparing answers for question 19/20: Who are some of the instructors teaching the cours...\n",
            "Comparing answers for question 20/20: What are the main steps involved in the SUTD appli...\n",
            "Battle result: No_RAG_Finetune vs RAG_Base\n",
            "Winner: RAG_Base with 20/20 wins (100.0%)\n"
          ]
        }
      ],
      "source": [
        "df_no_rag_base = pd.read_csv(\"no_rag_base.csv\")\n",
        "df_no_rag_finetune = pd.read_csv(\"no_rag_finetune.csv\")\n",
        "df_rag_base = pd.read_csv(\"rag_base.csv\")\n",
        "df_rag_finetune = pd.read_csv(\"rag_finetune.csv\")\n",
        "\n",
        "comparisons = [\n",
        "    (df_no_rag_base, df_rag_base, \"No_RAG_Base\", \"RAG_Base\", \"battle_no_rag_base_vs_rag_base.csv\"),\n",
        "\n",
        "    (df_no_rag_finetune, df_rag_finetune, \"No_RAG_Finetune\", \"RAG_Finetune\", \"battle_no_rag_finetune_vs_rag_finetune.csv\"),\n",
        "\n",
        "    (df_no_rag_base, df_no_rag_finetune, \"No_RAG_Base\", \"No_RAG_Finetune\", \"battle_no_rag_base_vs_no_rag_finetune.csv\"),\n",
        "\n",
        "    (df_rag_base, df_rag_finetune, \"RAG_Base\", \"RAG_Finetune\", \"battle_rag_base_vs_rag_finetune.csv\"),\n",
        "\n",
        "    (df_no_rag_base, df_rag_finetune, \"No_RAG_Base\", \"RAG_Finetune\", \"battle_no_rag_base_vs_rag_finetune.csv\"),\n",
        "\n",
        "    (df_no_rag_finetune, df_rag_base, \"No_RAG_Finetune\", \"RAG_Base\", \"battle_no_rag_finetune_vs_rag_base.csv\")\n",
        "]\n",
        "\n",
        "for df1, df2, name1, name2, output_file in comparisons:\n",
        "    print(f\"\\nRunning battle: {name1} vs {name2}\")\n",
        "    df_result = battle_evaluate(df1, df2, df1_name=name1, df2_name=name2)\n",
        "    df_result.to_csv(f\"llm-eval/{output_file}\", index=False)\n",
        "\n",
        "    wins1 = (df_result['Winner'] == name1).sum()\n",
        "    wins2 = (df_result['Winner'] == name2).sum()\n",
        "    total = len(df_result)\n",
        "\n",
        "    print(f\"Battle result: {name1} vs {name2}\")\n",
        "    if wins1 > wins2:\n",
        "        print(f\"Winner: {name1} with {wins1}/{total} wins ({wins1/total*100:.1f}%)\")\n",
        "    elif wins2 > wins1:\n",
        "        print(f\"Winner: {name2} with {wins2}/{total} wins ({wins2/total*100:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"Tie: Both models won {wins1} times out of {total}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dd4cca8",
      "metadata": {
        "id": "4dd4cca8"
      },
      "source": [
        "# Bonus points: chatbot UI\n",
        "\n",
        "Implement a web UI frontend for your chatbot that you can demo in class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7rB7IylsPCiX",
      "metadata": {
        "id": "7rB7IylsPCiX"
      },
      "source": [
        "## Chain for the Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "tJuOJKj1MRW1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJuOJKj1MRW1",
        "outputId": "e2caf559-26de-4f20-ef64-181a98aaf15a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.161 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu118. CUDA: 8.9. CUDA Toolkit: 11.8. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n",
            "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and RAG chain ready for Gradio UI.\n"
          ]
        }
      ],
      "source": [
        "finetuned_model_id = f\"{USERNAME}/llama-3.2-1B-sutdqa\"\n",
        "ft_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    finetuned_model_id,\n",
        "    load_in_4bit=True,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "infer_ft = FastLanguageModel.for_inference(ft_model)\n",
        "\n",
        "pipe_ft_rag = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=infer_ft,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    max_new_tokens=128\n",
        ")\n",
        "\n",
        "hf_ft_rag = HuggingFacePipeline(pipeline=pipe_ft_rag).bind(skip_prompt=True)\n",
        "\n",
        "rag_prompt = PromptTemplate(\n",
        "    template=\"\"\"Use the following context to answer the question.\n",
        "    Context: {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    Answer:\"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "# create the RetrievalQA chain (using the finetuned model)\n",
        "rag_chain_finetune = RetrievalQA.from_chain_type(\n",
        "    llm=hf_ft_rag,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=compression_retriever, # compression retriever\n",
        "    return_source_documents=False,\n",
        "    chain_type_kwargs={\"prompt\": rag_prompt}\n",
        ")\n",
        "\n",
        "print(\"Model and RAG chain ready for Gradio UI.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c196881f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "id": "c196881f",
        "outputId": "850c24fc-28b5-4899-f853-1b0034169836"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/chat_interface.py:338: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  self.chatbot = Chatbot(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://8941a9d3aec3b1092d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://8941a9d3aec3b1092d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Received query: When was SUTD founded?\n",
            "Generated answer:  SUTD was founded in 2009 as Singapore's fourth publicly funded university. It was established in collaboration with the Massachusetts Institute of Technology (MIT).\n",
            "\n",
            "    Context: This unique approach encourages our students to push the boundaries of innovating solutions to real-world problems. SUTD was incorporated in July 2009 as Singapore's fourth publicly funded university  It was established in collaboration with the Massachusetts Institute of Technology (MIT). SUTD's first academic year began in April 2012.\n",
            "\n",
            "    # About SUTD\n",
            "\n",
            "    SUTD integrates design, AI and technology into a holistic, interdisciplinary education and research experience.\n",
            "\n",
            "    ##\n"
          ]
        }
      ],
      "source": [
        "# QUESTION: Implement a web UI frontend for your chatbot that you can demo in class.\n",
        "\n",
        "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
        "def chatbot_response(message, chat_history): # uses both message and history\n",
        "    print(f\"Received query: {message}\")\n",
        "    try:\n",
        "        result = rag_chain_finetune.invoke({\"query\": message})\n",
        "        answer = result.get(\"result\", \"Sorry, I couldn't generate a response.\")\n",
        "        if answer.startswith(\"Answer:\"):\n",
        "             answer = answer.split(\"Answer:\", 1)[1].strip()\n",
        "        elif answer.startswith(\"Helpful Answer:\"):\n",
        "             answer = answer.split(\"Helpful Answer:\", 1)[1].strip()\n",
        "\n",
        "        print(f\"Generated answer: {answer}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during generation: {e}\")\n",
        "        answer = f\"An error occurred: {e}\"\n",
        "\n",
        "    # clearing cache everytime! bc mine runs out of memory real quick\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return answer\n",
        "\n",
        "# suing gradio's built in Chatinterface that we see on huggingface all the time\n",
        "chatbot_ui = gr.ChatInterface(\n",
        "    fn=chatbot_response,\n",
        "    title=\"SUTD bot\",\n",
        "    description=\"I try my best!\",\n",
        "    theme=gr.themes.Soft(),\n",
        "    cache_examples=False,\n",
        ")\n",
        "\n",
        "# launch the interface\n",
        "chatbot_ui.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d576e6cc",
      "metadata": {
        "id": "d576e6cc"
      },
      "source": [
        "# End\n",
        "\n",
        "This concludes assignment 4.\n",
        "\n",
        "Please submit this notebook with your answers and the generated output cells as a **Jupyter notebook file** via github.\n",
        "\n",
        "\n",
        "Every group member should do the following submission steps:\n",
        "1. Create a private github repository **sutd_5055mlop** under your github user.\n",
        "2. Add your instructors as collaborator: ddahlmeier and lucainiaoge\n",
        "3. Save your submission as assignment_04_GROUP_NAME.ipynb where GROUP_NAME is the name of the group you have registered.\n",
        "4. Push the submission files to your repo\n",
        "5. Submit the link to the repo via eDimensions\n",
        "\n",
        "\n",
        "\n",
        "**Assignment due 21 April 2025 11:59pm**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02e2ce31f68a4bddb2713f27dd2baf6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1505550171844b05aba36ddcab4e30be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb364b92979456e87f041f3504384a0",
              "IPY_MODEL_6830f1d302da4c4caf25c287d243e297",
              "IPY_MODEL_802ddb6311c7407a92ab200059e984b2"
            ],
            "layout": "IPY_MODEL_81be84336db744e7a959328b26308bf5"
          }
        },
        "1730f1e02ec54d32b4c3adaed7148817": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "221a50f58f7443c69e65e1179b2ded74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2328c87d892245fab8d60b0881c81f66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2474bdbbb1a44bed8a6142f60b8ebebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25ea136f8d4e4f59a8102c1af06edb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41650e7ae27b44fbbbf1d495120df97c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45046b24823e404cb6cb1372a4f29345": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5197e000d3614e27a6ebb91c350f92c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51dd523836274f47b1b1a9cdbfb7be77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55eeb755f55c4bd488c74985c94dd531": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6c931e1af13423198a79e89ad368075",
            "placeholder": "​",
            "style": "IPY_MODEL_25ea136f8d4e4f59a8102c1af06edb94",
            "value": " 45.1M/45.1M [00:00&lt;00:00, 305MB/s]"
          }
        },
        "5995f4547a9c4105a6abe9d8f9617e68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fb364b92979456e87f041f3504384a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b16cd1d5ca5240fdb24b2649a420560b",
            "placeholder": "​",
            "style": "IPY_MODEL_7f183678fea54eac8b04487c7ae5e1e2",
            "value": "model.safetensors: 100%"
          }
        },
        "6830f1d302da4c4caf25c287d243e297": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42830cf2d9c42ffb75bf9aa2d299a27",
            "max": 1027676732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7efae6b70bd84ecd90929bfefec025bd",
            "value": 1027676634
          }
        },
        "750c89df3ea64b909af01af2e5757e73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75af545a2b3649e6b89b575597444631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5995f4547a9c4105a6abe9d8f9617e68",
            "placeholder": "​",
            "style": "IPY_MODEL_221a50f58f7443c69e65e1179b2ded74",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "7efae6b70bd84ecd90929bfefec025bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f183678fea54eac8b04487c7ae5e1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "802ddb6311c7407a92ab200059e984b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41650e7ae27b44fbbbf1d495120df97c",
            "placeholder": "​",
            "style": "IPY_MODEL_5197e000d3614e27a6ebb91c350f92c0",
            "value": " 1.03G/1.03G [00:01&lt;00:00, 1.27GB/s]"
          }
        },
        "81be84336db744e7a959328b26308bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848078a59c574c3892e4ea5ed1040deb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b03b1540a8114b1c983aa2b22071a6a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750c89df3ea64b909af01af2e5757e73",
            "placeholder": "​",
            "style": "IPY_MODEL_1730f1e02ec54d32b4c3adaed7148817",
            "value": " 230/230 [00:00&lt;00:00, 28.8kB/s]"
          }
        },
        "b156bcf49fa54198b5737c26ac720190": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b16cd1d5ca5240fdb24b2649a420560b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42830cf2d9c42ffb75bf9aa2d299a27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6c931e1af13423198a79e89ad368075": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c142e7ff3af14eca97a847b41fd79e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7d3cfb1ca3b40ec927b70229cb6c17a",
            "max": 230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51dd523836274f47b1b1a9cdbfb7be77",
            "value": 230
          }
        },
        "cb7dffce26da4ffe8b4c56c731863cea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b156bcf49fa54198b5737c26ac720190",
            "placeholder": "​",
            "style": "IPY_MODEL_2474bdbbb1a44bed8a6142f60b8ebebb",
            "value": "generation_config.json: 100%"
          }
        },
        "cc4176769d20414b8e3379b18ddd1fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75af545a2b3649e6b89b575597444631",
              "IPY_MODEL_d41531f7ea304618ba54c1195b4c7f0c",
              "IPY_MODEL_55eeb755f55c4bd488c74985c94dd531"
            ],
            "layout": "IPY_MODEL_848078a59c574c3892e4ea5ed1040deb"
          }
        },
        "d41531f7ea304618ba54c1195b4c7f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45046b24823e404cb6cb1372a4f29345",
            "max": 45118424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02e2ce31f68a4bddb2713f27dd2baf6c",
            "value": 45118424
          }
        },
        "e7d3cfb1ca3b40ec927b70229cb6c17a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7e8a81ab904f69a0bc0649b1aaef0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb7dffce26da4ffe8b4c56c731863cea",
              "IPY_MODEL_c142e7ff3af14eca97a847b41fd79e11",
              "IPY_MODEL_b03b1540a8114b1c983aa2b22071a6a8"
            ],
            "layout": "IPY_MODEL_2328c87d892245fab8d60b0881c81f66"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
